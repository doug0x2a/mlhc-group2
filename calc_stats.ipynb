{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "# suppress RunTimeWarning\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_optimal_f1_threshold(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    return thresholds[np.argmax(f1)]\n",
    "\n",
    "def bootstrap_stats(y_true, y_prob1, y_prob2, bootstrap_samples=10000):\n",
    "    y_true = np.array(y_true)\n",
    "    results = {}\n",
    "    results['auc1'] = roc_auc_score(y_true, y_prob1)\n",
    "    results['auc2'] = roc_auc_score(y_true, y_prob2)\n",
    "    results['auc_diff'] = results['auc2'] - results['auc1']\n",
    "    aucs1 = []\n",
    "    aucs2 = []\n",
    "    auc_diffs = []\n",
    "    thresholds1 = get_optimal_f1_threshold(y_true, y_prob1)\n",
    "    thresholds2 = get_optimal_f1_threshold(y_true, y_prob2)\n",
    "    results['f1_score1'] = f1_score(y_true, y_prob1 > thresholds1)\n",
    "    results['f1_score2'] = f1_score(y_true, y_prob2 > thresholds2)\n",
    "    results['f1_diff'] = results['f1_score2'] - results['f1_score1']\n",
    "    f1_scores1 = []\n",
    "    f1_scores2 = []\n",
    "    f1_diffs = []\n",
    "\n",
    "    # Run the bootstrap\n",
    "    for _ in tqdm(range(bootstrap_samples)):\n",
    "        idx = np.random.choice(range(len(y_true)), len(y_true), replace=True)\n",
    "        auc1 = roc_auc_score(y_true[idx], y_prob1[idx])\n",
    "        auc2 = roc_auc_score(y_true[idx], y_prob2[idx])\n",
    "        thresholds1 = get_optimal_f1_threshold(y_true[idx], y_prob1[idx])\n",
    "        thresholds2 = get_optimal_f1_threshold(y_true[idx], y_prob2[idx])\n",
    "        f1_1 = f1_score(y_true[idx], y_prob1[idx] > thresholds1)\n",
    "        f1_2 = f1_score(y_true[idx], y_prob2[idx] > thresholds2)\n",
    "        aucs1.append(auc1)\n",
    "        aucs2.append(auc2)\n",
    "        auc_diffs.append(auc2 - auc1)\n",
    "        f1_scores1.append(f1_1)\n",
    "        f1_scores2.append(f1_2)\n",
    "        f1_diffs.append(f1_2 - f1_1)\n",
    "    \n",
    "    # Compute confidence intervals\n",
    "    aucs1 = np.array(aucs1)\n",
    "    aucs2 = np.array(aucs2)\n",
    "    auc_diffs = np.array(auc_diffs)\n",
    "    results['auc_diff_ci'] = np.percentile(auc_diffs, [2.5, 97.5])\n",
    "    if results['auc2'] > results['auc1']:\n",
    "        results['auc_diff_p_value'] = (auc_diffs < 0).mean()\n",
    "    else:\n",
    "        results['auc_diff_p_value'] = (auc_diffs > 0).mean()\n",
    "    results['auc1_ci'] = np.percentile(aucs1, [2.5, 97.5])\n",
    "    results['auc2_ci'] = np.percentile(aucs2, [2.5, 97.5])\n",
    "    f1_scores1 = np.array(f1_scores1)\n",
    "    f1_scores2 = np.array(f1_scores2)\n",
    "    f1_diffs = np.array(f1_diffs)\n",
    "    results['f1_diff_ci'] = np.percentile(f1_diffs, [2.5, 97.5])\n",
    "    if results['f1_score2'] > results['f1_score1']:\n",
    "        results['f1_diff_p_value'] = (f1_diffs < 0).mean()\n",
    "    else:\n",
    "        results['f1_diff_p_value'] = (f1_diffs > 0).mean()\n",
    "    results['f1_score1_ci'] = np.percentile(f1_scores1, [2.5, 97.5])\n",
    "    results['f1_score2_ci'] = np.percentile(f1_scores2, [2.5, 97.5])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BRSet Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_embed = pd.read_csv('embeddings.csv') # From Embeddings archive\n",
    "brset_split = pd.read_csv('split.csv') # generated from resplit_data.ipynb\n",
    "\n",
    "# Load the true values\n",
    "y_test = np.array(brset_embed[brset_split['split'] == 'test']['DR_2'])\n",
    "y_test_embed = np.array(brset_embed[brset_split['embeddings_split'] == 'test']['DR_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary_list = []\n",
    "difference_summary_list = []\n",
    "\n",
    "def add_model_line(model_name, summary_list, results, idx):\n",
    "    summary_list.append({\n",
    "        'model': model_name,\n",
    "        'auc': results[f'auc{idx}'],\n",
    "        'auc_ci' : results[f'auc{idx}_ci'],\n",
    "        # 'auc_ci_lower': results[f'auc{idx}_ci'][0],\n",
    "        # 'auc_ci_upper': results[f'auc{idx}_ci'][1],\n",
    "        'f1_score': results[f'f1_score{idx}'],\n",
    "        'f1_score_ci': results[f'f1_score{idx}_ci'],\n",
    "        # 'f1_score_ci_lower': results[f'f1_score{idx}_ci'][0],\n",
    "        # 'f1_score_ci_upper': results[f'f1_score{idx}_ci'][1]\n",
    "    })\n",
    "\n",
    "def add_difference_line(model1_name, model2_name, summary_list, results):\n",
    "    summary_list.append({\n",
    "        'model1': model1_name,\n",
    "        'model1_auc': results['auc1'],\n",
    "        'model1_f1_score': results['f1_score1'],\n",
    "        'model2': model2_name,\n",
    "        'model2_auc': results['auc2'],\n",
    "        'model2_f1_score': results['f1_score2'],\n",
    "        'auc_diff': results['auc_diff'],\n",
    "        'auc_diff_ci': results['auc_diff_ci'],\n",
    "        # 'auc_diff_ci_lower': results['auc_diff_ci'][0],\n",
    "        # 'auc_diff_ci_upper': results['auc_diff_ci'][1],\n",
    "        'auc_diff_p_value': results['auc_diff_p_value'],\n",
    "        'f1_diff': results['f1_diff'],\n",
    "        'f1_diff_ci': results['f1_diff_ci'],\n",
    "        # 'f1_diff_ci_lower': results['f1_diff_ci'][0],\n",
    "        # 'f1_diff_ci_upper': results['f1_diff_ci'][1],\n",
    "        'f1_diff_p_value': results['f1_diff_p_value']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note Analysis - All columns vs Patient History\n",
    "The all columns represents using all the data that was used to generate the text embeddings data, while the history columns are limited to the columns representing patient history.  The difference between these two represents the effect that adding in a clinical examination of the eye by an ophthalmologist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_samples = 1000 # Number of bootstrap samples to run; 10000 for final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 266.13it/s]\n"
     ]
    }
   ],
   "source": [
    "xgb_all_columns_test_probs = np.load('probs/xgb_all_columns_test_probs.npy')\n",
    "xgb_pt_history_test_probs = np.load('probs/xgb_pt_history_test_probs.npy')\n",
    "\n",
    "results = bootstrap_stats(y_test, xgb_all_columns_test_probs, xgb_pt_history_test_probs, bootstrap_samples=bootstrap_samples)\n",
    "add_model_line('XGBoost Complete Data', model_summary_list, results, 1)\n",
    "add_model_line('XGBoost Patient History', model_summary_list, results, 2)\n",
    "add_difference_line('XGBoost Complete Data', 'XGBoost Patient History', difference_summary_list, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary_df = pd.DataFrame(model_summary_list, columns=['model', 'auc',\n",
    "                                                                'auc_ci', \n",
    "                                                            #  'auc_ci_lower', 'auc_ci_upper', \n",
    "                                                             'f1_score',\n",
    "                                                                'f1_score_ci' \n",
    "                                                            #  'f1_score_ci_lower', 'f1_score_ci_upper'\n",
    "                                                             ])\n",
    "difference_summary_df = pd.DataFrame(difference_summary_list, columns=['model1', 'model1_auc', 'model1_f1_score', \n",
    "                                                                       'model2', 'model2_auc', 'model2_f1_score', \n",
    "                                                                       'auc_diff', \n",
    "                                                                       'auc_diff_ci', \n",
    "                                                                    #    'auc_diff_ci_lower', 'auc_diff_ci_upper', \n",
    "                                                                       'auc_diff_p_value',  \n",
    "                                                                       'f1_diff', \n",
    "                                                                       'f1_diff_ci'\n",
    "                                                                       #'f1_diff_ci_lower', 'f1_diff_ci_upper', \n",
    "                                                                       'f1_diff_p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_ci_lower</th>\n",
       "      <th>auc_ci_upper</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f1_score_ci_lower</th>\n",
       "      <th>f1_score_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Complete Data</td>\n",
       "      <td>0.976969</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>0.986529</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.895522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Patient History</td>\n",
       "      <td>0.851167</td>\n",
       "      <td>0.825734</td>\n",
       "      <td>0.875598</td>\n",
       "      <td>0.413953</td>\n",
       "      <td>0.355930</td>\n",
       "      <td>0.471850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost Complete Data</td>\n",
       "      <td>0.976969</td>\n",
       "      <td>0.966047</td>\n",
       "      <td>0.986354</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.826775</td>\n",
       "      <td>0.895443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost Patient History</td>\n",
       "      <td>0.851167</td>\n",
       "      <td>0.826143</td>\n",
       "      <td>0.874934</td>\n",
       "      <td>0.413953</td>\n",
       "      <td>0.355449</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model       auc  auc_ci_lower  auc_ci_upper  f1_score  \\\n",
       "0    XGBoost Complete Data  0.976969      0.966060      0.986529  0.862069   \n",
       "1  XGBoost Patient History  0.851167      0.825734      0.875598  0.413953   \n",
       "2    XGBoost Complete Data  0.976969      0.966047      0.986354  0.862069   \n",
       "3  XGBoost Patient History  0.851167      0.826143      0.874934  0.413953   \n",
       "\n",
       "   f1_score_ci_lower  f1_score_ci_upper  \n",
       "0           0.824742           0.895522  \n",
       "1           0.355930           0.471850  \n",
       "2           0.826775           0.895443  \n",
       "3           0.355449           0.476200  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model1_auc</th>\n",
       "      <th>model1_f1_score</th>\n",
       "      <th>model2</th>\n",
       "      <th>model2_auc</th>\n",
       "      <th>model2_f1_score</th>\n",
       "      <th>auc_diff</th>\n",
       "      <th>auc_diff_ci_lower</th>\n",
       "      <th>auc_diff_ci_upper</th>\n",
       "      <th>auc_diff_p_value</th>\n",
       "      <th>f1_diff</th>\n",
       "      <th>f1_diff_ci_lower</th>\n",
       "      <th>f1_diff_ci_upper</th>\n",
       "      <th>f1_diff_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Complete Data</td>\n",
       "      <td>0.976969</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>XGBoost Patient History</td>\n",
       "      <td>0.851167</td>\n",
       "      <td>0.413953</td>\n",
       "      <td>-0.125802</td>\n",
       "      <td>-0.149992</td>\n",
       "      <td>-0.102462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.448115</td>\n",
       "      <td>-0.51386</td>\n",
       "      <td>-0.380871</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model1  model1_auc  model1_f1_score  \\\n",
       "0  XGBoost Complete Data    0.976969         0.862069   \n",
       "\n",
       "                    model2  model2_auc  model2_f1_score  auc_diff  \\\n",
       "0  XGBoost Patient History    0.851167         0.413953 -0.125802   \n",
       "\n",
       "   auc_diff_ci_lower  auc_diff_ci_upper  auc_diff_p_value   f1_diff  \\\n",
       "0          -0.149992          -0.102462               0.0 -0.448115   \n",
       "\n",
       "   f1_diff_ci_lower  f1_diff_ci_upper  f1_diff_p_value  \n",
       "0          -0.51386         -0.380871              0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
