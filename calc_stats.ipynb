{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_optimal_f1_threshold(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    return thresholds[np.argmax(f1)]\n",
    "\n",
    "def bootstrap_stats(y_true, y_prob1, y_prob2, bootstrap_samples=10000):\n",
    "    y_true = np.array(y_true)\n",
    "    results = {}\n",
    "    results['auc1'] = roc_auc_score(y_true, y_prob1)\n",
    "    results['auc2'] = roc_auc_score(y_true, y_prob2)\n",
    "    results['auc_diff'] = results['auc2'] - results['auc1']\n",
    "    aucs1 = []\n",
    "    aucs2 = []\n",
    "    auc_diffs = []\n",
    "    thresholds1 = get_optimal_f1_threshold(y_true, y_prob1)\n",
    "    thresholds2 = get_optimal_f1_threshold(y_true, y_prob2)\n",
    "    results['f1_score1'] = f1_score(y_true, y_prob1 > thresholds1)\n",
    "    results['f1_score2'] = f1_score(y_true, y_prob2 > thresholds2)\n",
    "    results['f1_diff'] = results['f1_score2'] - results['f1_score1']\n",
    "    f1_scores1 = []\n",
    "    f1_scores2 = []\n",
    "    f1_diffs = []\n",
    "\n",
    "    # Run the bootstrap\n",
    "    for _ in tqdm(range(bootstrap_samples)):\n",
    "        idx = np.random.choice(range(len(y_true)), len(y_true), replace=True)\n",
    "        auc1 = roc_auc_score(y_true[idx], y_prob1[idx])\n",
    "        auc2 = roc_auc_score(y_true[idx], y_prob2[idx])\n",
    "        thresholds1 = get_optimal_f1_threshold(y_true[idx], y_prob1[idx])\n",
    "        thresholds2 = get_optimal_f1_threshold(y_true[idx], y_prob2[idx])\n",
    "        f1_1 = f1_score(y_true[idx], y_prob1[idx] > thresholds1)\n",
    "        f1_2 = f1_score(y_true[idx], y_prob2[idx] > thresholds2)\n",
    "        aucs1.append(auc1)\n",
    "        aucs2.append(auc2)\n",
    "        auc_diffs.append(auc2 - auc1)\n",
    "        f1_scores1.append(f1_1)\n",
    "        f1_scores2.append(f1_2)\n",
    "        f1_diffs.append(f1_2 - f1_1)\n",
    "    \n",
    "    # Compute confidence intervals\n",
    "    aucs1 = np.array(aucs1)\n",
    "    aucs2 = np.array(aucs2)\n",
    "    auc_diffs = np.array(auc_diffs)\n",
    "    results['auc_diff_ci'] = np.percentile(auc_diffs, [2.5, 97.5])\n",
    "    if results['auc2'] > results['auc1']:\n",
    "        results['auc_diff_p_value'] = (auc_diffs < 0).mean()\n",
    "    else:\n",
    "        results['auc_diff_p_value'] = (auc_diffs > 0).mean()\n",
    "    results['auc1_ci'] = np.percentile(aucs1, [2.5, 97.5])\n",
    "    results['auc2_ci'] = np.percentile(aucs2, [2.5, 97.5])\n",
    "    f1_scores1 = np.array(f1_scores1)\n",
    "    f1_scores2 = np.array(f1_scores2)\n",
    "    f1_diffs = np.array(f1_diffs)\n",
    "    results['f1_diff_ci'] = np.percentile(f1_diffs, [2.5, 97.5])\n",
    "    if results['f1_score2'] > results['f1_score1']:\n",
    "        results['f1_diff_p_value'] = (f1_diffs < 0).mean()\n",
    "    else:\n",
    "        results['f1_diff_p_value'] = (f1_diffs > 0).mean()\n",
    "    results['f1_score1_ci'] = np.percentile(f1_scores1, [2.5, 97.5])\n",
    "    results['f1_score2_ci'] = np.percentile(f1_scores2, [2.5, 97.5])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BRSet Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_embed = pd.read_csv('embeddings.csv') # From Embeddings archive\n",
    "brset_split = pd.read_csv('split.csv') # generated from resplit_data.ipynb\n",
    "\n",
    "# Load the true values\n",
    "y_test = np.array(brset_embed[brset_split['split'] == 'test']['DR_2'])\n",
    "y_test_embed = np.array(brset_embed[brset_split['embeddings_split'] == 'test']['DR_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary_list = []\n",
    "difference_summary_list = []\n",
    "\n",
    "def add_model_line(model_name, summary_list, results, idx):\n",
    "    summary_list.append({\n",
    "        'model': model_name,\n",
    "        'auc': results[f'auc{idx}'],\n",
    "        'auc_ci' : results[f'auc{idx}_ci'],\n",
    "        # 'auc_ci_lower': results[f'auc{idx}_ci'][0],\n",
    "        # 'auc_ci_upper': results[f'auc{idx}_ci'][1],\n",
    "        'f1_score': results[f'f1_score{idx}'],\n",
    "        'f1_score_ci': results[f'f1_score{idx}_ci'],\n",
    "        # 'f1_score_ci_lower': results[f'f1_score{idx}_ci'][0],\n",
    "        # 'f1_score_ci_upper': results[f'f1_score{idx}_ci'][1]\n",
    "    })\n",
    "\n",
    "def add_difference_line(model1_name, model2_name, summary_list, results):\n",
    "    summary_list.append({\n",
    "        'model1': model1_name,\n",
    "        'model1_auc': results['auc1'],\n",
    "        'model1_f1_score': results['f1_score1'],\n",
    "        'model2': model2_name,\n",
    "        'model2_auc': results['auc2'],\n",
    "        'model2_f1_score': results['f1_score2'],\n",
    "        'auc_diff': results['auc_diff'],\n",
    "        'auc_diff_ci': results['auc_diff_ci'],\n",
    "        # 'auc_diff_ci_lower': results['auc_diff_ci'][0],\n",
    "        # 'auc_diff_ci_upper': results['auc_diff_ci'][1],\n",
    "        'auc_diff_p_value': results['auc_diff_p_value'],\n",
    "        'f1_diff': results['f1_diff'],\n",
    "        'f1_diff_ci': results['f1_diff_ci'],\n",
    "        # 'f1_diff_ci_lower': results['f1_diff_ci'][0],\n",
    "        # 'f1_diff_ci_upper': results['f1_diff_ci'][1],\n",
    "        'f1_diff_p_value': results['f1_diff_p_value']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note Analysis - All columns vs Patient History\n",
    "The all columns represents using all the data that was used to generate the text embeddings data, while the history columns are limited to the columns representing patient history.  The difference between these two represents the effect that adding in a clinical examination of the eye by an ophthalmologist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_samples = 10000 # Number of bootstrap samples to run; 10000 for final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:37<00:00, 268.72it/s]\n"
     ]
    }
   ],
   "source": [
    "xgb_all_columns_test_probs = np.load('probs/xgb_all_columns_test_probs.npy')\n",
    "xgb_pt_history_test_probs = np.load('probs/xgb_pt_history_test_probs.npy')\n",
    "\n",
    "results = bootstrap_stats(y_test, xgb_all_columns_test_probs, xgb_pt_history_test_probs, bootstrap_samples=bootstrap_samples)\n",
    "add_model_line('XGBoost Complete Data', model_summary_list, results, 1)\n",
    "add_model_line('XGBoost Patient History', model_summary_list, results, 2)\n",
    "add_difference_line('XGBoost Complete Data', 'XGBoost Patient History', difference_summary_list, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary_df = pd.DataFrame(model_summary_list, columns=['model', 'auc',\n",
    "                                                                'auc_ci', \n",
    "                                                            #  'auc_ci_lower', 'auc_ci_upper', \n",
    "                                                             'f1_score',\n",
    "                                                                'f1_score_ci' \n",
    "                                                            #  'f1_score_ci_lower', 'f1_score_ci_upper'\n",
    "                                                             ])\n",
    "difference_summary_df = pd.DataFrame(difference_summary_list, columns=['model1', 'model1_auc', 'model1_f1_score', \n",
    "                                                                       'model2', 'model2_auc', 'model2_f1_score', \n",
    "                                                                       'auc_diff', \n",
    "                                                                       'auc_diff_ci', \n",
    "                                                                    #    'auc_diff_ci_lower', 'auc_diff_ci_upper', \n",
    "                                                                       'auc_diff_p_value',  \n",
    "                                                                       'f1_diff', \n",
    "                                                                       'f1_diff_ci',\n",
    "                                                                       #'f1_diff_ci_lower', 'f1_diff_ci_upper', \n",
    "                                                                       'f1_diff_p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_ci</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f1_score_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Complete Data</td>\n",
       "      <td>0.976969</td>\n",
       "      <td>[0.9660153387285747, 0.986757092246582]</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>[0.8243902439024391, 0.8956758076770015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Patient History</td>\n",
       "      <td>0.851167</td>\n",
       "      <td>[0.8259238867051708, 0.8753490262120656]</td>\n",
       "      <td>0.413953</td>\n",
       "      <td>[0.35596984263938536, 0.4721488364948928]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model       auc  \\\n",
       "0    XGBoost Complete Data  0.976969   \n",
       "1  XGBoost Patient History  0.851167   \n",
       "\n",
       "                                     auc_ci  f1_score  \\\n",
       "0   [0.9660153387285747, 0.986757092246582]  0.862069   \n",
       "1  [0.8259238867051708, 0.8753490262120656]  0.413953   \n",
       "\n",
       "                                 f1_score_ci  \n",
       "0   [0.8243902439024391, 0.8956758076770015]  \n",
       "1  [0.35596984263938536, 0.4721488364948928]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model1_auc</th>\n",
       "      <th>model1_f1_score</th>\n",
       "      <th>model2</th>\n",
       "      <th>model2_auc</th>\n",
       "      <th>model2_f1_score</th>\n",
       "      <th>auc_diff</th>\n",
       "      <th>auc_diff_ci</th>\n",
       "      <th>auc_diff_p_value</th>\n",
       "      <th>f1_diff</th>\n",
       "      <th>f1_diff_ci</th>\n",
       "      <th>f1_diff_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Complete Data</td>\n",
       "      <td>0.976969</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>XGBoost Patient History</td>\n",
       "      <td>0.851167</td>\n",
       "      <td>0.413953</td>\n",
       "      <td>-0.125802</td>\n",
       "      <td>[-0.15008124290746672, -0.10233034756119644]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.448115</td>\n",
       "      <td>[-0.5132898552455971, -0.3820983153500134]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model1  model1_auc  model1_f1_score  \\\n",
       "0  XGBoost Complete Data    0.976969         0.862069   \n",
       "\n",
       "                    model2  model2_auc  model2_f1_score  auc_diff  \\\n",
       "0  XGBoost Patient History    0.851167         0.413953 -0.125802   \n",
       "\n",
       "                                    auc_diff_ci  auc_diff_p_value   f1_diff  \\\n",
       "0  [-0.15008124290746672, -0.10233034756119644]               0.0 -0.448115   \n",
       "\n",
       "                                   f1_diff_ci  f1_diff_p_value  \n",
       "0  [-0.5132898552455971, -0.3820983153500134]              0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
