{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_embed = pd.read_csv('embeddings.csv')\n",
    "brset_split = pd.read_csv('split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_names = brset_embed.columns[brset_embed.columns.str.match('text_\\d+')]\n",
    "image_column_names = brset_embed.columns[brset_embed.columns.str.match('image_\\d+')]\n",
    "text_columns = brset_embed[text_column_names]\n",
    "image_columns = brset_embed[image_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = torch.tensor(text_columns.values)\n",
    "image_embed = torch.tensor(image_columns.values)\n",
    "y = torch.tensor(brset_embed['DR_2'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, verbose=True, scheduler=None):\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_accuracy': [], 'val_f1': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            val_logits = model(X)\n",
    "            loss = criterion(val_logits, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = []\n",
    "            val_labels = []\n",
    "            val_loss = 0\n",
    "            for X, y in val_loader:\n",
    "                X = X.to(device).float()\n",
    "                y = y.to(device).float()\n",
    "                val_labels.extend(y.tolist())\n",
    "                y_pred = model(X)\n",
    "                val_logits.append(y_pred.cpu().numpy())\n",
    "                loss = criterion(y_pred, y.unsqueeze(1))\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            val_logits = np.concatenate(val_logits)\n",
    "            val_preds = nn.Sigmoid()(torch.tensor(val_logits)).cpu().numpy()\n",
    "            auc = roc_auc_score(val_labels, val_preds)\n",
    "            history['val_auc'].append(auc)\n",
    "            accuracy = accuracy_score(val_labels, val_preds > 0.5)\n",
    "            history['val_accuracy'].append(accuracy)\n",
    "            f1 = f1_score(val_labels, val_preds > 0.5)\n",
    "            history['val_f1'].append(f1)\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(val_loss)\n",
    "                last_lr = scheduler.get_last_lr()[0]\n",
    "            else:\n",
    "                last_lr = optimizer.param_groups[0]['lr']\n",
    "            if verbose:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, val loss: {val_loss:.4f}, val auc: {auc:.4f}, val accuracy: {accuracy:.4f}, val f1: {f1:.4f}, LR: {last_lr}')\n",
    "    return history\n",
    "\n",
    "\n",
    "def get_probs(model, loader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    y_hat = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for X,_ in loader:\n",
    "            X = X.to(device).float()\n",
    "            y_hat = torch.cat((y_hat, model(X)))\n",
    "    return nn.Sigmoid()(y_hat).cpu().numpy().flatten()\n",
    "\n",
    "def get_optimal_f1_threshold(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    return thresholds[np.argmax(f1)]\n",
    "\n",
    "# Simple Dataset to support embeddings\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://github.com/luisnakayama/BRSET/blob/main/src/FocalLoss.py\n",
    "class BinaryFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(BinaryFocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Only Model - Embedding data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9758, 1536]) torch.Size([3254, 1536]) torch.Size([3254, 1536])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_embed_idx = brset_split[brset_split['embeddings_split'] == 'train'].index\n",
    "test_embed_idx = brset_split[brset_split['embeddings_split'] == 'test'].index\n",
    "train_img_emsplit = image_embed[train_embed_idx]\n",
    "test_img_emsplit = image_embed[test_embed_idx]\n",
    "train_y_emsplit = y[train_embed_idx]\n",
    "test_y_emsplit = y[test_embed_idx]\n",
    "\n",
    "train_img_emsplit, val_img_emsplit, train_y_emsplit, val_y_emsplit = train_test_split(train_img_emsplit, train_y_emsplit, \n",
    "                                                                                      test_size=len(test_embed_idx)/len(train_embed_idx),\n",
    "                                                                                      random_state=42)\n",
    "\n",
    "print(train_img_emsplit.shape, val_img_emsplit.shape, test_img_emsplit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_emsplit_train_dataset = SimpleDataset(train_img_emsplit, train_y_emsplit)\n",
    "image_emsplit_val_dataset = SimpleDataset(val_img_emsplit, val_y_emsplit)\n",
    "image_emsplit_test_dataset = SimpleDataset(test_img_emsplit, test_y_emsplit)\n",
    "\n",
    "image_emsplit_train_loader = DataLoader(image_emsplit_train_dataset, batch_size=32, shuffle=True)\n",
    "image_emsplit_val_loader = DataLoader(image_emsplit_val_dataset, batch_size=32, shuffle=False)\n",
    "image_emsplit_test_loader = DataLoader(image_emsplit_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train image only model\n",
    "image_only_model_emsplit = nn.Sequential(\n",
    "    nn.Linear(1536, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1294490/1978008771.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor(p0/p1).to(device)\n",
      "/home/doug/miniconda3/envs/mit-ml/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0709, val loss: 0.0469, val auc: 0.9281, val accuracy: 0.9462, val f1: 0.5658, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0389, val loss: 0.0370, val auc: 0.9311, val accuracy: 0.9474, val f1: 0.4771, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0375, val loss: 0.0503, val auc: 0.9364, val accuracy: 0.9373, val f1: 0.2444, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0363, val loss: 0.0455, val auc: 0.9411, val accuracy: 0.9462, val f1: 0.4224, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0343, val loss: 0.0339, val auc: 0.9404, val accuracy: 0.9539, val f1: 0.6053, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0336, val loss: 0.0443, val auc: 0.9445, val accuracy: 0.9468, val f1: 0.4328, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0340, val loss: 0.0701, val auc: 0.9408, val accuracy: 0.9388, val f1: 0.2491, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0340, val loss: 0.0376, val auc: 0.9467, val accuracy: 0.9505, val f1: 0.6596, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0321, val loss: 0.0324, val auc: 0.9475, val accuracy: 0.9554, val f1: 0.6402, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0327, val loss: 0.0326, val auc: 0.9486, val accuracy: 0.9561, val f1: 0.6452, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0312, val loss: 0.0309, val auc: 0.9511, val accuracy: 0.9567, val f1: 0.6240, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0316, val loss: 0.0395, val auc: 0.9486, val accuracy: 0.9456, val f1: 0.4080, LR: 0.001\n",
      "Epoch 13/50, train loss: 0.0327, val loss: 0.0312, val auc: 0.9503, val accuracy: 0.9561, val f1: 0.6554, LR: 0.001\n",
      "Epoch 14/50, train loss: 0.0311, val loss: 0.0421, val auc: 0.9483, val accuracy: 0.9499, val f1: 0.4890, LR: 0.001\n",
      "Epoch 15/50, train loss: 0.0312, val loss: 0.0308, val auc: 0.9517, val accuracy: 0.9561, val f1: 0.6651, LR: 0.001\n",
      "Epoch 16/50, train loss: 0.0310, val loss: 0.0351, val auc: 0.9513, val accuracy: 0.9551, val f1: 0.5805, LR: 0.001\n",
      "Epoch 17/50, train loss: 0.0306, val loss: 0.0401, val auc: 0.9507, val accuracy: 0.9511, val f1: 0.5108, LR: 0.001\n",
      "Epoch 18/50, train loss: 0.0311, val loss: 0.0306, val auc: 0.9525, val accuracy: 0.9576, val f1: 0.6209, LR: 0.001\n",
      "Epoch 19/50, train loss: 0.0287, val loss: 0.0333, val auc: 0.9522, val accuracy: 0.9561, val f1: 0.5994, LR: 0.001\n",
      "Epoch 20/50, train loss: 0.0282, val loss: 0.0363, val auc: 0.9526, val accuracy: 0.9570, val f1: 0.6154, LR: 0.001\n",
      "Epoch 21/50, train loss: 0.0283, val loss: 0.0298, val auc: 0.9516, val accuracy: 0.9594, val f1: 0.6471, LR: 0.001\n",
      "Epoch 22/50, train loss: 0.0270, val loss: 0.0300, val auc: 0.9539, val accuracy: 0.9613, val f1: 0.6736, LR: 0.001\n",
      "Epoch 23/50, train loss: 0.0280, val loss: 0.0307, val auc: 0.9529, val accuracy: 0.9597, val f1: 0.6507, LR: 0.001\n",
      "Epoch 24/50, train loss: 0.0275, val loss: 0.0336, val auc: 0.9535, val accuracy: 0.9551, val f1: 0.5731, LR: 0.001\n",
      "Epoch 25/50, train loss: 0.0283, val loss: 0.0319, val auc: 0.9558, val accuracy: 0.9597, val f1: 0.6946, LR: 0.001\n",
      "Epoch 26/50, train loss: 0.0270, val loss: 0.0348, val auc: 0.9558, val accuracy: 0.9533, val f1: 0.5394, LR: 0.001\n",
      "Epoch 27/50, train loss: 0.0275, val loss: 0.0301, val auc: 0.9549, val accuracy: 0.9576, val f1: 0.6124, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0236, val loss: 0.0287, val auc: 0.9558, val accuracy: 0.9619, val f1: 0.6961, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0236, val loss: 0.0291, val auc: 0.9549, val accuracy: 0.9616, val f1: 0.6787, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0226, val loss: 0.0296, val auc: 0.9545, val accuracy: 0.9625, val f1: 0.6872, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0226, val loss: 0.0290, val auc: 0.9541, val accuracy: 0.9616, val f1: 0.6883, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0220, val loss: 0.0289, val auc: 0.9552, val accuracy: 0.9634, val f1: 0.7003, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0224, val loss: 0.0294, val auc: 0.9551, val accuracy: 0.9616, val f1: 0.6944, LR: 0.0001\n",
      "Epoch 34/50, train loss: 0.0224, val loss: 0.0292, val auc: 0.9554, val accuracy: 0.9619, val f1: 0.6946, LR: 1e-05\n",
      "Epoch 35/50, train loss: 0.0212, val loss: 0.0293, val auc: 0.9554, val accuracy: 0.9622, val f1: 0.6948, LR: 1e-05\n",
      "Epoch 36/50, train loss: 0.0214, val loss: 0.0293, val auc: 0.9553, val accuracy: 0.9628, val f1: 0.6967, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0218, val loss: 0.0290, val auc: 0.9554, val accuracy: 0.9622, val f1: 0.6948, LR: 1e-05\n",
      "Epoch 38/50, train loss: 0.0222, val loss: 0.0289, val auc: 0.9553, val accuracy: 0.9613, val f1: 0.6897, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0215, val loss: 0.0290, val auc: 0.9553, val accuracy: 0.9619, val f1: 0.6931, LR: 1e-05\n",
      "Epoch 40/50, train loss: 0.0215, val loss: 0.0290, val auc: 0.9553, val accuracy: 0.9613, val f1: 0.6897, LR: 1.0000000000000002e-06\n",
      "Epoch 41/50, train loss: 0.0215, val loss: 0.0290, val auc: 0.9553, val accuracy: 0.9613, val f1: 0.6897, LR: 1.0000000000000002e-06\n",
      "Epoch 42/50, train loss: 0.0214, val loss: 0.0290, val auc: 0.9553, val accuracy: 0.9613, val f1: 0.6897, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0212, val loss: 0.0290, val auc: 0.9553, val accuracy: 0.9613, val f1: 0.6897, LR: 1.0000000000000002e-06\n",
      "Epoch 44/50, train loss: 0.0210, val loss: 0.0291, val auc: 0.9553, val accuracy: 0.9613, val f1: 0.6897, LR: 1.0000000000000002e-06\n",
      "Epoch 45/50, train loss: 0.0211, val loss: 0.0291, val auc: 0.9553, val accuracy: 0.9616, val f1: 0.6914, LR: 1.0000000000000002e-06\n",
      "Epoch 46/50, train loss: 0.0211, val loss: 0.0291, val auc: 0.9553, val accuracy: 0.9619, val f1: 0.6931, LR: 1.0000000000000002e-07\n",
      "Epoch 47/50, train loss: 0.0215, val loss: 0.0291, val auc: 0.9553, val accuracy: 0.9619, val f1: 0.6931, LR: 1.0000000000000002e-07\n",
      "Epoch 48/50, train loss: 0.0218, val loss: 0.0291, val auc: 0.9553, val accuracy: 0.9619, val f1: 0.6931, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0216, val loss: 0.0291, val auc: 0.9553, val accuracy: 0.9619, val f1: 0.6931, LR: 1.0000000000000002e-07\n",
      "Epoch 50/50, train loss: 0.0211, val loss: 0.0291, val auc: 0.9553, val accuracy: 0.9619, val f1: 0.6931, LR: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "p1 = sum(train_y_emsplit)/len(train_y_emsplit)\n",
    "p0 = 1 - p1\n",
    "pos_weight = torch.tensor(p0/p1).to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(image_only_model_emsplit.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(image_only_model_emsplit, image_emsplit_train_loader, image_emsplit_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Only ROC: 0.9480277164746064, Accuracy: 0.9668100799016595, F1: 0.7096774193548386\n",
      "Image Only Accuracy: 0.9683466502765826, F1: 0.7146814404432132\n"
     ]
    }
   ],
   "source": [
    "# Evaluate image only model on test set\n",
    "y_probs = get_probs(image_only_model_emsplit, image_emsplit_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "image_only_roc = roc_auc_score(test_y_emsplit.numpy(), y_probs)\n",
    "image_only_accuracy = accuracy_score(test_y_emsplit.numpy(), y_preds)\n",
    "image_only_f1 = f1_score(test_y_emsplit.numpy(), y_preds)\n",
    "print(f'Image Only ROC: {image_only_roc}, Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(test_y_emsplit.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "image_only_accuracy = accuracy_score(test_y_emsplit.numpy(), y_preds)\n",
    "image_only_f1 = f1_score(test_y_emsplit.numpy(), y_preds)\n",
    "print(f'Image Only Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "np.save('probs/image_only_test_emsplit_probs.npy', y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Only Model - Resplit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = brset_split[brset_split['split'] == 'train'].index\n",
    "val_idx = brset_split[brset_split['split'] == 'val'].index\n",
    "test_idx = brset_split[brset_split['split'] == 'test'].index\n",
    "\n",
    "image_train = image_embed[train_idx]\n",
    "image_val = image_embed[val_idx]\n",
    "image_test = image_embed[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "# DataSet\n",
    "image_train_dataset = SimpleDataset(image_train, y_train)\n",
    "image_val_dataset = SimpleDataset(image_val, y_val)\n",
    "image_test_dataset = SimpleDataset(image_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "image_train_loader = DataLoader(image_train_dataset, batch_size=32, shuffle=True)\n",
    "image_val_loader = DataLoader(image_val_dataset, batch_size=32, shuffle=False)\n",
    "image_test_loader = DataLoader(image_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_only_model = nn.Sequential(\n",
    "    nn.Linear(1536, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0595, val loss: 0.0378, val auc: 0.9081, val accuracy: 0.9521, val f1: 0.5465, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0434, val loss: 0.0457, val auc: 0.9250, val accuracy: 0.9487, val f1: 0.6089, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0402, val loss: 0.0355, val auc: 0.9277, val accuracy: 0.9530, val f1: 0.5049, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0370, val loss: 0.0390, val auc: 0.9360, val accuracy: 0.9585, val f1: 0.5714, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0368, val loss: 0.0396, val auc: 0.9278, val accuracy: 0.9555, val f1: 0.6348, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0360, val loss: 0.0327, val auc: 0.9373, val accuracy: 0.9604, val f1: 0.6195, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0338, val loss: 0.0349, val auc: 0.9433, val accuracy: 0.9542, val f1: 0.4880, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0329, val loss: 0.0307, val auc: 0.9413, val accuracy: 0.9622, val f1: 0.6535, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0335, val loss: 0.0319, val auc: 0.9316, val accuracy: 0.9585, val f1: 0.6667, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0330, val loss: 0.0355, val auc: 0.9426, val accuracy: 0.9576, val f1: 0.6584, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0327, val loss: 0.0447, val auc: 0.9438, val accuracy: 0.9552, val f1: 0.4895, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0318, val loss: 0.0296, val auc: 0.9437, val accuracy: 0.9601, val f1: 0.6505, LR: 0.001\n",
      "Epoch 13/50, train loss: 0.0332, val loss: 0.0357, val auc: 0.9427, val accuracy: 0.9555, val f1: 0.6572, LR: 0.001\n",
      "Epoch 14/50, train loss: 0.0304, val loss: 0.0301, val auc: 0.9410, val accuracy: 0.9631, val f1: 0.6859, LR: 0.001\n",
      "Epoch 15/50, train loss: 0.0296, val loss: 0.0306, val auc: 0.9510, val accuracy: 0.9628, val f1: 0.6409, LR: 0.001\n",
      "Epoch 16/50, train loss: 0.0292, val loss: 0.0295, val auc: 0.9459, val accuracy: 0.9625, val f1: 0.6685, LR: 0.001\n",
      "Epoch 17/50, train loss: 0.0308, val loss: 0.0286, val auc: 0.9508, val accuracy: 0.9622, val f1: 0.6555, LR: 0.001\n",
      "Epoch 18/50, train loss: 0.0290, val loss: 0.0289, val auc: 0.9491, val accuracy: 0.9616, val f1: 0.6556, LR: 0.001\n",
      "Epoch 19/50, train loss: 0.0284, val loss: 0.0275, val auc: 0.9510, val accuracy: 0.9628, val f1: 0.6667, LR: 0.001\n",
      "Epoch 20/50, train loss: 0.0299, val loss: 0.0282, val auc: 0.9492, val accuracy: 0.9644, val f1: 0.6813, LR: 0.001\n",
      "Epoch 21/50, train loss: 0.0293, val loss: 0.0289, val auc: 0.9531, val accuracy: 0.9635, val f1: 0.6405, LR: 0.001\n",
      "Epoch 22/50, train loss: 0.0291, val loss: 0.0337, val auc: 0.9529, val accuracy: 0.9576, val f1: 0.5175, LR: 0.001\n",
      "Epoch 23/50, train loss: 0.0298, val loss: 0.0328, val auc: 0.9530, val accuracy: 0.9644, val f1: 0.6398, LR: 0.001\n",
      "Epoch 24/50, train loss: 0.0284, val loss: 0.0290, val auc: 0.9519, val accuracy: 0.9619, val f1: 0.6497, LR: 0.001\n",
      "Epoch 25/50, train loss: 0.0275, val loss: 0.0306, val auc: 0.9521, val accuracy: 0.9533, val f1: 0.4370, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0250, val loss: 0.0271, val auc: 0.9542, val accuracy: 0.9625, val f1: 0.6872, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0232, val loss: 0.0282, val auc: 0.9543, val accuracy: 0.9644, val f1: 0.6742, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0235, val loss: 0.0270, val auc: 0.9547, val accuracy: 0.9635, val f1: 0.6722, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0231, val loss: 0.0275, val auc: 0.9547, val accuracy: 0.9638, val f1: 0.6529, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0234, val loss: 0.0273, val auc: 0.9543, val accuracy: 0.9631, val f1: 0.6721, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0230, val loss: 0.0279, val auc: 0.9541, val accuracy: 0.9635, val f1: 0.6775, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0224, val loss: 0.0274, val auc: 0.9536, val accuracy: 0.9628, val f1: 0.6739, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0228, val loss: 0.0271, val auc: 0.9548, val accuracy: 0.9650, val f1: 0.6935, LR: 0.0001\n",
      "Epoch 34/50, train loss: 0.0224, val loss: 0.0271, val auc: 0.9549, val accuracy: 0.9631, val f1: 0.6809, LR: 1e-05\n",
      "Epoch 35/50, train loss: 0.0216, val loss: 0.0271, val auc: 0.9548, val accuracy: 0.9638, val f1: 0.6828, LR: 1e-05\n",
      "Epoch 36/50, train loss: 0.0219, val loss: 0.0270, val auc: 0.9548, val accuracy: 0.9641, val f1: 0.6880, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0217, val loss: 0.0271, val auc: 0.9547, val accuracy: 0.9641, val f1: 0.6880, LR: 1e-05\n",
      "Epoch 38/50, train loss: 0.0216, val loss: 0.0272, val auc: 0.9545, val accuracy: 0.9662, val f1: 0.6978, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0218, val loss: 0.0273, val auc: 0.9546, val accuracy: 0.9647, val f1: 0.6883, LR: 1e-05\n",
      "Epoch 40/50, train loss: 0.0216, val loss: 0.0272, val auc: 0.9546, val accuracy: 0.9653, val f1: 0.6921, LR: 1e-05\n",
      "Epoch 41/50, train loss: 0.0224, val loss: 0.0271, val auc: 0.9545, val accuracy: 0.9653, val f1: 0.6954, LR: 1e-05\n",
      "Epoch 42/50, train loss: 0.0219, val loss: 0.0274, val auc: 0.9544, val accuracy: 0.9644, val f1: 0.6848, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0220, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9650, val f1: 0.6902, LR: 1.0000000000000002e-06\n",
      "Epoch 44/50, train loss: 0.0212, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9647, val f1: 0.6900, LR: 1.0000000000000002e-06\n",
      "Epoch 45/50, train loss: 0.0218, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9650, val f1: 0.6935, LR: 1.0000000000000002e-06\n",
      "Epoch 46/50, train loss: 0.0212, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9650, val f1: 0.6935, LR: 1.0000000000000002e-06\n",
      "Epoch 47/50, train loss: 0.0220, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9650, val f1: 0.6935, LR: 1.0000000000000002e-06\n",
      "Epoch 48/50, train loss: 0.0217, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9647, val f1: 0.6917, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0220, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9647, val f1: 0.6917, LR: 1.0000000000000002e-07\n",
      "Epoch 50/50, train loss: 0.0217, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9647, val f1: 0.6917, LR: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(image_only_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(image_only_model, image_train_loader, image_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Only ROC: 0.9557650850470365, Accuracy: 0.9637257915770059, F1: 0.6775956284153005\n",
      "Image Only Accuracy: 0.9600368890255149, F1: 0.7161572052401747\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(image_only_model, image_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "image_only_roc = roc_auc_score(y[test_idx].numpy(), y_probs)\n",
    "image_only_accuracy = accuracy_score(y[test_idx].numpy(), y_preds)\n",
    "image_only_f1 = f1_score(y[test_idx].numpy(), y_preds)\n",
    "print(f'Image Only ROC: {image_only_roc}, Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y[test_idx].numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "image_only_accuracy = accuracy_score(y[test_idx].numpy(), y_preds)\n",
    "image_only_f1 = f1_score(y[test_idx].numpy(), y_preds)\n",
    "print(f'Image Only Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "np.save('probs/image_only_test_probs.npy', y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text_embed into train and test based on brset_embed['split']\n",
    "text_train = text_embed[train_idx]\n",
    "text_val = text_embed[val_idx]\n",
    "text_test = text_embed[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_dataset = SimpleDataset(text_train, y_train)\n",
    "text_val_dataset = SimpleDataset(text_val, y_val)\n",
    "text_test_dataset = SimpleDataset(text_test, y_test)\n",
    "\n",
    "text_train_loader = DataLoader(text_train_dataset, batch_size=32, shuffle=True)\n",
    "text_val_loader = DataLoader(text_val_dataset, batch_size=32, shuffle=False)\n",
    "text_test_loader = DataLoader(text_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_model = nn.Sequential(\n",
    "    nn.Linear(4096, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    # nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0905, val loss: 0.0330, val auc: 0.9505, val accuracy: 0.9493, val f1: 0.3726, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0331, val loss: 0.0293, val auc: 0.9565, val accuracy: 0.9705, val f1: 0.7513, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0321, val loss: 0.0309, val auc: 0.9548, val accuracy: 0.9352, val f1: 0.0000, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0356, val loss: 0.0321, val auc: 0.9523, val accuracy: 0.9564, val f1: 0.5449, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0328, val loss: 0.0431, val auc: 0.9565, val accuracy: 0.9561, val f1: 0.4911, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0335, val loss: 0.0287, val auc: 0.9561, val accuracy: 0.9613, val f1: 0.6379, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0341, val loss: 0.0360, val auc: 0.9546, val accuracy: 0.9671, val f1: 0.7617, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0341, val loss: 0.0294, val auc: 0.9573, val accuracy: 0.9721, val f1: 0.7378, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0305, val loss: 0.0293, val auc: 0.9603, val accuracy: 0.9656, val f1: 0.6606, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0297, val loss: 0.0321, val auc: 0.9614, val accuracy: 0.9678, val f1: 0.6847, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0296, val loss: 0.0329, val auc: 0.9510, val accuracy: 0.9641, val f1: 0.7451, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0290, val loss: 0.0460, val auc: 0.9623, val accuracy: 0.9527, val f1: 0.4296, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0273, val loss: 0.0270, val auc: 0.9604, val accuracy: 0.9776, val f1: 0.8142, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0251, val loss: 0.0272, val auc: 0.9614, val accuracy: 0.9760, val f1: 0.7937, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0258, val loss: 0.0267, val auc: 0.9616, val accuracy: 0.9760, val f1: 0.8060, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0264, val loss: 0.0265, val auc: 0.9619, val accuracy: 0.9782, val f1: 0.8184, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0264, val loss: 0.0268, val auc: 0.9609, val accuracy: 0.9767, val f1: 0.8109, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0251, val loss: 0.0276, val auc: 0.9628, val accuracy: 0.9764, val f1: 0.7925, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0263, val loss: 0.0259, val auc: 0.9618, val accuracy: 0.9770, val f1: 0.8042, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0251, val loss: 0.0257, val auc: 0.9614, val accuracy: 0.9779, val f1: 0.8173, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0248, val loss: 0.0256, val auc: 0.9620, val accuracy: 0.9767, val f1: 0.8090, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0251, val loss: 0.0254, val auc: 0.9613, val accuracy: 0.9770, val f1: 0.8120, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0251, val loss: 0.0257, val auc: 0.9617, val accuracy: 0.9770, val f1: 0.8042, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0247, val loss: 0.0253, val auc: 0.9617, val accuracy: 0.9788, val f1: 0.8226, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0244, val loss: 0.0257, val auc: 0.9624, val accuracy: 0.9757, val f1: 0.7916, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0253, val loss: 0.0252, val auc: 0.9615, val accuracy: 0.9757, val f1: 0.8049, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0245, val loss: 0.0254, val auc: 0.9621, val accuracy: 0.9776, val f1: 0.8084, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0245, val loss: 0.0244, val auc: 0.9620, val accuracy: 0.9770, val f1: 0.8166, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0246, val loss: 0.0247, val auc: 0.9622, val accuracy: 0.9791, val f1: 0.8256, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0237, val loss: 0.0252, val auc: 0.9623, val accuracy: 0.9757, val f1: 0.7916, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0251, val loss: 0.0248, val auc: 0.9621, val accuracy: 0.9785, val f1: 0.8205, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0237, val loss: 0.0242, val auc: 0.9626, val accuracy: 0.9770, val f1: 0.8120, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0243, val loss: 0.0240, val auc: 0.9625, val accuracy: 0.9776, val f1: 0.8152, LR: 0.0001\n",
      "Epoch 34/50, train loss: 0.0228, val loss: 0.0251, val auc: 0.9629, val accuracy: 0.9764, val f1: 0.7958, LR: 0.0001\n",
      "Epoch 35/50, train loss: 0.0229, val loss: 0.0244, val auc: 0.9629, val accuracy: 0.9794, val f1: 0.8269, LR: 0.0001\n",
      "Epoch 36/50, train loss: 0.0230, val loss: 0.0239, val auc: 0.9632, val accuracy: 0.9773, val f1: 0.8063, LR: 0.0001\n",
      "Epoch 37/50, train loss: 0.0229, val loss: 0.0234, val auc: 0.9631, val accuracy: 0.9770, val f1: 0.8101, LR: 0.0001\n",
      "Epoch 38/50, train loss: 0.0223, val loss: 0.0234, val auc: 0.9633, val accuracy: 0.9794, val f1: 0.8269, LR: 0.0001\n",
      "Epoch 39/50, train loss: 0.0225, val loss: 0.0231, val auc: 0.9634, val accuracy: 0.9767, val f1: 0.8146, LR: 0.0001\n",
      "Epoch 40/50, train loss: 0.0222, val loss: 0.0237, val auc: 0.9629, val accuracy: 0.9797, val f1: 0.8290, LR: 0.0001\n",
      "Epoch 41/50, train loss: 0.0217, val loss: 0.0235, val auc: 0.9637, val accuracy: 0.9794, val f1: 0.8269, LR: 0.0001\n",
      "Epoch 42/50, train loss: 0.0218, val loss: 0.0228, val auc: 0.9637, val accuracy: 0.9791, val f1: 0.8247, LR: 0.0001\n",
      "Epoch 43/50, train loss: 0.0215, val loss: 0.0234, val auc: 0.9638, val accuracy: 0.9797, val f1: 0.8290, LR: 0.0001\n",
      "Epoch 44/50, train loss: 0.0218, val loss: 0.0229, val auc: 0.9631, val accuracy: 0.9794, val f1: 0.8269, LR: 0.0001\n",
      "Epoch 45/50, train loss: 0.0216, val loss: 0.0222, val auc: 0.9632, val accuracy: 0.9779, val f1: 0.8218, LR: 0.0001\n",
      "Epoch 46/50, train loss: 0.0215, val loss: 0.0221, val auc: 0.9638, val accuracy: 0.9776, val f1: 0.8206, LR: 0.0001\n",
      "Epoch 47/50, train loss: 0.0217, val loss: 0.0220, val auc: 0.9622, val accuracy: 0.9785, val f1: 0.8223, LR: 0.0001\n",
      "Epoch 48/50, train loss: 0.0204, val loss: 0.0228, val auc: 0.9633, val accuracy: 0.9797, val f1: 0.8290, LR: 0.0001\n",
      "Epoch 49/50, train loss: 0.0222, val loss: 0.0230, val auc: 0.9640, val accuracy: 0.9779, val f1: 0.8105, LR: 0.0001\n",
      "Epoch 50/50, train loss: 0.0215, val loss: 0.0219, val auc: 0.9639, val accuracy: 0.9782, val f1: 0.8229, LR: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(text_only_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(text_only_model, text_train_loader, text_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Only ROC: 0.9794025026678107, Accuracy: 0.9809406701506301, F1: 0.8495145631067962\n",
      "Text Only Accuracy: 0.9827851214263756, F1: 0.8585858585858586\n"
     ]
    }
   ],
   "source": [
    "# Evaluate text only model on test set\n",
    "y_probs = get_probs(text_only_model, text_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "text_only_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "text_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "text_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Text Only ROC: {text_only_roc}, Accuracy: {text_only_accuracy}, F1: {text_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "text_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "text_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Text Only Accuracy: {text_only_accuracy}, F1: {text_only_f1}')\n",
    "\n",
    "np.save('probs/text_only_test_probs.npy', y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Early Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_early_fusion_model = nn.Sequential(\n",
    "    nn.Linear(4096+1536, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 1),\n",
    "    # nn.Sigmoid()\n",
    ")\n",
    "\n",
    "combined_train = torch.cat((text_train, image_train), dim=1)\n",
    "combined_val = torch.cat((text_val, image_val), dim=1)\n",
    "combined_test = torch.cat((text_test, image_test), dim=1)\n",
    "\n",
    "combined_train_dataset = SimpleDataset(combined_train, y_train)\n",
    "combined_val_dataset = SimpleDataset(combined_val, y_val)\n",
    "combined_test_dataset = SimpleDataset(combined_test, y_test)\n",
    "\n",
    "combined_train_loader = DataLoader(combined_train_dataset, batch_size=32, shuffle=True)\n",
    "combined_val_loader = DataLoader(combined_val_dataset, batch_size=32, shuffle=False)\n",
    "combined_test_loader = DataLoader(combined_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0672, val loss: 0.0274, val auc: 0.9603, val accuracy: 0.9610, val f1: 0.5916, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0307, val loss: 0.0353, val auc: 0.9628, val accuracy: 0.9524, val f1: 0.4238, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0328, val loss: 0.0355, val auc: 0.9621, val accuracy: 0.9438, val f1: 0.2343, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0310, val loss: 0.0271, val auc: 0.9646, val accuracy: 0.9748, val f1: 0.7819, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0293, val loss: 0.0262, val auc: 0.9664, val accuracy: 0.9730, val f1: 0.7514, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0301, val loss: 0.0323, val auc: 0.9600, val accuracy: 0.9714, val f1: 0.7748, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0348, val loss: 0.0367, val auc: 0.9628, val accuracy: 0.9555, val f1: 0.4803, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0314, val loss: 0.0266, val auc: 0.9685, val accuracy: 0.9721, val f1: 0.7300, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0321, val loss: 0.0265, val auc: 0.9669, val accuracy: 0.9352, val f1: 0.0000, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0333, val loss: 0.0279, val auc: 0.9640, val accuracy: 0.9352, val f1: 0.0000, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0307, val loss: 0.0263, val auc: 0.9662, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0278, val loss: 0.0278, val auc: 0.9687, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0282, val loss: 0.0260, val auc: 0.9674, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0282, val loss: 0.0273, val auc: 0.9689, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0280, val loss: 0.0269, val auc: 0.9688, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0276, val loss: 0.0262, val auc: 0.9688, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0279, val loss: 0.0282, val auc: 0.9690, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0278, val loss: 0.0265, val auc: 0.9689, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0288, val loss: 0.0255, val auc: 0.9685, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0281, val loss: 0.0254, val auc: 0.9682, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0269, val loss: 0.0271, val auc: 0.9693, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0280, val loss: 0.0269, val auc: 0.9692, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0276, val loss: 0.0257, val auc: 0.9692, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0273, val loss: 0.0259, val auc: 0.9692, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0279, val loss: 0.0253, val auc: 0.9692, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0278, val loss: 0.0253, val auc: 0.9689, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0274, val loss: 0.0272, val auc: 0.9696, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0264, val loss: 0.0263, val auc: 0.9694, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0273, val loss: 0.0265, val auc: 0.9695, val accuracy: 0.9352, val f1: 0.0000, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0271, val loss: 0.0248, val auc: 0.9687, val accuracy: 0.9668, val f1: 0.6842, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0263, val loss: 0.0227, val auc: 0.9689, val accuracy: 0.9770, val f1: 0.8193, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0254, val loss: 0.0270, val auc: 0.9691, val accuracy: 0.9588, val f1: 0.5533, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0235, val loss: 0.0240, val auc: 0.9692, val accuracy: 0.9751, val f1: 0.7805, LR: 0.0001\n",
      "Epoch 34/50, train loss: 0.0237, val loss: 0.0238, val auc: 0.9690, val accuracy: 0.9751, val f1: 0.7828, LR: 0.0001\n",
      "Epoch 35/50, train loss: 0.0227, val loss: 0.0214, val auc: 0.9696, val accuracy: 0.9785, val f1: 0.8293, LR: 0.0001\n",
      "Epoch 36/50, train loss: 0.0222, val loss: 0.0227, val auc: 0.9697, val accuracy: 0.9797, val f1: 0.8281, LR: 0.0001\n",
      "Epoch 37/50, train loss: 0.0222, val loss: 0.0243, val auc: 0.9696, val accuracy: 0.9757, val f1: 0.7859, LR: 0.0001\n",
      "Epoch 38/50, train loss: 0.0199, val loss: 0.0232, val auc: 0.9698, val accuracy: 0.9757, val f1: 0.7859, LR: 0.0001\n",
      "Epoch 39/50, train loss: 0.0194, val loss: 0.0229, val auc: 0.9703, val accuracy: 0.9782, val f1: 0.8117, LR: 0.0001\n",
      "Epoch 40/50, train loss: 0.0215, val loss: 0.0209, val auc: 0.9702, val accuracy: 0.9782, val f1: 0.8229, LR: 0.0001\n",
      "Epoch 41/50, train loss: 0.0204, val loss: 0.0217, val auc: 0.9701, val accuracy: 0.9788, val f1: 0.8208, LR: 0.0001\n",
      "Epoch 42/50, train loss: 0.0203, val loss: 0.0214, val auc: 0.9702, val accuracy: 0.9764, val f1: 0.8213, LR: 0.0001\n",
      "Epoch 43/50, train loss: 0.0191, val loss: 0.0214, val auc: 0.9706, val accuracy: 0.9760, val f1: 0.7937, LR: 0.0001\n",
      "Epoch 44/50, train loss: 0.0195, val loss: 0.0213, val auc: 0.9712, val accuracy: 0.9794, val f1: 0.8251, LR: 0.0001\n",
      "Epoch 45/50, train loss: 0.0193, val loss: 0.0195, val auc: 0.9714, val accuracy: 0.9803, val f1: 0.8447, LR: 0.0001\n",
      "Epoch 46/50, train loss: 0.0191, val loss: 0.0203, val auc: 0.9715, val accuracy: 0.9782, val f1: 0.8156, LR: 0.0001\n",
      "Epoch 47/50, train loss: 0.0189, val loss: 0.0208, val auc: 0.9714, val accuracy: 0.9779, val f1: 0.8115, LR: 0.0001\n",
      "Epoch 48/50, train loss: 0.0185, val loss: 0.0215, val auc: 0.9715, val accuracy: 0.9791, val f1: 0.8220, LR: 0.0001\n",
      "Epoch 49/50, train loss: 0.0185, val loss: 0.0203, val auc: 0.9718, val accuracy: 0.9794, val f1: 0.8286, LR: 0.0001\n",
      "Epoch 50/50, train loss: 0.0187, val loss: 0.0196, val auc: 0.9719, val accuracy: 0.9794, val f1: 0.8260, LR: 0.0001\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(simple_early_fusion_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(simple_early_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Fusion ROC: 0.9869392600246637, Accuracy: 0.9837073470642483, F1: 0.8651399491094147\n",
      "Early Fusion Accuracy: 0.9833999385182908, F1: 0.864321608040201\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(simple_early_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "early_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "early_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "early_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Early Fusion ROC: {early_fusion_roc}, Accuracy: {early_fusion_accuracy}, F1: {early_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "early_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "early_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Early Fusion Accuracy: {early_fusion_accuracy}, F1: {early_fusion_f1}')\n",
    "\n",
    "np.save('probs/early_fusion_test_probs.npy', y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Late Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separate modules for text and image processing\n",
    "class TextModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class ImageModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class SimpleLateFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLateFusionModel, self).__init__()\n",
    "        self.text_module = TextModule()\n",
    "        self.image_module = ImageModule()\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_features = self.text_module(text_data)\n",
    "        image_features = self.image_module(image_data)\n",
    "        combined_features = torch.cat((text_features, image_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.output(x)\n",
    "        return x\n",
    "\n",
    "late_fusion_model = SimpleLateFusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0396, val loss: 0.0313, val auc: 0.9571, val accuracy: 0.9545, val f1: 0.4752, LR: 0.0001\n",
      "Epoch 2/50, train loss: 0.0240, val loss: 0.0280, val auc: 0.9665, val accuracy: 0.9644, val f1: 0.6258, LR: 0.0001\n",
      "Epoch 3/50, train loss: 0.0215, val loss: 0.0224, val auc: 0.9686, val accuracy: 0.9724, val f1: 0.7384, LR: 0.0001\n",
      "Epoch 4/50, train loss: 0.0189, val loss: 0.0217, val auc: 0.9704, val accuracy: 0.9770, val f1: 0.7899, LR: 0.0001\n",
      "Epoch 5/50, train loss: 0.0184, val loss: 0.0190, val auc: 0.9702, val accuracy: 0.9785, val f1: 0.8223, LR: 0.0001\n",
      "Epoch 6/50, train loss: 0.0181, val loss: 0.0261, val auc: 0.9716, val accuracy: 0.9687, val f1: 0.6832, LR: 0.0001\n",
      "Epoch 7/50, train loss: 0.0172, val loss: 0.0195, val auc: 0.9726, val accuracy: 0.9782, val f1: 0.8065, LR: 0.0001\n",
      "Epoch 8/50, train loss: 0.0159, val loss: 0.0324, val auc: 0.9725, val accuracy: 0.9678, val f1: 0.6708, LR: 0.0001\n",
      "Epoch 9/50, train loss: 0.0164, val loss: 0.0172, val auc: 0.9722, val accuracy: 0.9807, val f1: 0.8421, LR: 0.0001\n",
      "Epoch 10/50, train loss: 0.0149, val loss: 0.0261, val auc: 0.9708, val accuracy: 0.9708, val f1: 0.7974, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0143, val loss: 0.0218, val auc: 0.9730, val accuracy: 0.9782, val f1: 0.8375, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0147, val loss: 0.0177, val auc: 0.9747, val accuracy: 0.9791, val f1: 0.8162, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0146, val loss: 0.0163, val auc: 0.9750, val accuracy: 0.9819, val f1: 0.8460, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0131, val loss: 0.0185, val auc: 0.9732, val accuracy: 0.9788, val f1: 0.8130, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0139, val loss: 0.0189, val auc: 0.9748, val accuracy: 0.9800, val f1: 0.8506, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0130, val loss: 0.0173, val auc: 0.9758, val accuracy: 0.9828, val f1: 0.8571, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0117, val loss: 0.0258, val auc: 0.9765, val accuracy: 0.9767, val f1: 0.7841, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0146, val loss: 0.0213, val auc: 0.9760, val accuracy: 0.9708, val f1: 0.7147, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0129, val loss: 0.0171, val auc: 0.9764, val accuracy: 0.9794, val f1: 0.8174, LR: 1e-05\n",
      "Epoch 20/50, train loss: 0.0101, val loss: 0.0159, val auc: 0.9772, val accuracy: 0.9834, val f1: 0.8615, LR: 1e-05\n",
      "Epoch 21/50, train loss: 0.0098, val loss: 0.0155, val auc: 0.9775, val accuracy: 0.9834, val f1: 0.8629, LR: 1e-05\n",
      "Epoch 22/50, train loss: 0.0097, val loss: 0.0155, val auc: 0.9778, val accuracy: 0.9837, val f1: 0.8645, LR: 1e-05\n",
      "Epoch 23/50, train loss: 0.0096, val loss: 0.0157, val auc: 0.9778, val accuracy: 0.9837, val f1: 0.8645, LR: 1e-05\n",
      "Epoch 24/50, train loss: 0.0097, val loss: 0.0159, val auc: 0.9777, val accuracy: 0.9840, val f1: 0.8667, LR: 1e-05\n",
      "Epoch 25/50, train loss: 0.0095, val loss: 0.0158, val auc: 0.9778, val accuracy: 0.9837, val f1: 0.8691, LR: 1e-05\n",
      "Epoch 26/50, train loss: 0.0094, val loss: 0.0156, val auc: 0.9780, val accuracy: 0.9846, val f1: 0.8724, LR: 1e-05\n",
      "Epoch 27/50, train loss: 0.0094, val loss: 0.0156, val auc: 0.9779, val accuracy: 0.9840, val f1: 0.8693, LR: 1e-05\n",
      "Epoch 28/50, train loss: 0.0094, val loss: 0.0159, val auc: 0.9780, val accuracy: 0.9840, val f1: 0.8667, LR: 1.0000000000000002e-06\n",
      "Epoch 29/50, train loss: 0.0090, val loss: 0.0157, val auc: 0.9781, val accuracy: 0.9846, val f1: 0.8724, LR: 1.0000000000000002e-06\n",
      "Epoch 30/50, train loss: 0.0090, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9840, val f1: 0.8687, LR: 1.0000000000000002e-06\n",
      "Epoch 31/50, train loss: 0.0090, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-06\n",
      "Epoch 32/50, train loss: 0.0090, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-06\n",
      "Epoch 33/50, train loss: 0.0090, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9846, val f1: 0.8724, LR: 1.0000000000000002e-06\n",
      "Epoch 34/50, train loss: 0.0090, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9840, val f1: 0.8687, LR: 1.0000000000000002e-07\n",
      "Epoch 35/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-07\n",
      "Epoch 36/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-07\n",
      "Epoch 37/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-07\n",
      "Epoch 38/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-07\n",
      "Epoch 39/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-07\n",
      "Epoch 40/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 41/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 42/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 43/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 44/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 45/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 46/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 47/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 48/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 49/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n",
      "Epoch 50/50, train loss: 0.0089, val loss: 0.0156, val auc: 0.9781, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(late_fusion_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(late_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion ROC: 0.9874512951567319, Accuracy: 0.9843221641561636, F1: 0.874074074074074\n",
      "Late Fusion Accuracy: 0.9852443897940363, F1: 0.8829268292682927\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(late_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "late_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "late_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "late_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Late Fusion ROC: {late_fusion_roc}, Accuracy: {late_fusion_accuracy}, F1: {late_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "late_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "late_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Late Fusion Accuracy: {late_fusion_accuracy}, F1: {late_fusion_f1}')\n",
    "\n",
    "np.save('probs/late_fusion_test_probs.npy', y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Reshape x from [batch_size, 256] to [batch_size, 16, 16] for attention\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class TextAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionFusionModel, self).__init__()\n",
    "        self.text_attention = TextAttentionModule()\n",
    "        self.image_attention = ImageAttentionModule()\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=256, num_heads=4, batch_first=True)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_output = self.text_attention(text_data)\n",
    "        image_output = self.image_attention(image_data)\n",
    "        # combined_features = torch.cat((text_output, image_output), dim=1)\n",
    "        combined_features, _ = self.cross_attention(text_output.unsqueeze(1), image_output.unsqueeze(1), image_output.unsqueeze(1))\n",
    "        combined_features = combined_features.squeeze(1)\n",
    "        x = self.fc1(combined_features)\n",
    "\n",
    "        x = torch.relu(x)\n",
    " \n",
    "        x = self.fc2(x)\n",
    "        # x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "attention_fusion_model = AttentionFusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0567, val loss: 0.0510, val auc: 0.8974, val accuracy: 0.9367, val f1: 0.0463, LR: 0.0001\n",
      "Epoch 2/50, train loss: 0.0405, val loss: 0.0354, val auc: 0.9188, val accuracy: 0.9533, val f1: 0.5936, LR: 0.0001\n",
      "Epoch 3/50, train loss: 0.0381, val loss: 0.0376, val auc: 0.9251, val accuracy: 0.9502, val f1: 0.4130, LR: 0.0001\n",
      "Epoch 4/50, train loss: 0.0382, val loss: 0.0384, val auc: 0.9256, val accuracy: 0.9481, val f1: 0.3525, LR: 0.0001\n",
      "Epoch 5/50, train loss: 0.0362, val loss: 0.0352, val auc: 0.9322, val accuracy: 0.9582, val f1: 0.6402, LR: 0.0001\n",
      "Epoch 6/50, train loss: 0.0340, val loss: 0.0335, val auc: 0.9330, val accuracy: 0.9582, val f1: 0.5641, LR: 0.0001\n",
      "Epoch 7/50, train loss: 0.0333, val loss: 0.0311, val auc: 0.9369, val accuracy: 0.9619, val f1: 0.6517, LR: 0.0001\n",
      "Epoch 8/50, train loss: 0.0324, val loss: 0.0313, val auc: 0.9374, val accuracy: 0.9598, val f1: 0.6431, LR: 0.0001\n",
      "Epoch 9/50, train loss: 0.0316, val loss: 0.0302, val auc: 0.9414, val accuracy: 0.9610, val f1: 0.6631, LR: 0.0001\n",
      "Epoch 10/50, train loss: 0.0310, val loss: 0.0305, val auc: 0.9421, val accuracy: 0.9628, val f1: 0.6409, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0302, val loss: 0.0370, val auc: 0.9436, val accuracy: 0.9573, val f1: 0.5157, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0303, val loss: 0.0307, val auc: 0.9435, val accuracy: 0.9631, val f1: 0.6226, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0293, val loss: 0.0301, val auc: 0.9460, val accuracy: 0.9622, val f1: 0.6070, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0292, val loss: 0.0303, val auc: 0.9442, val accuracy: 0.9619, val f1: 0.6000, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0294, val loss: 0.0316, val auc: 0.9444, val accuracy: 0.9607, val f1: 0.5705, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0291, val loss: 0.0297, val auc: 0.9466, val accuracy: 0.9622, val f1: 0.6737, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0282, val loss: 0.0283, val auc: 0.9481, val accuracy: 0.9641, val f1: 0.6569, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0275, val loss: 0.0281, val auc: 0.9488, val accuracy: 0.9644, val f1: 0.6628, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0274, val loss: 0.0332, val auc: 0.9489, val accuracy: 0.9555, val f1: 0.4876, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0272, val loss: 0.0300, val auc: 0.9480, val accuracy: 0.9631, val f1: 0.6178, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0270, val loss: 0.0304, val auc: 0.9519, val accuracy: 0.9625, val f1: 0.6090, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0265, val loss: 0.0270, val auc: 0.9524, val accuracy: 0.9659, val f1: 0.6819, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0269, val loss: 0.0280, val auc: 0.9508, val accuracy: 0.9647, val f1: 0.6505, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0254, val loss: 0.0279, val auc: 0.9499, val accuracy: 0.9635, val f1: 0.6877, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0248, val loss: 0.0271, val auc: 0.9532, val accuracy: 0.9653, val f1: 0.6523, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0251, val loss: 0.0401, val auc: 0.9528, val accuracy: 0.9585, val f1: 0.5329, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0260, val loss: 0.0289, val auc: 0.9524, val accuracy: 0.9665, val f1: 0.6785, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0254, val loss: 0.0273, val auc: 0.9535, val accuracy: 0.9656, val f1: 0.6606, LR: 1e-05\n",
      "Epoch 29/50, train loss: 0.0221, val loss: 0.0267, val auc: 0.9533, val accuracy: 0.9650, val f1: 0.6761, LR: 1e-05\n",
      "Epoch 30/50, train loss: 0.0216, val loss: 0.0266, val auc: 0.9543, val accuracy: 0.9644, val f1: 0.6647, LR: 1e-05\n",
      "Epoch 31/50, train loss: 0.0208, val loss: 0.0271, val auc: 0.9545, val accuracy: 0.9635, val f1: 0.6590, LR: 1e-05\n",
      "Epoch 32/50, train loss: 0.0208, val loss: 0.0267, val auc: 0.9545, val accuracy: 0.9650, val f1: 0.6647, LR: 1e-05\n",
      "Epoch 33/50, train loss: 0.0205, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9653, val f1: 0.6586, LR: 1e-05\n",
      "Epoch 34/50, train loss: 0.0207, val loss: 0.0264, val auc: 0.9543, val accuracy: 0.9656, val f1: 0.6906, LR: 1e-05\n",
      "Epoch 35/50, train loss: 0.0206, val loss: 0.0271, val auc: 0.9546, val accuracy: 0.9650, val f1: 0.6587, LR: 1e-05\n",
      "Epoch 36/50, train loss: 0.0203, val loss: 0.0264, val auc: 0.9543, val accuracy: 0.9662, val f1: 0.6784, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0202, val loss: 0.0276, val auc: 0.9547, val accuracy: 0.9650, val f1: 0.6566, LR: 1e-05\n",
      "Epoch 38/50, train loss: 0.0200, val loss: 0.0270, val auc: 0.9544, val accuracy: 0.9656, val f1: 0.6744, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0198, val loss: 0.0278, val auc: 0.9545, val accuracy: 0.9635, val f1: 0.6383, LR: 1e-05\n",
      "Epoch 40/50, train loss: 0.0201, val loss: 0.0268, val auc: 0.9542, val accuracy: 0.9647, val f1: 0.6686, LR: 1.0000000000000002e-06\n",
      "Epoch 41/50, train loss: 0.0192, val loss: 0.0275, val auc: 0.9543, val accuracy: 0.9638, val f1: 0.6424, LR: 1.0000000000000002e-06\n",
      "Epoch 42/50, train loss: 0.0191, val loss: 0.0272, val auc: 0.9543, val accuracy: 0.9647, val f1: 0.6588, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0192, val loss: 0.0275, val auc: 0.9544, val accuracy: 0.9638, val f1: 0.6424, LR: 1.0000000000000002e-06\n",
      "Epoch 44/50, train loss: 0.0192, val loss: 0.0274, val auc: 0.9544, val accuracy: 0.9638, val f1: 0.6424, LR: 1.0000000000000002e-06\n",
      "Epoch 45/50, train loss: 0.0196, val loss: 0.0271, val auc: 0.9544, val accuracy: 0.9647, val f1: 0.6547, LR: 1.0000000000000002e-06\n",
      "Epoch 46/50, train loss: 0.0193, val loss: 0.0275, val auc: 0.9545, val accuracy: 0.9638, val f1: 0.6424, LR: 1.0000000000000002e-07\n",
      "Epoch 47/50, train loss: 0.0193, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9638, val f1: 0.6424, LR: 1.0000000000000002e-07\n",
      "Epoch 48/50, train loss: 0.0190, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9638, val f1: 0.6424, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0193, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9641, val f1: 0.6465, LR: 1.0000000000000002e-07\n",
      "Epoch 50/50, train loss: 0.0187, val loss: 0.0273, val auc: 0.9544, val accuracy: 0.9641, val f1: 0.6465, LR: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(attention_fusion_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(attention_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Fusion ROC: 0.9537507726656272, Accuracy: 0.9640332001229635, F1: 0.6507462686567165\n",
      "Attention Fusion Accuracy: 0.9637257915770059, F1: 0.7293577981651376\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(attention_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "attention_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "attention_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "attention_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Attention Fusion ROC: {attention_fusion_roc}, Accuracy: {attention_fusion_accuracy}, F1: {attention_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "attention_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "attention_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Attention Fusion Accuracy: {attention_fusion_accuracy}, F1: {attention_fusion_f1}')\n",
    "\n",
    "np.save('probs/attention_fusion_test_probs.npy', y_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
