{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_embed = pd.read_csv('embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_names = brset_embed.columns[brset_embed.columns.str.match('text_\\d+')]\n",
    "image_column_names = brset_embed.columns[brset_embed.columns.str.match('image_\\d+')]\n",
    "text_columns = brset_embed[text_column_names]\n",
    "image_columns = brset_embed[image_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = torch.tensor(text_columns.values)\n",
    "image_embed = torch.tensor(image_columns.values)\n",
    "y = torch.tensor(brset_embed['DR_2'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_model = nn.Sequential(\n",
    "    nn.Linear(4096, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    # nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text_embed into train and test based on brset_embed['split']\n",
    "train_idx = brset_embed[brset_embed['split'] == 'train'].index\n",
    "test_idx = brset_embed[brset_embed['split'] == 'test'].index\n",
    "\n",
    "text_train = text_embed[train_idx]\n",
    "text_test = text_embed[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset and dataloader for text only\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "text_train_dataset = SimpleDataset(text_train, y_train)\n",
    "text_test_dataset = SimpleDataset(text_test, y_test)\n",
    "\n",
    "text_train_loader = DataLoader(text_train_dataset, batch_size=32, shuffle=True)\n",
    "text_test_loader = DataLoader(text_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        epoch_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        # Probably would be more meaningful to use a validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_hat = torch.tensor([]).to(device)\n",
    "            y_true = torch.tensor([]).to(device)\n",
    "            for X, y in test_loader:\n",
    "                X = X.to(device).float()\n",
    "                y = y.to(device).float()\n",
    "                y_hat = torch.cat((y_hat, model(X)))\n",
    "                y_true = torch.cat((y_true, y.unsqueeze(1)))\n",
    "            auc = roc_auc_score(y_true.cpu().numpy(), y_hat.cpu().numpy())\n",
    "            accuracy = accuracy_score(y_true.cpu().numpy(), y_hat.cpu().numpy() > 0.5)\n",
    "            f1 = f1_score(y_true.cpu().numpy(), y_hat.cpu().numpy() > 0.5)\n",
    "            print(f'Epoch {epoch} Loss: {epoch_loss}, AUC: {auc}, Accuracy: {accuracy}, F1: {f1}')\n",
    "\n",
    "def get_predicted_probs(model, loader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    y_hat = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for X,_ in loader:\n",
    "            X = X.to(device).float()\n",
    "            y_hat = torch.cat((y_hat, model(X)))\n",
    "    return y_hat.cpu().numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doug/miniconda3/envs/mit-ml/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2601.4479944936684, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 1 Loss: 2639.5737512111664, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 2 Loss: 2640.5594022274017, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 3 Loss: 2635.1970212459564, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 4 Loss: 2635.176661968231, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 5 Loss: 2639.4062683582306, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 6 Loss: 2640.1730177402496, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 7 Loss: 2638.8391065597534, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 8 Loss: 2641.0860862731934, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 9 Loss: 2636.728802919388, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 10 Loss: 2637.664505958557, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 11 Loss: 2635.28834605217, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 12 Loss: 2638.769811630249, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 13 Loss: 2637.8734765052795, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 14 Loss: 2641.9643218517303, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 15 Loss: 2639.563991546631, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 16 Loss: 2646.1285004615784, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 17 Loss: 2638.76451587677, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 18 Loss: 2635.608414888382, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n",
      "Epoch 19 Loss: 2641.8406326770782, AUC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(text_only_model.parameters(), lr=0.001)\n",
    "train(text_only_model, text_train_loader, text_test_loader, criterion, optimizer, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Only ROC: 0.5, Accuracy: 0.9351567301782422, F1: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate text only model on test set\n",
    "y_pred_probs = get_predicted_probs(text_only_model, text_test_loader)\n",
    "y_preds = (np.array(y_pred_probs) > 0.5).astype(int)\n",
    "text_only_roc = roc_auc_score(y_test.numpy(), y_pred_probs)\n",
    "text_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "text_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Text Only ROC: {text_only_roc}, Accuracy: {text_only_accuracy}, F1: {text_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train image only model\n",
    "image_only_model = nn.Sequential(\n",
    "    nn.Linear(1536, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "image_train = image_embed[train_idx]\n",
    "image_test = image_embed[test_idx]\n",
    "\n",
    "image_train_dataset = SimpleDataset(image_train, y_train)\n",
    "image_test_dataset = SimpleDataset(image_test, y_test)\n",
    "\n",
    "image_train_loader = DataLoader(image_train_dataset, batch_size=32, shuffle=True)\n",
    "image_test_loader = DataLoader(image_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 76.19346247427166, AUC: 0.926287197873139, Accuracy: 0.9520590043023971, F1: 0.472972972972973\n",
      "Epoch 1 Loss: 60.208522813394666, AUC: 0.9332334485331107, Accuracy: 0.9557467732022127, F1: 0.5443037974683544\n",
      "Epoch 2 Loss: 58.06787451263517, AUC: 0.9370445416642657, Accuracy: 0.9511370620774432, F1: 0.4341637010676156\n",
      "Epoch 3 Loss: 56.007340430282056, AUC: 0.9394305631914128, Accuracy: 0.96220036877689, F1: 0.6434782608695652\n",
      "Epoch 4 Loss: 51.650988567620516, AUC: 0.9434597000652573, Accuracy: 0.9600491702519975, F1: 0.6036585365853658\n",
      "Epoch 5 Loss: 50.063370938878506, AUC: 0.9404351218630904, Accuracy: 0.9631223110018439, F1: 0.6511627906976745\n",
      "Epoch 6 Loss: 48.70467131724581, AUC: 0.9451261772415287, Accuracy: 0.9631223110018439, F1: 0.6685082872928176\n",
      "Epoch 7 Loss: 47.15485030040145, AUC: 0.9458644110560637, Accuracy: 0.9652735095267363, F1: 0.6869806094182825\n",
      "Epoch 8 Loss: 48.07534423749894, AUC: 0.9480432910276557, Accuracy: 0.96220036877689, F1: 0.6328358208955224\n",
      "Epoch 9 Loss: 46.95225043222308, AUC: 0.9459633094679264, Accuracy: 0.9615857406269207, F1: 0.6246246246246246\n",
      "Epoch 10 Loss: 48.03362945350818, AUC: 0.9444938503877285, Accuracy: 0.9603564843269822, F1: 0.603076923076923\n",
      "Epoch 11 Loss: 44.76028069900349, AUC: 0.9468019991496294, Accuracy: 0.9668100799016595, F1: 0.6878612716763005\n",
      "Epoch 12 Loss: 45.84252367797308, AUC: 0.9508560553083527, Accuracy: 0.9637369391518131, F1: 0.6358024691358025\n",
      "Epoch 13 Loss: 44.41063619009219, AUC: 0.9521020195522938, Accuracy: 0.9634296250768285, F1: 0.7061728395061728\n",
      "Epoch 14 Loss: 42.50084997259546, AUC: 0.952036606429487, Accuracy: 0.9665027658266748, F1: 0.7108753315649868\n",
      "Epoch 15 Loss: 41.511125633027405, AUC: 0.9516815066199639, Accuracy: 0.9671173939766441, F1: 0.6985915492957746\n",
      "Epoch 16 Loss: 43.46723024896346, AUC: 0.9521721050410156, Accuracy: 0.9668100799016595, F1: 0.6983240223463688\n",
      "Epoch 17 Loss: 43.041582859354094, AUC: 0.9505663686216366, Accuracy: 0.9594345421020283, F1: 0.6972477064220184\n",
      "Epoch 18 Loss: 43.20269549591467, AUC: 0.9493453236625742, Accuracy: 0.9637369391518131, F1: 0.6424242424242425\n",
      "Epoch 19 Loss: 41.666266383603215, AUC: 0.9517952008572232, Accuracy: 0.9569760295021512, F1: 0.6929824561403508\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(image_only_model.parameters(), lr=0.001)\n",
    "train(image_only_model, image_train_loader, image_test_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Only ROC: 0.9517952008572232, Accuracy: 0.9569760295021512, F1: 0.6929824561403508\n"
     ]
    }
   ],
   "source": [
    "# Evaluate image only model on test set\n",
    "y_pred_probs = get_predicted_probs(image_only_model, image_test_loader)\n",
    "y_preds = (np.array(y_pred_probs) > 0.5).astype(int)\n",
    "image_only_roc = roc_auc_score(y_test.numpy(), y_pred_probs)\n",
    "image_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "image_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Image Only ROC: {image_only_roc}, Accuracy: {image_only_accuracy}, F1: {image_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Early Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_early_fusion_model = nn.Sequential(\n",
    "    nn.Linear(4096+1536, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "combined_train = torch.cat((text_train, image_train), dim=1)\n",
    "combined_test = torch.cat((text_test, image_test), dim=1)\n",
    "\n",
    "combined_train_dataset = SimpleDataset(combined_train, y_train)\n",
    "combined_test_dataset = SimpleDataset(combined_test, y_test)\n",
    "\n",
    "combined_train_loader = DataLoader(combined_train_dataset, batch_size=32, shuffle=True)\n",
    "combined_test_loader = DataLoader(combined_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 67.18348330259323, AUC: 0.9691468104094083, Accuracy: 0.9711124769514444, F1: 0.756476683937824\n",
      "Epoch 1 Loss: 41.87031468027271, AUC: 0.9759248558964481, Accuracy: 0.9726490473263676, F1: 0.7464387464387465\n",
      "Epoch 2 Loss: 34.91454142378643, AUC: 0.9787220456240957, Accuracy: 0.9708051628764598, F1: 0.7181008902077153\n",
      "Epoch 3 Loss: 31.292649308452383, AUC: 0.9798963669240102, Accuracy: 0.9772587584511371, F1: 0.7944444444444444\n",
      "Epoch 4 Loss: 30.941961539559998, AUC: 0.9806392731044601, Accuracy: 0.9800245851259988, F1: 0.8228882833787466\n",
      "Epoch 5 Loss: 28.34704295359552, AUC: 0.9811205267936823, Accuracy: 0.9837123540258144, F1: 0.8651399491094148\n",
      "Epoch 6 Loss: 28.188363395864144, AUC: 0.9806159112748862, Accuracy: 0.9830977258758451, F1: 0.8655256723716381\n",
      "Epoch 7 Loss: 26.849562769173644, AUC: 0.9818307264127288, Accuracy: 0.9800245851259988, F1: 0.8209366391184573\n",
      "Epoch 8 Loss: 27.01791507669259, AUC: 0.981466281871376, Accuracy: 0.984019668100799, F1: 0.8706467661691543\n",
      "Epoch 9 Loss: 27.485816622211132, AUC: 0.9805816472581778, Accuracy: 0.9830977258758451, F1: 0.8556430446194225\n",
      "Epoch 10 Loss: 26.51939271297306, AUC: 0.9823509164845742, Accuracy: 0.9775660725261217, F1: 0.7943661971830986\n",
      "Epoch 11 Loss: 24.23882714379579, AUC: 0.9816500615973572, Accuracy: 0.9849416103257529, F1: 0.8740359897172237\n",
      "Epoch 12 Loss: 23.634390430524945, AUC: 0.98201762104932, Accuracy: 0.9849416103257529, F1: 0.8746803069053708\n",
      "Epoch 13 Loss: 24.907087282830616, AUC: 0.9825923220568378, Accuracy: 0.9846342962507683, F1: 0.8730964467005076\n",
      "Epoch 14 Loss: 25.200197853147984, AUC: 0.9819911443091361, Accuracy: 0.9787953288260602, F1: 0.8099173553719008\n",
      "Epoch 15 Loss: 23.565980303566903, AUC: 0.9831607932431359, Accuracy: 0.9830977258758451, F1: 0.8541114058355437\n",
      "Epoch 16 Loss: 23.62665906944312, AUC: 0.9831545634219162, Accuracy: 0.9846342962507683, F1: 0.8749999999999999\n",
      "Epoch 17 Loss: 23.874824619095307, AUC: 0.9831202994052078, Accuracy: 0.9846342962507683, F1: 0.8724489795918368\n",
      "Epoch 18 Loss: 23.010513107059523, AUC: 0.9833866242623502, Accuracy: 0.9846342962507683, F1: 0.8743718592964824\n",
      "Epoch 19 Loss: 22.682084002764896, AUC: 0.9841778115572528, Accuracy: 0.9741856177012908, F1: 0.7543859649122807\n",
      "Epoch 20 Loss: 22.572773775435053, AUC: 0.9839036994235858, Accuracy: 0.9815611555009219, F1: 0.8378378378378379\n",
      "Epoch 21 Loss: 23.11264659720473, AUC: 0.9830252946316073, Accuracy: 0.9837123540258144, F1: 0.8747044917257683\n",
      "Epoch 22 Loss: 22.265193971805274, AUC: 0.9841513348170691, Accuracy: 0.9846342962507683, F1: 0.8691099476439791\n",
      "Epoch 23 Loss: 21.56625598296523, AUC: 0.9821655793032879, Accuracy: 0.9849416103257529, F1: 0.8765743073047859\n",
      "Epoch 24 Loss: 21.19463250914123, AUC: 0.9838118095605952, Accuracy: 0.9843269821757836, F1: 0.8734491315136476\n",
      "Epoch 25 Loss: 21.75081259640865, AUC: 0.9845079920818972, Accuracy: 0.9849416103257529, F1: 0.8733850129198967\n",
      "Epoch 26 Loss: 21.5621720959316, AUC: 0.9845173368137267, Accuracy: 0.9843269821757836, F1: 0.8740740740740741\n",
      "Epoch 27 Loss: 22.569985649955925, AUC: 0.9823882954118923, Accuracy: 0.9800245851259988, F1: 0.8539325842696629\n",
      "Epoch 28 Loss: 21.073337737703696, AUC: 0.9839192739766351, Accuracy: 0.9849416103257529, F1: 0.8765743073047859\n",
      "Epoch 29 Loss: 21.274000525241718, AUC: 0.9841170708003607, Accuracy: 0.9821757836508912, F1: 0.8657407407407407\n",
      "Epoch 30 Loss: 20.722943438449875, AUC: 0.9854564823625975, Accuracy: 0.9855562384757222, F1: 0.8816120906801008\n",
      "Epoch 31 Loss: 20.242779084597714, AUC: 0.9851387614803924, Accuracy: 0.9855562384757222, F1: 0.8791773778920309\n",
      "Epoch 32 Loss: 20.266693294979632, AUC: 0.9846793121654391, Accuracy: 0.9834050399508297, F1: 0.8689320388349515\n",
      "Epoch 33 Loss: 20.858426244696602, AUC: 0.9851652382205762, Accuracy: 0.9855562384757222, F1: 0.8804071246819339\n",
      "Epoch 34 Loss: 20.749360836751293, AUC: 0.9856729686499821, Accuracy: 0.9858635525507068, F1: 0.8826530612244898\n",
      "Epoch 35 Loss: 20.23223417927511, AUC: 0.9857788756107172, Accuracy: 0.9738783036263061, F1: 0.7521865889212828\n",
      "Epoch 36 Loss: 19.64069445442874, AUC: 0.9860576601102989, Accuracy: 0.9849416103257529, F1: 0.8740359897172237\n",
      "Epoch 37 Loss: 20.635139041522052, AUC: 0.9845687328387894, Accuracy: 0.9834050399508297, F1: 0.8738317757009346\n",
      "Epoch 38 Loss: 19.863644054858014, AUC: 0.9843382294536602, Accuracy: 0.980639213275968, F1: 0.8545034642032333\n",
      "Epoch 39 Loss: 20.712882240855834, AUC: 0.985926833864685, Accuracy: 0.9852489244007375, F1: 0.8762886597938144\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(simple_early_fusion_model.parameters(), lr=0.0001)\n",
    "train(simple_early_fusion_model, combined_train_loader, combined_test_loader, criterion, optimizer, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Fusion ROC: 0.985926833864685, Accuracy: 0.9852489244007375, F1: 0.8762886597938144\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = get_predicted_probs(simple_early_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_pred_probs) > 0.5).astype(int)\n",
    "early_fusion_roc = roc_auc_score(y_test.numpy(), y_pred_probs)\n",
    "early_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "early_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Early Fusion ROC: {early_fusion_roc}, Accuracy: {early_fusion_accuracy}, F1: {early_fusion_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Late Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separate modules for text and image processing\n",
    "class TextModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class ImageModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class SimpleLateFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLateFusionModel, self).__init__()\n",
    "        self.text_module = TextModule()\n",
    "        self.image_module = ImageModule()\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_features = self.text_module(text_data)\n",
    "        image_features = self.image_module(image_data)\n",
    "        combined_features = torch.cat((text_features, image_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and configure the model, criterion, and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 68.11527671851218, AUC: 0.9675286143475899, Accuracy: 0.9572833435771358, F1: 0.5223367697594502\n",
      "Epoch 1 Loss: 40.441093879169784, AUC: 0.9777564233350413, Accuracy: 0.9711124769514444, F1: 0.7235294117647059\n",
      "Epoch 2 Loss: 32.83470815431792, AUC: 0.9789307446349559, Accuracy: 0.9827904118008605, F1: 0.8541666666666667\n",
      "Epoch 3 Loss: 27.80017889046576, AUC: 0.9812840596006995, Accuracy: 0.9846342962507683, F1: 0.8743718592964824\n",
      "Epoch 4 Loss: 28.721639645773394, AUC: 0.9806221410961059, Accuracy: 0.9837123540258144, F1: 0.8637532133676094\n",
      "Epoch 5 Loss: 26.776782686880324, AUC: 0.9816687510610163, Accuracy: 0.9843269821757836, F1: 0.8740740740740741\n",
      "Epoch 6 Loss: 26.23835004295688, AUC: 0.9810706882239246, Accuracy: 0.9815611555009219, F1: 0.853658536585366\n",
      "Epoch 7 Loss: 23.18979552714154, AUC: 0.9825876496909232, Accuracy: 0.9837123540258144, F1: 0.8608923884514436\n",
      "Epoch 8 Loss: 24.209635002858704, AUC: 0.9825549431295195, Accuracy: 0.9824830977258758, F1: 0.8633093525179856\n",
      "Epoch 9 Loss: 22.27527061814908, AUC: 0.982142217473714, Accuracy: 0.9852489244007375, F1: 0.876923076923077\n",
      "Epoch 10 Loss: 22.04837089648936, AUC: 0.9821484472949338, Accuracy: 0.9852489244007375, F1: 0.8781725888324874\n",
      "Epoch 11 Loss: 22.3508227764396, AUC: 0.9829754560618497, Accuracy: 0.9858635525507068, F1: 0.8838383838383838\n",
      "Epoch 12 Loss: 20.905430537299253, AUC: 0.9831561208772212, Accuracy: 0.9843269821757836, F1: 0.8675324675324675\n",
      "Epoch 13 Loss: 21.630937964539044, AUC: 0.9830393117293516, Accuracy: 0.9837123540258144, F1: 0.8601583113456465\n",
      "Epoch 14 Loss: 20.645083286683075, AUC: 0.9839535379933434, Accuracy: 0.9852489244007375, F1: 0.8781725888324874\n",
      "Epoch 15 Loss: 21.18605170585215, AUC: 0.9836669662172369, Accuracy: 0.980639213275968, F1: 0.8273972602739725\n",
      "Epoch 16 Loss: 20.060972115956247, AUC: 0.9843989702105523, Accuracy: 0.9861708666256914, F1: 0.8866498740554156\n",
      "Epoch 17 Loss: 19.98818879236933, AUC: 0.9834925312230852, Accuracy: 0.9855562384757222, F1: 0.8822055137844612\n",
      "Epoch 18 Loss: 18.656520868826192, AUC: 0.9825923220568378, Accuracy: 0.9834050399508297, F1: 0.8701923076923077\n",
      "Epoch 19 Loss: 19.067547841346823, AUC: 0.9836186851027843, Accuracy: 0.9846342962507683, F1: 0.8743718592964824\n",
      "Epoch 20 Loss: 19.447657967320993, AUC: 0.9827916763358683, Accuracy: 0.984019668100799, F1: 0.8712871287128713\n",
      "Epoch 21 Loss: 17.943379398959223, AUC: 0.9841669093701183, Accuracy: 0.9855562384757222, F1: 0.8804071246819339\n",
      "Epoch 22 Loss: 18.912901999632595, AUC: 0.9820783618062121, Accuracy: 0.9824830977258758, F1: 0.8471849865951743\n",
      "Epoch 23 Loss: 18.60333114414243, AUC: 0.9829334047686167, Accuracy: 0.9741856177012908, F1: 0.7558139534883721\n",
      "Epoch 24 Loss: 17.567701203224715, AUC: 0.9841513348170691, Accuracy: 0.9855562384757222, F1: 0.8822055137844612\n",
      "Epoch 25 Loss: 17.970536482229363, AUC: 0.9852493408070422, Accuracy: 0.984019668100799, F1: 0.8624338624338623\n",
      "Epoch 26 Loss: 17.541973579704063, AUC: 0.9850297396090476, Accuracy: 0.9858635525507068, F1: 0.8872549019607844\n",
      "Epoch 27 Loss: 17.59635624202201, AUC: 0.9848802238997746, Accuracy: 0.9834050399508297, F1: 0.8601036269430051\n",
      "Epoch 28 Loss: 18.104223239177372, AUC: 0.985929948775295, Accuracy: 0.9846342962507683, F1: 0.8792270531400966\n",
      "Epoch 29 Loss: 17.99042716558324, AUC: 0.9854455801754629, Accuracy: 0.9846342962507683, F1: 0.8786407766990291\n",
      "Epoch 30 Loss: 16.239284551644232, AUC: 0.9844145447636017, Accuracy: 0.9858635525507068, F1: 0.8855721393034826\n",
      "Epoch 31 Loss: 16.25036833237391, AUC: 0.9845126644478119, Accuracy: 0.9867854947756607, F1: 0.8938271604938273\n",
      "Epoch 32 Loss: 16.537149234121898, AUC: 0.9837728731779719, Accuracy: 0.9800245851259988, F1: 0.8526077097505669\n",
      "Epoch 33 Loss: 16.31930942222243, AUC: 0.9844363491378706, Accuracy: 0.9760295021511985, F1: 0.7771428571428571\n",
      "Epoch 34 Loss: 16.231828783871606, AUC: 0.985233766253993, Accuracy: 0.9858635525507068, F1: 0.8826530612244898\n",
      "Epoch 35 Loss: 16.02921059972141, AUC: 0.9858287141804749, Accuracy: 0.9861708666256914, F1: 0.8843187660668379\n",
      "Epoch 36 Loss: 15.503332350344863, AUC: 0.9852633579047865, Accuracy: 0.9870928088506453, F1: 0.8944723618090453\n",
      "Epoch 37 Loss: 15.434469692001585, AUC: 0.985506320932355, Accuracy: 0.9870928088506453, F1: 0.8960396039603962\n",
      "Epoch 38 Loss: 15.752964857820189, AUC: 0.9861339754202404, Accuracy: 0.986478180700676, F1: 0.891089108910891\n",
      "Epoch 39 Loss: 14.486601830663858, AUC: 0.9836607363960173, Accuracy: 0.9830977258758451, F1: 0.8705882352941177\n"
     ]
    }
   ],
   "source": [
    "late_fusion_model = SimpleLateFusionModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(late_fusion_model.parameters(), lr=0.0001)\n",
    "train(late_fusion_model, combined_train_loader, combined_test_loader, criterion, optimizer, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion ROC: 0.9836607363960173, Accuracy: 0.9830977258758451, F1: 0.8705882352941177\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = get_predicted_probs(late_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_pred_probs) > 0.5).astype(int)\n",
    "late_fusion_roc = roc_auc_score(y_test.numpy(), y_pred_probs)\n",
    "late_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "late_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Late Fusion ROC: {late_fusion_roc}, Accuracy: {late_fusion_accuracy}, F1: {late_fusion_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Reshape x from [batch_size, 256] to [batch_size, 16, 16] for attention\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class TextAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionFusionModel, self).__init__()\n",
    "        self.text_attention = TextAttentionModule()\n",
    "        self.image_attention = ImageAttentionModule()\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=256, num_heads=4, batch_first=True)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_output = self.text_attention(text_data)\n",
    "        image_output = self.image_attention(image_data)\n",
    "        # combined_features = torch.cat((text_output, image_output), dim=1)\n",
    "        combined_features, _ = self.cross_attention(text_output.unsqueeze(1), image_output.unsqueeze(1), image_output.unsqueeze(1))\n",
    "        combined_features = combined_features.squeeze(1)\n",
    "        x = self.fc1(combined_features)\n",
    "\n",
    "        x = torch.relu(x)\n",
    " \n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 93.73704588413239, AUC: 0.8956224603744434, Accuracy: 0.9363859864781807, F1: 0.08810572687224669\n",
      "Epoch 1 Loss: 65.28769809193909, AUC: 0.925480436025187, Accuracy: 0.9594345421020283, F1: 0.6271186440677966\n",
      "Epoch 2 Loss: 59.690624251030385, AUC: 0.9321494596408819, Accuracy: 0.9557467732022127, F1: 0.5414012738853504\n",
      "Epoch 3 Loss: 55.741092530079186, AUC: 0.9356490617110516, Accuracy: 0.958819913952059, F1: 0.5838509316770186\n",
      "Epoch 4 Loss: 52.87391759082675, AUC: 0.9353500302925056, Accuracy: 0.9591272280270436, F1: 0.5777777777777778\n",
      "Epoch 5 Loss: 50.79753237683326, AUC: 0.9400519878580785, Accuracy: 0.9532882606023356, F1: 0.45714285714285713\n",
      "Epoch 6 Loss: 49.525770098902285, AUC: 0.9426825298680991, Accuracy: 0.9560540872771973, F1: 0.5051903114186852\n",
      "Epoch 7 Loss: 46.95384145854041, AUC: 0.9418897851178916, Accuracy: 0.9532882606023356, F1: 0.4492753623188405\n",
      "Epoch 8 Loss: 47.327771314419806, AUC: 0.9458270321287454, Accuracy: 0.9640442532267978, F1: 0.6666666666666666\n",
      "Epoch 9 Loss: 45.59369652532041, AUC: 0.9429021310660937, Accuracy: 0.9514443761524278, F1: 0.4191176470588235\n",
      "Epoch 10 Loss: 44.326877393526956, AUC: 0.945985892569848, Accuracy: 0.964658881376767, F1: 0.6723646723646725\n",
      "Epoch 11 Loss: 43.52077078609727, AUC: 0.9475184285898954, Accuracy: 0.9652735095267363, F1: 0.6780626780626781\n",
      "Epoch 12 Loss: 43.579933484084904, AUC: 0.9445343442256566, Accuracy: 0.9606637984019668, F1: 0.6\n",
      "Epoch 13 Loss: 42.47033233125694, AUC: 0.9492160548722652, Accuracy: 0.9652735095267363, F1: 0.7139240506329115\n",
      "Epoch 14 Loss: 41.198472388321534, AUC: 0.9464858357227294, Accuracy: 0.9628149969268592, F1: 0.6366366366366366\n",
      "Epoch 15 Loss: 41.110961706377566, AUC: 0.9476290079165453, Accuracy: 0.9674247080516287, F1: 0.6988636363636362\n",
      "Epoch 16 Loss: 40.65769160282798, AUC: 0.9469826639650009, Accuracy: 0.9637369391518131, F1: 0.6424242424242425\n",
      "Epoch 17 Loss: 40.85867452912498, AUC: 0.9510351626684194, Accuracy: 0.964658881376767, F1: 0.6627565982404693\n",
      "Epoch 18 Loss: 38.42449125042185, AUC: 0.9526362267218837, Accuracy: 0.9640442532267978, F1: 0.6422018348623854\n",
      "Epoch 19 Loss: 38.78675319388276, AUC: 0.9479700906283242, Accuracy: 0.9618930547019053, F1: 0.6075949367088608\n",
      "Epoch 20 Loss: 39.7457924017217, AUC: 0.9509027789675006, Accuracy: 0.9671173939766441, F1: 0.69164265129683\n",
      "Epoch 21 Loss: 38.55279458547011, AUC: 0.9506286668338335, Accuracy: 0.968039336201598, F1: 0.7094972067039107\n",
      "Epoch 22 Loss: 37.54939082916826, AUC: 0.9507719527218867, Accuracy: 0.9683466502765826, F1: 0.7223719676549866\n",
      "Epoch 23 Loss: 37.41915011592209, AUC: 0.9495540226734343, Accuracy: 0.9655808236017209, F1: 0.6646706586826348\n",
      "Epoch 24 Loss: 38.139211309258826, AUC: 0.952799759528901, Accuracy: 0.9658881376767056, F1: 0.7086614173228346\n",
      "Epoch 25 Loss: 37.06317554740235, AUC: 0.9523808040518758, Accuracy: 0.9683466502765826, F1: 0.711484593837535\n",
      "Epoch 26 Loss: 36.336376453517005, AUC: 0.9524306426216333, Accuracy: 0.9665027658266748, F1: 0.6765578635014837\n",
      "Epoch 27 Loss: 36.60027108201757, AUC: 0.9532288384654081, Accuracy: 0.9671173939766441, F1: 0.7206266318537858\n",
      "Epoch 28 Loss: 36.78524993988685, AUC: 0.9517702815723447, Accuracy: 0.9689612784265519, F1: 0.7170868347338936\n",
      "Epoch 29 Loss: 37.374963224865496, AUC: 0.9513575559165391, Accuracy: 0.956361401352182, F1: 0.5069444444444444\n",
      "Epoch 30 Loss: 34.84417710546404, AUC: 0.9536548024913055, Accuracy: 0.9655808236017209, F1: 0.711340206185567\n",
      "Epoch 31 Loss: 35.885941134998575, AUC: 0.9510803288722622, Accuracy: 0.9686539643515673, F1: 0.7052023121387282\n",
      "Epoch 32 Loss: 34.71872083470225, AUC: 0.9511971380201316, Accuracy: 0.9692685925015365, F1: 0.7142857142857143\n",
      "Epoch 33 Loss: 33.61771313601639, AUC: 0.9530520672882989, Accuracy: 0.9674247080516287, F1: 0.6787878787878788\n",
      "Epoch 34 Loss: 34.476340217515826, AUC: 0.952670490738592, Accuracy: 0.9717271051014137, F1: 0.7430167597765363\n",
      "Epoch 35 Loss: 32.36268175859004, AUC: 0.9519968913192114, Accuracy: 0.9683466502765826, F1: 0.7178082191780821\n",
      "Epoch 36 Loss: 34.17091331887059, AUC: 0.9540060086625664, Accuracy: 0.9674247080516287, F1: 0.7225130890052356\n",
      "Epoch 37 Loss: 32.97449438646436, AUC: 0.9521869008664124, Accuracy: 0.9714197910264291, F1: 0.7452054794520547\n",
      "Epoch 38 Loss: 32.82485518034082, AUC: 0.9520693129908905, Accuracy: 0.9674247080516287, F1: 0.6918604651162791\n",
      "Epoch 39 Loss: 33.43025527568534, AUC: 0.953812105477103, Accuracy: 0.964658881376767, F1: 0.7132169576059849\n"
     ]
    }
   ],
   "source": [
    "attention_fusion_model = AttentionFusionModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(attention_fusion_model.parameters(), lr=0.0001)\n",
    "train(attention_fusion_model, combined_train_loader, combined_test_loader, criterion, optimizer, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Fusion ROC: 0.953812105477103, Accuracy: 0.964658881376767, F1: 0.7132169576059849\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = get_predicted_probs(attention_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_pred_probs) > 0.5).astype(int)\n",
    "attention_fusion_roc = roc_auc_score(y_test.numpy(), y_pred_probs)\n",
    "attention_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "attention_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Attention Fusion ROC: {attention_fusion_roc}, Accuracy: {attention_fusion_accuracy}, F1: {attention_fusion_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
