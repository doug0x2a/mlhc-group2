{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_embed = pd.read_csv('embeddings.csv')\n",
    "brset_split = pd.read_csv('split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_names = brset_embed.columns[brset_embed.columns.str.match('text_\\d+')]\n",
    "image_column_names = brset_embed.columns[brset_embed.columns.str.match('image_\\d+')]\n",
    "text_columns = brset_embed[text_column_names]\n",
    "image_columns = brset_embed[image_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = torch.tensor(text_columns.values)\n",
    "image_embed = torch.tensor(image_columns.values)\n",
    "y = torch.tensor(brset_embed['DR_2'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, verbose=True, scheduler=None):\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_accuracy': [], 'val_f1': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            val_logits = model(X)\n",
    "            loss = criterion(val_logits, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = []\n",
    "            val_labels = []\n",
    "            val_loss = 0\n",
    "            for X, y in val_loader:\n",
    "                X = X.to(device).float()\n",
    "                y = y.to(device).float()\n",
    "                val_labels.extend(y.tolist())\n",
    "                y_pred = model(X)\n",
    "                val_logits.append(y_pred.cpu().numpy())\n",
    "                loss = criterion(y_pred, y.unsqueeze(1))\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            val_logits = np.concatenate(val_logits)\n",
    "            val_preds = nn.Sigmoid()(torch.tensor(val_logits)).cpu().numpy()\n",
    "            auc = roc_auc_score(val_labels, val_preds)\n",
    "            history['val_auc'].append(auc)\n",
    "            accuracy = accuracy_score(val_labels, val_preds > 0.5)\n",
    "            history['val_accuracy'].append(accuracy)\n",
    "            f1 = f1_score(val_labels, val_preds > 0.5)\n",
    "            history['val_f1'].append(f1)\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(val_loss)\n",
    "                last_lr = scheduler.get_last_lr()[0]\n",
    "            else:\n",
    "                last_lr = optimizer.param_groups[0]['lr']\n",
    "            if verbose:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, val loss: {val_loss:.4f}, val auc: {auc:.4f}, val accuracy: {accuracy:.4f}, val f1: {f1:.4f}, LR: {last_lr}')\n",
    "    return history\n",
    "\n",
    "\n",
    "def get_probs(model, loader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    y_hat = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for X,_ in loader:\n",
    "            X = X.to(device).float()\n",
    "            y_hat = torch.cat((y_hat, model(X)))\n",
    "    return nn.Sigmoid()(y_hat).cpu().numpy().flatten()\n",
    "\n",
    "def get_optimal_f1_threshold(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    return thresholds[np.argmax(f1)]\n",
    "\n",
    "# Simple Dataset to support embeddings\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://github.com/luisnakayama/BRSET/blob/main/src/FocalLoss.py\n",
    "class BinaryFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(BinaryFocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Only Model - Embedding data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9758, 1536]) torch.Size([3254, 1536]) torch.Size([3254, 1536])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_embed_idx = brset_split[brset_split['embeddings_split'] == 'train'].index\n",
    "test_embed_idx = brset_split[brset_split['embeddings_split'] == 'test'].index\n",
    "train_img_emsplit = image_embed[train_embed_idx]\n",
    "test_img_emsplit = image_embed[test_embed_idx]\n",
    "train_y_emsplit = y[train_embed_idx]\n",
    "test_y_emsplit = y[test_embed_idx]\n",
    "\n",
    "train_img_emsplit, val_img_emsplit, train_y_emsplit, val_y_emsplit = train_test_split(train_img_emsplit, train_y_emsplit, \n",
    "                                                                                      test_size=len(test_embed_idx)/len(train_embed_idx),\n",
    "                                                                                      random_state=42)\n",
    "\n",
    "print(train_img_emsplit.shape, val_img_emsplit.shape, test_img_emsplit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_emsplit_train_dataset = SimpleDataset(train_img_emsplit, train_y_emsplit)\n",
    "image_emsplit_val_dataset = SimpleDataset(val_img_emsplit, val_y_emsplit)\n",
    "image_emsplit_test_dataset = SimpleDataset(test_img_emsplit, test_y_emsplit)\n",
    "\n",
    "image_emsplit_train_loader = DataLoader(image_emsplit_train_dataset, batch_size=32, shuffle=True)\n",
    "image_emsplit_val_loader = DataLoader(image_emsplit_val_dataset, batch_size=32, shuffle=False)\n",
    "image_emsplit_test_loader = DataLoader(image_emsplit_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train image only model\n",
    "image_only_model_emsplit = nn.Sequential(\n",
    "    nn.Linear(1536, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_868643/1978008771.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor(p0/p1).to(device)\n",
      "/home/doug/miniconda3/envs/mit-ml/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0607, val loss: 0.0495, val auc: 0.9274, val accuracy: 0.9364, val f1: 0.2473, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0400, val loss: 0.0365, val auc: 0.9362, val accuracy: 0.9499, val f1: 0.5382, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0373, val loss: 0.0438, val auc: 0.9382, val accuracy: 0.9431, val f1: 0.3813, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0343, val loss: 0.0361, val auc: 0.9418, val accuracy: 0.9502, val f1: 0.5207, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0342, val loss: 0.0334, val auc: 0.9460, val accuracy: 0.9551, val f1: 0.6404, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0336, val loss: 0.0374, val auc: 0.9460, val accuracy: 0.9521, val f1: 0.5465, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0343, val loss: 0.0395, val auc: 0.9474, val accuracy: 0.9471, val f1: 0.6461, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0345, val loss: 0.0340, val auc: 0.9465, val accuracy: 0.9493, val f1: 0.4762, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0312, val loss: 0.0311, val auc: 0.9488, val accuracy: 0.9567, val f1: 0.6412, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0301, val loss: 0.0332, val auc: 0.9487, val accuracy: 0.9505, val f1: 0.4921, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0315, val loss: 0.0392, val auc: 0.9472, val accuracy: 0.9478, val f1: 0.4408, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0324, val loss: 0.0311, val auc: 0.9507, val accuracy: 0.9548, val f1: 0.6589, LR: 0.001\n",
      "Epoch 13/50, train loss: 0.0300, val loss: 0.0349, val auc: 0.9485, val accuracy: 0.9499, val f1: 0.4858, LR: 0.001\n",
      "Epoch 14/50, train loss: 0.0310, val loss: 0.0371, val auc: 0.9518, val accuracy: 0.9554, val f1: 0.5821, LR: 0.001\n",
      "Epoch 15/50, train loss: 0.0301, val loss: 0.0315, val auc: 0.9520, val accuracy: 0.9564, val f1: 0.5943, LR: 0.001\n",
      "Epoch 16/50, train loss: 0.0297, val loss: 0.0321, val auc: 0.9524, val accuracy: 0.9561, val f1: 0.5879, LR: 0.001\n",
      "Epoch 17/50, train loss: 0.0293, val loss: 0.0432, val auc: 0.9515, val accuracy: 0.9413, val f1: 0.6483, LR: 0.001\n",
      "Epoch 18/50, train loss: 0.0291, val loss: 0.0354, val auc: 0.9521, val accuracy: 0.9533, val f1: 0.5394, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0269, val loss: 0.0297, val auc: 0.9556, val accuracy: 0.9613, val f1: 0.6667, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0240, val loss: 0.0287, val auc: 0.9555, val accuracy: 0.9619, val f1: 0.6900, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0242, val loss: 0.0290, val auc: 0.9550, val accuracy: 0.9616, val f1: 0.6883, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0243, val loss: 0.0289, val auc: 0.9546, val accuracy: 0.9619, val f1: 0.6804, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0237, val loss: 0.0291, val auc: 0.9551, val accuracy: 0.9628, val f1: 0.6998, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0239, val loss: 0.0288, val auc: 0.9551, val accuracy: 0.9628, val f1: 0.6921, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0237, val loss: 0.0303, val auc: 0.9552, val accuracy: 0.9619, val f1: 0.6771, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0237, val loss: 0.0292, val auc: 0.9557, val accuracy: 0.9631, val f1: 0.6985, LR: 1e-05\n",
      "Epoch 27/50, train loss: 0.0236, val loss: 0.0290, val auc: 0.9556, val accuracy: 0.9634, val f1: 0.7003, LR: 1e-05\n",
      "Epoch 28/50, train loss: 0.0224, val loss: 0.0289, val auc: 0.9556, val accuracy: 0.9622, val f1: 0.6933, LR: 1e-05\n",
      "Epoch 29/50, train loss: 0.0227, val loss: 0.0288, val auc: 0.9556, val accuracy: 0.9637, val f1: 0.7020, LR: 1e-05\n",
      "Epoch 30/50, train loss: 0.0228, val loss: 0.0287, val auc: 0.9557, val accuracy: 0.9631, val f1: 0.7030, LR: 1e-05\n",
      "Epoch 31/50, train loss: 0.0228, val loss: 0.0287, val auc: 0.9557, val accuracy: 0.9634, val f1: 0.7032, LR: 1e-05\n",
      "Epoch 32/50, train loss: 0.0227, val loss: 0.0286, val auc: 0.9557, val accuracy: 0.9631, val f1: 0.7030, LR: 1e-05\n",
      "Epoch 33/50, train loss: 0.0233, val loss: 0.0287, val auc: 0.9557, val accuracy: 0.9628, val f1: 0.6967, LR: 1e-05\n",
      "Epoch 34/50, train loss: 0.0231, val loss: 0.0286, val auc: 0.9557, val accuracy: 0.9634, val f1: 0.7032, LR: 1e-05\n",
      "Epoch 35/50, train loss: 0.0231, val loss: 0.0286, val auc: 0.9557, val accuracy: 0.9631, val f1: 0.7044, LR: 1e-05\n",
      "Epoch 36/50, train loss: 0.0228, val loss: 0.0290, val auc: 0.9558, val accuracy: 0.9631, val f1: 0.6954, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0231, val loss: 0.0288, val auc: 0.9557, val accuracy: 0.9631, val f1: 0.6970, LR: 1e-05\n",
      "Epoch 38/50, train loss: 0.0228, val loss: 0.0287, val auc: 0.9556, val accuracy: 0.9631, val f1: 0.7015, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0231, val loss: 0.0287, val auc: 0.9555, val accuracy: 0.9625, val f1: 0.6919, LR: 1e-05\n",
      "Epoch 40/50, train loss: 0.0223, val loss: 0.0287, val auc: 0.9554, val accuracy: 0.9634, val f1: 0.7062, LR: 1e-05\n",
      "Epoch 41/50, train loss: 0.0227, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9634, val f1: 0.7018, LR: 1.0000000000000002e-06\n",
      "Epoch 42/50, train loss: 0.0230, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9628, val f1: 0.6983, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0231, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9631, val f1: 0.7015, LR: 1.0000000000000002e-06\n",
      "Epoch 44/50, train loss: 0.0225, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9631, val f1: 0.7015, LR: 1.0000000000000002e-06\n",
      "Epoch 45/50, train loss: 0.0226, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9628, val f1: 0.6998, LR: 1.0000000000000002e-06\n",
      "Epoch 46/50, train loss: 0.0227, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9628, val f1: 0.6998, LR: 1.0000000000000002e-06\n",
      "Epoch 47/50, train loss: 0.0225, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9628, val f1: 0.6998, LR: 1.0000000000000002e-07\n",
      "Epoch 48/50, train loss: 0.0231, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9628, val f1: 0.6998, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0228, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9628, val f1: 0.6998, LR: 1.0000000000000002e-07\n",
      "Epoch 50/50, train loss: 0.0226, val loss: 0.0288, val auc: 0.9554, val accuracy: 0.9628, val f1: 0.6998, LR: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "p1 = sum(train_y_emsplit)/len(train_y_emsplit)\n",
    "p0 = 1 - p1\n",
    "pos_weight = torch.tensor(p0/p1).to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(image_only_model_emsplit.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(image_only_model_emsplit, image_emsplit_train_loader, image_emsplit_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Only ROC: 0.9463721414854697, Accuracy: 0.9668100799016595, F1: 0.7112299465240641\n",
      "Image Only Accuracy: 0.968039336201598, F1: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Evaluate image only model on test set\n",
    "y_probs = get_probs(image_only_model_emsplit, image_emsplit_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "image_only_roc = roc_auc_score(test_y_emsplit.numpy(), y_probs)\n",
    "image_only_accuracy = accuracy_score(test_y_emsplit.numpy(), y_preds)\n",
    "image_only_f1 = f1_score(test_y_emsplit.numpy(), y_preds)\n",
    "print(f'Image Only ROC: {image_only_roc}, Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(test_y_emsplit.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "image_only_accuracy = accuracy_score(test_y_emsplit.numpy(), y_preds)\n",
    "image_only_f1 = f1_score(test_y_emsplit.numpy(), y_preds)\n",
    "print(f'Image Only Accuracy: {image_only_accuracy}, F1: {image_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Only Model - Resplit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = brset_split[brset_split['split'] == 'train'].index\n",
    "val_idx = brset_split[brset_split['split'] == 'val'].index\n",
    "test_idx = brset_split[brset_split['split'] == 'test'].index\n",
    "\n",
    "image_train = image_embed[train_idx]\n",
    "image_val = image_embed[val_idx]\n",
    "image_test = image_embed[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "# DataSet\n",
    "image_train_dataset = SimpleDataset(image_train, y_train)\n",
    "image_val_dataset = SimpleDataset(image_val, y_val)\n",
    "image_test_dataset = SimpleDataset(image_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "image_train_loader = DataLoader(image_train_dataset, batch_size=32, shuffle=True)\n",
    "image_val_loader = DataLoader(image_val_dataset, batch_size=32, shuffle=False)\n",
    "image_test_loader = DataLoader(image_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_only_model = nn.Sequential(\n",
    "    nn.Linear(1536, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0546, val loss: 0.0373, val auc: 0.9150, val accuracy: 0.9469, val f1: 0.3709, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0398, val loss: 0.0345, val auc: 0.9243, val accuracy: 0.9561, val f1: 0.5489, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0382, val loss: 0.0338, val auc: 0.9302, val accuracy: 0.9570, val f1: 0.5395, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0371, val loss: 0.0390, val auc: 0.9367, val accuracy: 0.9536, val f1: 0.4739, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0368, val loss: 0.0375, val auc: 0.9379, val accuracy: 0.9530, val f1: 0.4516, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0333, val loss: 0.0323, val auc: 0.9376, val accuracy: 0.9598, val f1: 0.6507, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0353, val loss: 0.0333, val auc: 0.9401, val accuracy: 0.9582, val f1: 0.6566, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0338, val loss: 0.0317, val auc: 0.9422, val accuracy: 0.9604, val f1: 0.6667, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0327, val loss: 0.0312, val auc: 0.9406, val accuracy: 0.9613, val f1: 0.6613, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0329, val loss: 0.0316, val auc: 0.9450, val accuracy: 0.9631, val f1: 0.6532, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0326, val loss: 0.0328, val auc: 0.9443, val accuracy: 0.9607, val f1: 0.5949, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0325, val loss: 0.0303, val auc: 0.9436, val accuracy: 0.9635, val f1: 0.6469, LR: 0.001\n",
      "Epoch 13/50, train loss: 0.0320, val loss: 0.0297, val auc: 0.9480, val accuracy: 0.9619, val f1: 0.6220, LR: 0.001\n",
      "Epoch 14/50, train loss: 0.0325, val loss: 0.0298, val auc: 0.9469, val accuracy: 0.9622, val f1: 0.6805, LR: 0.001\n",
      "Epoch 15/50, train loss: 0.0306, val loss: 0.0291, val auc: 0.9457, val accuracy: 0.9628, val f1: 0.6685, LR: 0.001\n",
      "Epoch 16/50, train loss: 0.0309, val loss: 0.0299, val auc: 0.9479, val accuracy: 0.9585, val f1: 0.6731, LR: 0.001\n",
      "Epoch 17/50, train loss: 0.0328, val loss: 0.0293, val auc: 0.9495, val accuracy: 0.9635, val f1: 0.6426, LR: 0.001\n",
      "Epoch 18/50, train loss: 0.0315, val loss: 0.0336, val auc: 0.9468, val accuracy: 0.9515, val f1: 0.6489, LR: 0.001\n",
      "Epoch 19/50, train loss: 0.0301, val loss: 0.0284, val auc: 0.9503, val accuracy: 0.9598, val f1: 0.6351, LR: 0.001\n",
      "Epoch 20/50, train loss: 0.0292, val loss: 0.0414, val auc: 0.9502, val accuracy: 0.9592, val f1: 0.5492, LR: 0.001\n",
      "Epoch 21/50, train loss: 0.0293, val loss: 0.0282, val auc: 0.9503, val accuracy: 0.9650, val f1: 0.6780, LR: 0.001\n",
      "Epoch 22/50, train loss: 0.0304, val loss: 0.0303, val auc: 0.9521, val accuracy: 0.9552, val f1: 0.4786, LR: 0.001\n",
      "Epoch 23/50, train loss: 0.0317, val loss: 0.0368, val auc: 0.9503, val accuracy: 0.9361, val f1: 0.0280, LR: 0.001\n",
      "Epoch 24/50, train loss: 0.0333, val loss: 0.0371, val auc: 0.9472, val accuracy: 0.9619, val f1: 0.6536, LR: 0.001\n",
      "Epoch 25/50, train loss: 0.0297, val loss: 0.0283, val auc: 0.9507, val accuracy: 0.9628, val f1: 0.6592, LR: 0.001\n",
      "Epoch 26/50, train loss: 0.0296, val loss: 0.0287, val auc: 0.9520, val accuracy: 0.9604, val f1: 0.6614, LR: 0.001\n",
      "Epoch 27/50, train loss: 0.0292, val loss: 0.0286, val auc: 0.9518, val accuracy: 0.9635, val f1: 0.6648, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0259, val loss: 0.0277, val auc: 0.9524, val accuracy: 0.9619, val f1: 0.6575, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0253, val loss: 0.0278, val auc: 0.9528, val accuracy: 0.9625, val f1: 0.6685, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0250, val loss: 0.0275, val auc: 0.9525, val accuracy: 0.9613, val f1: 0.6613, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0241, val loss: 0.0281, val auc: 0.9524, val accuracy: 0.9616, val f1: 0.6753, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0239, val loss: 0.0287, val auc: 0.9529, val accuracy: 0.9641, val f1: 0.6648, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0244, val loss: 0.0282, val auc: 0.9534, val accuracy: 0.9635, val f1: 0.6610, LR: 0.0001\n",
      "Epoch 34/50, train loss: 0.0248, val loss: 0.0281, val auc: 0.9536, val accuracy: 0.9628, val f1: 0.6611, LR: 0.0001\n",
      "Epoch 35/50, train loss: 0.0240, val loss: 0.0276, val auc: 0.9533, val accuracy: 0.9622, val f1: 0.6737, LR: 0.0001\n",
      "Epoch 36/50, train loss: 0.0240, val loss: 0.0276, val auc: 0.9531, val accuracy: 0.9638, val f1: 0.6758, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0235, val loss: 0.0275, val auc: 0.9533, val accuracy: 0.9616, val f1: 0.6649, LR: 1e-05\n",
      "Epoch 38/50, train loss: 0.0231, val loss: 0.0277, val auc: 0.9534, val accuracy: 0.9622, val f1: 0.6667, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0238, val loss: 0.0275, val auc: 0.9534, val accuracy: 0.9622, val f1: 0.6667, LR: 1e-05\n",
      "Epoch 40/50, train loss: 0.0233, val loss: 0.0274, val auc: 0.9533, val accuracy: 0.9619, val f1: 0.6684, LR: 1e-05\n",
      "Epoch 41/50, train loss: 0.0230, val loss: 0.0277, val auc: 0.9538, val accuracy: 0.9622, val f1: 0.6667, LR: 1e-05\n",
      "Epoch 42/50, train loss: 0.0230, val loss: 0.0275, val auc: 0.9541, val accuracy: 0.9619, val f1: 0.6667, LR: 1e-05\n",
      "Epoch 43/50, train loss: 0.0227, val loss: 0.0276, val auc: 0.9544, val accuracy: 0.9622, val f1: 0.6667, LR: 1e-05\n",
      "Epoch 44/50, train loss: 0.0230, val loss: 0.0275, val auc: 0.9544, val accuracy: 0.9625, val f1: 0.6703, LR: 1e-05\n",
      "Epoch 45/50, train loss: 0.0234, val loss: 0.0274, val auc: 0.9544, val accuracy: 0.9625, val f1: 0.6703, LR: 1e-05\n",
      "Epoch 46/50, train loss: 0.0234, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9625, val f1: 0.6703, LR: 1.0000000000000002e-06\n",
      "Epoch 47/50, train loss: 0.0232, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9619, val f1: 0.6630, LR: 1.0000000000000002e-06\n",
      "Epoch 48/50, train loss: 0.0228, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9625, val f1: 0.6703, LR: 1.0000000000000002e-06\n",
      "Epoch 49/50, train loss: 0.0224, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9622, val f1: 0.6667, LR: 1.0000000000000002e-06\n",
      "Epoch 50/50, train loss: 0.0227, val loss: 0.0274, val auc: 0.9545, val accuracy: 0.9622, val f1: 0.6667, LR: 1.0000000000000002e-06\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(image_only_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(image_only_model, image_train_loader, image_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Only ROC: 0.956475476131167, Accuracy: 0.9652628343067937, F1: 0.6904109589041096\n",
      "Image Only Accuracy: 0.9640332001229635, F1: 0.7259953161592504\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(image_only_model, image_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "image_only_roc = roc_auc_score(y[test_idx].numpy(), y_probs)\n",
    "image_only_accuracy = accuracy_score(y[test_idx].numpy(), y_preds)\n",
    "image_only_f1 = f1_score(y[test_idx].numpy(), y_preds)\n",
    "print(f'Image Only ROC: {image_only_roc}, Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y[test_idx].numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "image_only_accuracy = accuracy_score(y[test_idx].numpy(), y_preds)\n",
    "image_only_f1 = f1_score(y[test_idx].numpy(), y_preds)\n",
    "print(f'Image Only Accuracy: {image_only_accuracy}, F1: {image_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text_embed into train and test based on brset_embed['split']\n",
    "text_train = text_embed[train_idx]\n",
    "text_val = text_embed[val_idx]\n",
    "text_test = text_embed[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_dataset = SimpleDataset(text_train, y_train)\n",
    "text_val_dataset = SimpleDataset(text_val, y_val)\n",
    "text_test_dataset = SimpleDataset(text_test, y_test)\n",
    "\n",
    "text_train_loader = DataLoader(text_train_dataset, batch_size=32, shuffle=True)\n",
    "text_val_loader = DataLoader(text_val_dataset, batch_size=32, shuffle=False)\n",
    "text_test_loader = DataLoader(text_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_model = nn.Sequential(\n",
    "    nn.Linear(4096, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    # nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0636, val loss: 0.0327, val auc: 0.9471, val accuracy: 0.9499, val f1: 0.3895, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0347, val loss: 0.0349, val auc: 0.9546, val accuracy: 0.9567, val f1: 0.5220, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0288, val loss: 0.0285, val auc: 0.9596, val accuracy: 0.9628, val f1: 0.7375, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0307, val loss: 0.0263, val auc: 0.9584, val accuracy: 0.9653, val f1: 0.6706, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0337, val loss: 0.0336, val auc: 0.9550, val accuracy: 0.9352, val f1: 0.0000, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0320, val loss: 0.0314, val auc: 0.9569, val accuracy: 0.9367, val f1: 0.0463, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0308, val loss: 0.0294, val auc: 0.9585, val accuracy: 0.9352, val f1: 0.0000, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0301, val loss: 0.0302, val auc: 0.9558, val accuracy: 0.9352, val f1: 0.0000, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0332, val loss: 0.0365, val auc: 0.9510, val accuracy: 0.9671, val f1: 0.6667, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0294, val loss: 0.0289, val auc: 0.9560, val accuracy: 0.9760, val f1: 0.7809, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0265, val loss: 0.0275, val auc: 0.9609, val accuracy: 0.9754, val f1: 0.7895, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0262, val loss: 0.0274, val auc: 0.9611, val accuracy: 0.9767, val f1: 0.7979, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0263, val loss: 0.0275, val auc: 0.9611, val accuracy: 0.9764, val f1: 0.7958, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0268, val loss: 0.0277, val auc: 0.9613, val accuracy: 0.9773, val f1: 0.8021, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0264, val loss: 0.0272, val auc: 0.9614, val accuracy: 0.9764, val f1: 0.7958, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0258, val loss: 0.0273, val auc: 0.9615, val accuracy: 0.9770, val f1: 0.8000, LR: 1e-05\n",
      "Epoch 17/50, train loss: 0.0250, val loss: 0.0276, val auc: 0.9615, val accuracy: 0.9770, val f1: 0.8000, LR: 1e-05\n",
      "Epoch 18/50, train loss: 0.0267, val loss: 0.0272, val auc: 0.9610, val accuracy: 0.9779, val f1: 0.8163, LR: 1e-05\n",
      "Epoch 19/50, train loss: 0.0252, val loss: 0.0275, val auc: 0.9613, val accuracy: 0.9764, val f1: 0.7958, LR: 1e-05\n",
      "Epoch 20/50, train loss: 0.0259, val loss: 0.0273, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1e-05\n",
      "Epoch 21/50, train loss: 0.0262, val loss: 0.0271, val auc: 0.9611, val accuracy: 0.9773, val f1: 0.8063, LR: 1e-05\n",
      "Epoch 22/50, train loss: 0.0259, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-06\n",
      "Epoch 23/50, train loss: 0.0260, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-06\n",
      "Epoch 24/50, train loss: 0.0261, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-06\n",
      "Epoch 25/50, train loss: 0.0259, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-06\n",
      "Epoch 26/50, train loss: 0.0253, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-06\n",
      "Epoch 27/50, train loss: 0.0255, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-06\n",
      "Epoch 28/50, train loss: 0.0255, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-07\n",
      "Epoch 29/50, train loss: 0.0263, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-07\n",
      "Epoch 30/50, train loss: 0.0266, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-07\n",
      "Epoch 31/50, train loss: 0.0256, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-07\n",
      "Epoch 32/50, train loss: 0.0259, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-07\n",
      "Epoch 33/50, train loss: 0.0256, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000002e-07\n",
      "Epoch 34/50, train loss: 0.0258, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 35/50, train loss: 0.0257, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 36/50, train loss: 0.0256, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 37/50, train loss: 0.0262, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 38/50, train loss: 0.0253, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 39/50, train loss: 0.0261, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 40/50, train loss: 0.0257, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 41/50, train loss: 0.0261, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 42/50, train loss: 0.0257, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 43/50, train loss: 0.0262, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 44/50, train loss: 0.0256, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 45/50, train loss: 0.0257, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 46/50, train loss: 0.0257, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 47/50, train loss: 0.0263, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 48/50, train loss: 0.0246, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 49/50, train loss: 0.0262, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n",
      "Epoch 50/50, train loss: 0.0253, val loss: 0.0272, val auc: 0.9612, val accuracy: 0.9764, val f1: 0.7958, LR: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(text_only_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(text_only_model, text_train_loader, text_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Only ROC: 0.9773974161446368, Accuracy: 0.9772517675991392, F1: 0.8082901554404145\n",
      "Text Only Accuracy: 0.9790962188748847, F1: 0.8357487922705314\n"
     ]
    }
   ],
   "source": [
    "# Evaluate text only model on test set\n",
    "y_probs = get_probs(text_only_model, text_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "text_only_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "text_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "text_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Text Only ROC: {text_only_roc}, Accuracy: {text_only_accuracy}, F1: {text_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "text_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "text_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Text Only Accuracy: {text_only_accuracy}, F1: {text_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Early Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_early_fusion_model = nn.Sequential(\n",
    "    nn.Linear(4096+1536, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 1),\n",
    "    # nn.Sigmoid()\n",
    ")\n",
    "\n",
    "combined_train = torch.cat((text_train, image_train), dim=1)\n",
    "combined_val = torch.cat((text_val, image_val), dim=1)\n",
    "combined_test = torch.cat((text_test, image_test), dim=1)\n",
    "\n",
    "combined_train_dataset = SimpleDataset(combined_train, y_train)\n",
    "combined_val_dataset = SimpleDataset(combined_val, y_val)\n",
    "combined_test_dataset = SimpleDataset(combined_test, y_test)\n",
    "\n",
    "combined_train_loader = DataLoader(combined_train_dataset, batch_size=32, shuffle=True)\n",
    "combined_val_loader = DataLoader(combined_val_dataset, batch_size=32, shuffle=False)\n",
    "combined_test_loader = DataLoader(combined_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.1241, val loss: 0.0315, val auc: 0.9619, val accuracy: 0.9573, val f1: 0.7011, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0327, val loss: 0.0243, val auc: 0.9611, val accuracy: 0.9730, val f1: 0.7569, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0266, val loss: 0.0225, val auc: 0.9655, val accuracy: 0.9736, val f1: 0.7663, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0252, val loss: 0.0376, val auc: 0.9667, val accuracy: 0.9595, val f1: 0.5510, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0279, val loss: 0.0247, val auc: 0.9662, val accuracy: 0.9727, val f1: 0.7886, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0249, val loss: 0.0205, val auc: 0.9686, val accuracy: 0.9757, val f1: 0.7882, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0243, val loss: 0.0224, val auc: 0.9678, val accuracy: 0.9764, val f1: 0.7819, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0255, val loss: 0.0295, val auc: 0.9683, val accuracy: 0.9650, val f1: 0.6323, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0268, val loss: 0.0229, val auc: 0.9681, val accuracy: 0.9699, val f1: 0.7012, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0264, val loss: 0.0222, val auc: 0.9697, val accuracy: 0.9788, val f1: 0.8198, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0284, val loss: 0.0266, val auc: 0.9690, val accuracy: 0.9352, val f1: 0.0000, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0254, val loss: 0.0253, val auc: 0.9719, val accuracy: 0.9721, val f1: 0.8009, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0192, val loss: 0.0194, val auc: 0.9713, val accuracy: 0.9800, val f1: 0.8320, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0188, val loss: 0.0193, val auc: 0.9713, val accuracy: 0.9794, val f1: 0.8278, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0189, val loss: 0.0191, val auc: 0.9714, val accuracy: 0.9797, val f1: 0.8281, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0180, val loss: 0.0188, val auc: 0.9717, val accuracy: 0.9779, val f1: 0.8209, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0184, val loss: 0.0199, val auc: 0.9717, val accuracy: 0.9807, val f1: 0.8338, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0177, val loss: 0.0187, val auc: 0.9717, val accuracy: 0.9800, val f1: 0.8320, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0182, val loss: 0.0200, val auc: 0.9719, val accuracy: 0.9803, val f1: 0.8316, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0183, val loss: 0.0191, val auc: 0.9718, val accuracy: 0.9803, val f1: 0.8307, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0181, val loss: 0.0187, val auc: 0.9722, val accuracy: 0.9803, val f1: 0.8333, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0181, val loss: 0.0181, val auc: 0.9726, val accuracy: 0.9807, val f1: 0.8429, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0179, val loss: 0.0185, val auc: 0.9721, val accuracy: 0.9803, val f1: 0.8325, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0175, val loss: 0.0187, val auc: 0.9723, val accuracy: 0.9810, val f1: 0.8377, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0182, val loss: 0.0182, val auc: 0.9724, val accuracy: 0.9800, val f1: 0.8379, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0179, val loss: 0.0181, val auc: 0.9723, val accuracy: 0.9803, val f1: 0.8400, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0178, val loss: 0.0181, val auc: 0.9724, val accuracy: 0.9819, val f1: 0.8483, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0166, val loss: 0.0182, val auc: 0.9725, val accuracy: 0.9816, val f1: 0.8421, LR: 1e-05\n",
      "Epoch 29/50, train loss: 0.0166, val loss: 0.0180, val auc: 0.9725, val accuracy: 0.9819, val f1: 0.8483, LR: 1e-05\n",
      "Epoch 30/50, train loss: 0.0171, val loss: 0.0181, val auc: 0.9725, val accuracy: 0.9816, val f1: 0.8462, LR: 1e-05\n",
      "Epoch 31/50, train loss: 0.0164, val loss: 0.0179, val auc: 0.9726, val accuracy: 0.9803, val f1: 0.8408, LR: 1e-05\n",
      "Epoch 32/50, train loss: 0.0170, val loss: 0.0181, val auc: 0.9725, val accuracy: 0.9819, val f1: 0.8483, LR: 1e-05\n",
      "Epoch 33/50, train loss: 0.0173, val loss: 0.0181, val auc: 0.9725, val accuracy: 0.9819, val f1: 0.8475, LR: 1e-05\n",
      "Epoch 34/50, train loss: 0.0172, val loss: 0.0182, val auc: 0.9725, val accuracy: 0.9813, val f1: 0.8416, LR: 1e-05\n",
      "Epoch 35/50, train loss: 0.0164, val loss: 0.0181, val auc: 0.9726, val accuracy: 0.9819, val f1: 0.8483, LR: 1e-05\n",
      "Epoch 36/50, train loss: 0.0171, val loss: 0.0181, val auc: 0.9726, val accuracy: 0.9819, val f1: 0.8483, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0171, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9816, val f1: 0.8469, LR: 1.0000000000000002e-06\n",
      "Epoch 38/50, train loss: 0.0163, val loss: 0.0181, val auc: 0.9726, val accuracy: 0.9816, val f1: 0.8469, LR: 1.0000000000000002e-06\n",
      "Epoch 39/50, train loss: 0.0174, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9816, val f1: 0.8469, LR: 1.0000000000000002e-06\n",
      "Epoch 40/50, train loss: 0.0168, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9816, val f1: 0.8469, LR: 1.0000000000000002e-06\n",
      "Epoch 41/50, train loss: 0.0172, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9816, val f1: 0.8469, LR: 1.0000000000000002e-06\n",
      "Epoch 42/50, train loss: 0.0169, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0163, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000002e-07\n",
      "Epoch 44/50, train loss: 0.0159, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000002e-07\n",
      "Epoch 45/50, train loss: 0.0168, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000002e-07\n",
      "Epoch 46/50, train loss: 0.0168, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000002e-07\n",
      "Epoch 47/50, train loss: 0.0166, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000002e-07\n",
      "Epoch 48/50, train loss: 0.0160, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0169, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000004e-08\n",
      "Epoch 50/50, train loss: 0.0163, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9813, val f1: 0.8440, LR: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(simple_early_fusion_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(simple_early_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Fusion ROC: 0.9884030961980239, Accuracy: 0.984014755610206, F1: 0.8693467336683417\n",
      "Early Fusion Accuracy: 0.984014755610206, F1: 0.8686868686868686\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(simple_early_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "early_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "early_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "early_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Early Fusion ROC: {early_fusion_roc}, Accuracy: {early_fusion_accuracy}, F1: {early_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "early_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "early_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Early Fusion Accuracy: {early_fusion_accuracy}, F1: {early_fusion_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Late Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separate modules for text and image processing\n",
    "class TextModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class ImageModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class SimpleLateFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLateFusionModel, self).__init__()\n",
    "        self.text_module = TextModule()\n",
    "        self.image_module = ImageModule()\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_features = self.text_module(text_data)\n",
    "        image_features = self.image_module(image_data)\n",
    "        combined_features = torch.cat((text_features, image_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.output(x)\n",
    "        return x\n",
    "\n",
    "late_fusion_model = SimpleLateFusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0398, val loss: 0.0283, val auc: 0.9562, val accuracy: 0.9607, val f1: 0.5871, LR: 0.0001\n",
      "Epoch 2/50, train loss: 0.0274, val loss: 0.0275, val auc: 0.9643, val accuracy: 0.9650, val f1: 0.6460, LR: 0.0001\n",
      "Epoch 3/50, train loss: 0.0239, val loss: 0.0277, val auc: 0.9671, val accuracy: 0.9659, val f1: 0.6498, LR: 0.0001\n",
      "Epoch 4/50, train loss: 0.0191, val loss: 0.0213, val auc: 0.9692, val accuracy: 0.9764, val f1: 0.7855, LR: 0.0001\n",
      "Epoch 5/50, train loss: 0.0177, val loss: 0.0228, val auc: 0.9703, val accuracy: 0.9751, val f1: 0.7692, LR: 0.0001\n",
      "Epoch 6/50, train loss: 0.0170, val loss: 0.0180, val auc: 0.9726, val accuracy: 0.9782, val f1: 0.8097, LR: 0.0001\n",
      "Epoch 7/50, train loss: 0.0176, val loss: 0.0200, val auc: 0.9718, val accuracy: 0.9779, val f1: 0.8326, LR: 0.0001\n",
      "Epoch 8/50, train loss: 0.0154, val loss: 0.0178, val auc: 0.9721, val accuracy: 0.9810, val f1: 0.8394, LR: 0.0001\n",
      "Epoch 9/50, train loss: 0.0157, val loss: 0.0170, val auc: 0.9724, val accuracy: 0.9810, val f1: 0.8442, LR: 0.0001\n",
      "Epoch 10/50, train loss: 0.0144, val loss: 0.0215, val auc: 0.9678, val accuracy: 0.9773, val f1: 0.8238, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0148, val loss: 0.0174, val auc: 0.9734, val accuracy: 0.9816, val f1: 0.8522, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0144, val loss: 0.0194, val auc: 0.9725, val accuracy: 0.9776, val f1: 0.8352, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0142, val loss: 0.0185, val auc: 0.9737, val accuracy: 0.9785, val f1: 0.8098, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0139, val loss: 0.0190, val auc: 0.9745, val accuracy: 0.9797, val f1: 0.8177, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0136, val loss: 0.0195, val auc: 0.9741, val accuracy: 0.9788, val f1: 0.8345, LR: 1e-05\n",
      "Epoch 16/50, train loss: 0.0113, val loss: 0.0159, val auc: 0.9756, val accuracy: 0.9831, val f1: 0.8586, LR: 1e-05\n",
      "Epoch 17/50, train loss: 0.0106, val loss: 0.0160, val auc: 0.9754, val accuracy: 0.9837, val f1: 0.8672, LR: 1e-05\n",
      "Epoch 18/50, train loss: 0.0104, val loss: 0.0161, val auc: 0.9757, val accuracy: 0.9837, val f1: 0.8691, LR: 1e-05\n",
      "Epoch 19/50, train loss: 0.0105, val loss: 0.0158, val auc: 0.9759, val accuracy: 0.9831, val f1: 0.8622, LR: 1e-05\n",
      "Epoch 20/50, train loss: 0.0103, val loss: 0.0159, val auc: 0.9758, val accuracy: 0.9834, val f1: 0.8622, LR: 1e-05\n",
      "Epoch 21/50, train loss: 0.0104, val loss: 0.0161, val auc: 0.9761, val accuracy: 0.9834, val f1: 0.8615, LR: 1e-05\n",
      "Epoch 22/50, train loss: 0.0103, val loss: 0.0157, val auc: 0.9761, val accuracy: 0.9837, val f1: 0.8658, LR: 1e-05\n",
      "Epoch 23/50, train loss: 0.0100, val loss: 0.0161, val auc: 0.9761, val accuracy: 0.9834, val f1: 0.8615, LR: 1e-05\n",
      "Epoch 24/50, train loss: 0.0101, val loss: 0.0165, val auc: 0.9762, val accuracy: 0.9828, val f1: 0.8549, LR: 1e-05\n",
      "Epoch 25/50, train loss: 0.0100, val loss: 0.0157, val auc: 0.9763, val accuracy: 0.9843, val f1: 0.8709, LR: 1e-05\n",
      "Epoch 26/50, train loss: 0.0100, val loss: 0.0161, val auc: 0.9764, val accuracy: 0.9840, val f1: 0.8732, LR: 1e-05\n",
      "Epoch 27/50, train loss: 0.0100, val loss: 0.0166, val auc: 0.9765, val accuracy: 0.9831, val f1: 0.8579, LR: 1e-05\n",
      "Epoch 28/50, train loss: 0.0100, val loss: 0.0161, val auc: 0.9766, val accuracy: 0.9837, val f1: 0.8704, LR: 1e-05\n",
      "Epoch 29/50, train loss: 0.0098, val loss: 0.0170, val auc: 0.9766, val accuracy: 0.9825, val f1: 0.8512, LR: 1e-05\n",
      "Epoch 30/50, train loss: 0.0096, val loss: 0.0160, val auc: 0.9765, val accuracy: 0.9840, val f1: 0.8673, LR: 1e-05\n",
      "Epoch 31/50, train loss: 0.0096, val loss: 0.0161, val auc: 0.9766, val accuracy: 0.9837, val f1: 0.8645, LR: 1.0000000000000002e-06\n",
      "Epoch 32/50, train loss: 0.0093, val loss: 0.0159, val auc: 0.9766, val accuracy: 0.9837, val f1: 0.8645, LR: 1.0000000000000002e-06\n",
      "Epoch 33/50, train loss: 0.0093, val loss: 0.0158, val auc: 0.9766, val accuracy: 0.9846, val f1: 0.8744, LR: 1.0000000000000002e-06\n",
      "Epoch 34/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9766, val accuracy: 0.9843, val f1: 0.8709, LR: 1.0000000000000002e-06\n",
      "Epoch 35/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000002e-06\n",
      "Epoch 36/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9840, val f1: 0.8673, LR: 1.0000000000000002e-06\n",
      "Epoch 37/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8744, LR: 1.0000000000000002e-07\n",
      "Epoch 38/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9850, val f1: 0.8766, LR: 1.0000000000000002e-07\n",
      "Epoch 39/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8737, LR: 1.0000000000000002e-07\n",
      "Epoch 40/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000002e-07\n",
      "Epoch 41/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000002e-07\n",
      "Epoch 42/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9843, val f1: 0.8702, LR: 1.0000000000000002e-07\n",
      "Epoch 43/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n",
      "Epoch 44/50, train loss: 0.0091, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n",
      "Epoch 45/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n",
      "Epoch 46/50, train loss: 0.0091, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n",
      "Epoch 47/50, train loss: 0.0091, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n",
      "Epoch 48/50, train loss: 0.0092, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n",
      "Epoch 49/50, train loss: 0.0091, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n",
      "Epoch 50/50, train loss: 0.0091, val loss: 0.0158, val auc: 0.9767, val accuracy: 0.9846, val f1: 0.8731, LR: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(late_fusion_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(late_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion ROC: 0.9871114760450591, Accuracy: 0.9837073470642483, F1: 0.8684863523573202\n",
      "Late Fusion Accuracy: 0.9846295727021211, F1: 0.8803827751196173\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(late_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "late_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "late_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "late_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Late Fusion ROC: {late_fusion_roc}, Accuracy: {late_fusion_accuracy}, F1: {late_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "late_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "late_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Late Fusion Accuracy: {late_fusion_accuracy}, F1: {late_fusion_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Reshape x from [batch_size, 256] to [batch_size, 16, 16] for attention\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class TextAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionFusionModel, self).__init__()\n",
    "        self.text_attention = TextAttentionModule()\n",
    "        self.image_attention = ImageAttentionModule()\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=256, num_heads=4, batch_first=True)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_output = self.text_attention(text_data)\n",
    "        image_output = self.image_attention(image_data)\n",
    "        # combined_features = torch.cat((text_output, image_output), dim=1)\n",
    "        combined_features, _ = self.cross_attention(text_output.unsqueeze(1), image_output.unsqueeze(1), image_output.unsqueeze(1))\n",
    "        combined_features = combined_features.squeeze(1)\n",
    "        x = self.fc1(combined_features)\n",
    "\n",
    "        x = torch.relu(x)\n",
    " \n",
    "        x = self.fc2(x)\n",
    "        # x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "attention_fusion_model = AttentionFusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0592, val loss: 0.0518, val auc: 0.8876, val accuracy: 0.9373, val f1: 0.0642, LR: 0.0001\n",
      "Epoch 2/50, train loss: 0.0445, val loss: 0.0380, val auc: 0.9100, val accuracy: 0.9515, val f1: 0.4803, LR: 0.0001\n",
      "Epoch 3/50, train loss: 0.0399, val loss: 0.0376, val auc: 0.9197, val accuracy: 0.9502, val f1: 0.4173, LR: 0.0001\n",
      "Epoch 4/50, train loss: 0.0370, val loss: 0.0345, val auc: 0.9270, val accuracy: 0.9579, val f1: 0.5910, LR: 0.0001\n",
      "Epoch 5/50, train loss: 0.0353, val loss: 0.0335, val auc: 0.9294, val accuracy: 0.9604, val f1: 0.6079, LR: 0.0001\n",
      "Epoch 6/50, train loss: 0.0344, val loss: 0.0340, val auc: 0.9317, val accuracy: 0.9567, val f1: 0.5284, LR: 0.0001\n",
      "Epoch 7/50, train loss: 0.0326, val loss: 0.0413, val auc: 0.9350, val accuracy: 0.9496, val f1: 0.3740, LR: 0.0001\n",
      "Epoch 8/50, train loss: 0.0335, val loss: 0.0345, val auc: 0.9374, val accuracy: 0.9592, val f1: 0.5751, LR: 0.0001\n",
      "Epoch 9/50, train loss: 0.0325, val loss: 0.0350, val auc: 0.9359, val accuracy: 0.9601, val f1: 0.6632, LR: 0.0001\n",
      "Epoch 10/50, train loss: 0.0317, val loss: 0.0349, val auc: 0.9413, val accuracy: 0.9536, val f1: 0.4469, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0308, val loss: 0.0354, val auc: 0.9410, val accuracy: 0.9619, val f1: 0.6051, LR: 1e-05\n",
      "Epoch 12/50, train loss: 0.0278, val loss: 0.0298, val auc: 0.9420, val accuracy: 0.9644, val f1: 0.6628, LR: 1e-05\n",
      "Epoch 13/50, train loss: 0.0276, val loss: 0.0294, val auc: 0.9427, val accuracy: 0.9638, val f1: 0.6648, LR: 1e-05\n",
      "Epoch 14/50, train loss: 0.0274, val loss: 0.0312, val auc: 0.9431, val accuracy: 0.9638, val f1: 0.6358, LR: 1e-05\n",
      "Epoch 15/50, train loss: 0.0269, val loss: 0.0302, val auc: 0.9435, val accuracy: 0.9644, val f1: 0.6420, LR: 1e-05\n",
      "Epoch 16/50, train loss: 0.0266, val loss: 0.0298, val auc: 0.9439, val accuracy: 0.9641, val f1: 0.6444, LR: 1e-05\n",
      "Epoch 17/50, train loss: 0.0268, val loss: 0.0293, val auc: 0.9440, val accuracy: 0.9644, val f1: 0.6527, LR: 1e-05\n",
      "Epoch 18/50, train loss: 0.0266, val loss: 0.0291, val auc: 0.9441, val accuracy: 0.9638, val f1: 0.6529, LR: 1e-05\n",
      "Epoch 19/50, train loss: 0.0267, val loss: 0.0294, val auc: 0.9442, val accuracy: 0.9650, val f1: 0.6545, LR: 1e-05\n",
      "Epoch 20/50, train loss: 0.0261, val loss: 0.0291, val auc: 0.9443, val accuracy: 0.9644, val f1: 0.6628, LR: 1e-05\n",
      "Epoch 21/50, train loss: 0.0263, val loss: 0.0296, val auc: 0.9454, val accuracy: 0.9638, val f1: 0.6335, LR: 1e-05\n",
      "Epoch 22/50, train loss: 0.0259, val loss: 0.0297, val auc: 0.9454, val accuracy: 0.9641, val f1: 0.6378, LR: 1e-05\n",
      "Epoch 23/50, train loss: 0.0260, val loss: 0.0295, val auc: 0.9457, val accuracy: 0.9656, val f1: 0.6606, LR: 1e-05\n",
      "Epoch 24/50, train loss: 0.0258, val loss: 0.0292, val auc: 0.9452, val accuracy: 0.9659, val f1: 0.6647, LR: 1e-05\n",
      "Epoch 25/50, train loss: 0.0254, val loss: 0.0284, val auc: 0.9461, val accuracy: 0.9653, val f1: 0.6667, LR: 1e-05\n",
      "Epoch 26/50, train loss: 0.0251, val loss: 0.0300, val auc: 0.9458, val accuracy: 0.9638, val f1: 0.6335, LR: 1e-05\n",
      "Epoch 27/50, train loss: 0.0253, val loss: 0.0286, val auc: 0.9463, val accuracy: 0.9653, val f1: 0.6586, LR: 1e-05\n",
      "Epoch 28/50, train loss: 0.0252, val loss: 0.0298, val auc: 0.9458, val accuracy: 0.9644, val f1: 0.6442, LR: 1e-05\n",
      "Epoch 29/50, train loss: 0.0253, val loss: 0.0291, val auc: 0.9462, val accuracy: 0.9653, val f1: 0.6565, LR: 1e-05\n",
      "Epoch 30/50, train loss: 0.0249, val loss: 0.0286, val auc: 0.9462, val accuracy: 0.9653, val f1: 0.6607, LR: 1e-05\n",
      "Epoch 31/50, train loss: 0.0253, val loss: 0.0284, val auc: 0.9460, val accuracy: 0.9662, val f1: 0.6746, LR: 1e-05\n",
      "Epoch 32/50, train loss: 0.0245, val loss: 0.0297, val auc: 0.9461, val accuracy: 0.9635, val f1: 0.6293, LR: 1e-05\n",
      "Epoch 33/50, train loss: 0.0248, val loss: 0.0296, val auc: 0.9471, val accuracy: 0.9641, val f1: 0.6355, LR: 1e-05\n",
      "Epoch 34/50, train loss: 0.0243, val loss: 0.0293, val auc: 0.9471, val accuracy: 0.9653, val f1: 0.6565, LR: 1e-05\n",
      "Epoch 35/50, train loss: 0.0247, val loss: 0.0289, val auc: 0.9471, val accuracy: 0.9650, val f1: 0.6545, LR: 1e-05\n",
      "Epoch 36/50, train loss: 0.0245, val loss: 0.0312, val auc: 0.9472, val accuracy: 0.9647, val f1: 0.6417, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0243, val loss: 0.0294, val auc: 0.9475, val accuracy: 0.9644, val f1: 0.6442, LR: 1.0000000000000002e-06\n",
      "Epoch 38/50, train loss: 0.0235, val loss: 0.0294, val auc: 0.9476, val accuracy: 0.9641, val f1: 0.6400, LR: 1.0000000000000002e-06\n",
      "Epoch 39/50, train loss: 0.0237, val loss: 0.0298, val auc: 0.9477, val accuracy: 0.9644, val f1: 0.6398, LR: 1.0000000000000002e-06\n",
      "Epoch 40/50, train loss: 0.0232, val loss: 0.0295, val auc: 0.9478, val accuracy: 0.9644, val f1: 0.6420, LR: 1.0000000000000002e-06\n",
      "Epoch 41/50, train loss: 0.0233, val loss: 0.0297, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-06\n",
      "Epoch 42/50, train loss: 0.0238, val loss: 0.0296, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0232, val loss: 0.0297, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-07\n",
      "Epoch 44/50, train loss: 0.0237, val loss: 0.0297, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-07\n",
      "Epoch 45/50, train loss: 0.0234, val loss: 0.0296, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-07\n",
      "Epoch 46/50, train loss: 0.0236, val loss: 0.0296, val auc: 0.9478, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-07\n",
      "Epoch 47/50, train loss: 0.0233, val loss: 0.0296, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-07\n",
      "Epoch 48/50, train loss: 0.0235, val loss: 0.0296, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0232, val loss: 0.0296, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000004e-08\n",
      "Epoch 50/50, train loss: 0.0235, val loss: 0.0296, val auc: 0.9479, val accuracy: 0.9641, val f1: 0.6378, LR: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(attention_fusion_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(attention_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Fusion ROC: 0.9524437760822702, Accuracy: 0.9618813403012604, F1: 0.6196319018404908\n",
      "Attention Fusion Accuracy: 0.9591146633876422, F1: 0.6970387243735764\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(attention_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "attention_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "attention_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "attention_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Attention Fusion ROC: {attention_fusion_roc}, Accuracy: {attention_fusion_accuracy}, F1: {attention_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "attention_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "attention_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Attention Fusion Accuracy: {attention_fusion_accuracy}, F1: {attention_fusion_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
