{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_embed = pd.read_csv('embeddings.csv')\n",
    "brset_split = pd.read_csv('split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column_names = brset_embed.columns[brset_embed.columns.str.match('text_\\d+')]\n",
    "image_column_names = brset_embed.columns[brset_embed.columns.str.match('image_\\d+')]\n",
    "text_columns = brset_embed[text_column_names]\n",
    "image_columns = brset_embed[image_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = torch.tensor(text_columns.values)\n",
    "image_embed = torch.tensor(image_columns.values)\n",
    "y = torch.tensor(brset_embed['DR_2'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, verbose=True, scheduler=None):\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_accuracy': [], 'val_f1': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            val_logits = model(X)\n",
    "            loss = criterion(val_logits, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = []\n",
    "            val_labels = []\n",
    "            val_loss = 0\n",
    "            for X, y in val_loader:\n",
    "                X = X.to(device).float()\n",
    "                y = y.to(device).float()\n",
    "                val_labels.extend(y.tolist())\n",
    "                y_pred = model(X)\n",
    "                val_logits.append(y_pred.cpu().numpy())\n",
    "                loss = criterion(y_pred, y.unsqueeze(1))\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            val_logits = np.concatenate(val_logits)\n",
    "            val_preds = nn.Sigmoid()(torch.tensor(val_logits)).cpu().numpy()\n",
    "            auc = roc_auc_score(val_labels, val_preds)\n",
    "            history['val_auc'].append(auc)\n",
    "            accuracy = accuracy_score(val_labels, val_preds > 0.5)\n",
    "            history['val_accuracy'].append(accuracy)\n",
    "            f1 = f1_score(val_labels, val_preds > 0.5)\n",
    "            history['val_f1'].append(f1)\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(val_loss)\n",
    "                last_lr = scheduler.get_last_lr()[0]\n",
    "            else:\n",
    "                last_lr = optimizer.param_groups[0]['lr']\n",
    "            if verbose:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, val loss: {val_loss:.4f}, val auc: {auc:.4f}, val accuracy: {accuracy:.4f}, val f1: {f1:.4f}, LR: {last_lr}')\n",
    "    return history\n",
    "\n",
    "\n",
    "def get_probs(model, loader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    y_hat = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for X,_ in loader:\n",
    "            X = X.to(device).float()\n",
    "            y_hat = torch.cat((y_hat, model(X)))\n",
    "    return y_hat.cpu().numpy().flatten()\n",
    "\n",
    "def get_optimal_f1_threshold(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    return thresholds[np.argmax(f1)]\n",
    "\n",
    "# Simple Dataset to support embeddings\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://github.com/luisnakayama/BRSET/blob/main/src/FocalLoss.py\n",
    "class BinaryFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(BinaryFocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Only Model - Embedding data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9758, 1536]) torch.Size([3254, 1536]) torch.Size([3254, 1536])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_embed_idx = brset_split[brset_split['embeddings_split'] == 'train'].index\n",
    "test_embed_idx = brset_split[brset_split['embeddings_split'] == 'test'].index\n",
    "train_img_emsplit = image_embed[train_embed_idx]\n",
    "test_img_emsplit = image_embed[test_embed_idx]\n",
    "train_y_emsplit = y[train_embed_idx]\n",
    "test_y_emsplit = y[test_embed_idx]\n",
    "\n",
    "train_img_emsplit, val_img_emsplit, train_y_emsplit, val_y_emsplit = train_test_split(train_img_emsplit, train_y_emsplit, \n",
    "                                                                                      test_size=len(test_embed_idx)/len(train_embed_idx),\n",
    "                                                                                      random_state=42)\n",
    "\n",
    "print(train_img_emsplit.shape, val_img_emsplit.shape, test_img_emsplit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_emsplit_train_dataset = SimpleDataset(train_img_emsplit, train_y_emsplit)\n",
    "image_emsplit_val_dataset = SimpleDataset(val_img_emsplit, val_y_emsplit)\n",
    "image_emsplit_test_dataset = SimpleDataset(test_img_emsplit, test_y_emsplit)\n",
    "\n",
    "image_emsplit_train_loader = DataLoader(image_emsplit_train_dataset, batch_size=32, shuffle=True)\n",
    "image_emsplit_val_loader = DataLoader(image_emsplit_val_dataset, batch_size=32, shuffle=False)\n",
    "image_emsplit_test_loader = DataLoader(image_emsplit_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train image only model\n",
    "image_only_model_emsplit = nn.Sequential(\n",
    "    nn.Linear(1536, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827406/1978008771.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor(p0/p1).to(device)\n",
      "/home/doug/miniconda3/envs/mit-ml/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0627, val loss: 0.0376, val auc: 0.9234, val accuracy: 0.9468, val f1: 0.5014, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0400, val loss: 0.0422, val auc: 0.9221, val accuracy: 0.9428, val f1: 0.3716, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0366, val loss: 0.0421, val auc: 0.9381, val accuracy: 0.9471, val f1: 0.6195, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0362, val loss: 0.0339, val auc: 0.9409, val accuracy: 0.9536, val f1: 0.5973, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0359, val loss: 0.0348, val auc: 0.9428, val accuracy: 0.9518, val f1: 0.5501, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0348, val loss: 0.0340, val auc: 0.9446, val accuracy: 0.9527, val f1: 0.5497, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0332, val loss: 0.0351, val auc: 0.9420, val accuracy: 0.9542, val f1: 0.5803, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0324, val loss: 0.0330, val auc: 0.9449, val accuracy: 0.9530, val f1: 0.5405, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0318, val loss: 0.0325, val auc: 0.9440, val accuracy: 0.9567, val f1: 0.6199, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0316, val loss: 0.0411, val auc: 0.9444, val accuracy: 0.9514, val f1: 0.5123, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0333, val loss: 0.0319, val auc: 0.9498, val accuracy: 0.9557, val f1: 0.6129, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0290, val loss: 0.0310, val auc: 0.9518, val accuracy: 0.9567, val f1: 0.6220, LR: 0.001\n",
      "Epoch 13/50, train loss: 0.0316, val loss: 0.0323, val auc: 0.9506, val accuracy: 0.9539, val f1: 0.5427, LR: 0.001\n",
      "Epoch 14/50, train loss: 0.0293, val loss: 0.0383, val auc: 0.9516, val accuracy: 0.9533, val f1: 0.5422, LR: 0.001\n",
      "Epoch 15/50, train loss: 0.0276, val loss: 0.0294, val auc: 0.9531, val accuracy: 0.9600, val f1: 0.6667, LR: 0.001\n",
      "Epoch 16/50, train loss: 0.0293, val loss: 0.0331, val auc: 0.9547, val accuracy: 0.9536, val f1: 0.6780, LR: 0.001\n",
      "Epoch 17/50, train loss: 0.0283, val loss: 0.0303, val auc: 0.9522, val accuracy: 0.9585, val f1: 0.6793, LR: 0.001\n",
      "Epoch 18/50, train loss: 0.0291, val loss: 0.0296, val auc: 0.9525, val accuracy: 0.9604, val f1: 0.6632, LR: 0.001\n",
      "Epoch 19/50, train loss: 0.0275, val loss: 0.0389, val auc: 0.9553, val accuracy: 0.9545, val f1: 0.5647, LR: 0.001\n",
      "Epoch 20/50, train loss: 0.0289, val loss: 0.0375, val auc: 0.9517, val accuracy: 0.9508, val f1: 0.6748, LR: 0.001\n",
      "Epoch 21/50, train loss: 0.0288, val loss: 0.0308, val auc: 0.9543, val accuracy: 0.9597, val f1: 0.6431, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0237, val loss: 0.0295, val auc: 0.9552, val accuracy: 0.9607, val f1: 0.6995, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0232, val loss: 0.0298, val auc: 0.9550, val accuracy: 0.9625, val f1: 0.6919, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0230, val loss: 0.0307, val auc: 0.9550, val accuracy: 0.9588, val f1: 0.6436, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0233, val loss: 0.0306, val auc: 0.9553, val accuracy: 0.9607, val f1: 0.6684, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0229, val loss: 0.0298, val auc: 0.9559, val accuracy: 0.9631, val f1: 0.7170, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0231, val loss: 0.0289, val auc: 0.9555, val accuracy: 0.9625, val f1: 0.6919, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0225, val loss: 0.0286, val auc: 0.9555, val accuracy: 0.9628, val f1: 0.6905, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0226, val loss: 0.0288, val auc: 0.9557, val accuracy: 0.9622, val f1: 0.6870, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0224, val loss: 0.0294, val auc: 0.9560, val accuracy: 0.9625, val f1: 0.6919, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0218, val loss: 0.0300, val auc: 0.9556, val accuracy: 0.9622, val f1: 0.6838, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0220, val loss: 0.0285, val auc: 0.9559, val accuracy: 0.9619, val f1: 0.6900, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0223, val loss: 0.0301, val auc: 0.9563, val accuracy: 0.9628, val f1: 0.6889, LR: 0.0001\n",
      "Epoch 34/50, train loss: 0.0216, val loss: 0.0292, val auc: 0.9560, val accuracy: 0.9610, val f1: 0.6701, LR: 0.0001\n",
      "Epoch 35/50, train loss: 0.0218, val loss: 0.0291, val auc: 0.9567, val accuracy: 0.9628, val f1: 0.6889, LR: 0.0001\n",
      "Epoch 36/50, train loss: 0.0210, val loss: 0.0291, val auc: 0.9564, val accuracy: 0.9634, val f1: 0.6987, LR: 0.0001\n",
      "Epoch 37/50, train loss: 0.0213, val loss: 0.0287, val auc: 0.9567, val accuracy: 0.9625, val f1: 0.7024, LR: 0.0001\n",
      "Epoch 38/50, train loss: 0.0217, val loss: 0.0289, val auc: 0.9562, val accuracy: 0.9619, val f1: 0.7005, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0205, val loss: 0.0288, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6886, LR: 1e-05\n",
      "Epoch 40/50, train loss: 0.0205, val loss: 0.0287, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6886, LR: 1e-05\n",
      "Epoch 41/50, train loss: 0.0209, val loss: 0.0287, val auc: 0.9565, val accuracy: 0.9625, val f1: 0.6919, LR: 1e-05\n",
      "Epoch 42/50, train loss: 0.0205, val loss: 0.0287, val auc: 0.9564, val accuracy: 0.9625, val f1: 0.6888, LR: 1e-05\n",
      "Epoch 43/50, train loss: 0.0204, val loss: 0.0287, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6886, LR: 1e-05\n",
      "Epoch 44/50, train loss: 0.0206, val loss: 0.0289, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6870, LR: 1.0000000000000002e-06\n",
      "Epoch 45/50, train loss: 0.0205, val loss: 0.0288, val auc: 0.9565, val accuracy: 0.9625, val f1: 0.6904, LR: 1.0000000000000002e-06\n",
      "Epoch 46/50, train loss: 0.0201, val loss: 0.0288, val auc: 0.9565, val accuracy: 0.9625, val f1: 0.6904, LR: 1.0000000000000002e-06\n",
      "Epoch 47/50, train loss: 0.0205, val loss: 0.0288, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6886, LR: 1.0000000000000002e-06\n",
      "Epoch 48/50, train loss: 0.0206, val loss: 0.0288, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6886, LR: 1.0000000000000002e-06\n",
      "Epoch 49/50, train loss: 0.0207, val loss: 0.0288, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6886, LR: 1.0000000000000002e-06\n",
      "Epoch 50/50, train loss: 0.0208, val loss: 0.0288, val auc: 0.9565, val accuracy: 0.9622, val f1: 0.6886, LR: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "p1 = sum(train_y_emsplit)/len(train_y_emsplit)\n",
    "p0 = 1 - p1\n",
    "pos_weight = torch.tensor(p0/p1).to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(image_only_model_emsplit.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(image_only_model_emsplit, image_emsplit_train_loader, image_emsplit_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Only ROC: 0.9477691788939887, Accuracy: 0.9640442532267978, F1: 0.6443768996960486\n",
      "Image Only Accuracy: 0.9683466502765826, F1: 0.7178082191780821\n"
     ]
    }
   ],
   "source": [
    "# Evaluate image only model on test set\n",
    "y_probs = get_probs(image_only_model_emsplit, image_emsplit_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "image_only_roc = roc_auc_score(test_y_emsplit.numpy(), y_probs)\n",
    "image_only_accuracy = accuracy_score(test_y_emsplit.numpy(), y_preds)\n",
    "image_only_f1 = f1_score(test_y_emsplit.numpy(), y_preds)\n",
    "print(f'Image Only ROC: {image_only_roc}, Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(test_y_emsplit.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "image_only_accuracy = accuracy_score(test_y_emsplit.numpy(), y_preds)\n",
    "image_only_f1 = f1_score(test_y_emsplit.numpy(), y_preds)\n",
    "print(f'Image Only Accuracy: {image_only_accuracy}, F1: {image_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Only Model - Resplit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = brset_split[brset_split['split'] == 'train'].index\n",
    "val_idx = brset_split[brset_split['split'] == 'val'].index\n",
    "test_idx = brset_split[brset_split['split'] == 'test'].index\n",
    "\n",
    "image_train = image_embed[train_idx]\n",
    "image_val = image_embed[val_idx]\n",
    "image_test = image_embed[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "# DataSet\n",
    "image_train_dataset = SimpleDataset(image_train, y_train)\n",
    "image_val_dataset = SimpleDataset(image_val, y_val)\n",
    "image_test_dataset = SimpleDataset(image_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "image_train_loader = DataLoader(image_train_dataset, batch_size=32, shuffle=True)\n",
    "image_val_loader = DataLoader(image_val_dataset, batch_size=32, shuffle=False)\n",
    "image_test_loader = DataLoader(image_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_only_model = nn.Sequential(\n",
    "    nn.Linear(1536, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0574, val loss: 0.0364, val auc: 0.9224, val accuracy: 0.9518, val f1: 0.4678, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0430, val loss: 0.0392, val auc: 0.9187, val accuracy: 0.9472, val f1: 0.3485, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0384, val loss: 0.0342, val auc: 0.9333, val accuracy: 0.9533, val f1: 0.4967, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0378, val loss: 0.0357, val auc: 0.9316, val accuracy: 0.9545, val f1: 0.6318, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0375, val loss: 0.0347, val auc: 0.9325, val accuracy: 0.9567, val f1: 0.5220, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0337, val loss: 0.0320, val auc: 0.9349, val accuracy: 0.9588, val f1: 0.6510, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0336, val loss: 0.0367, val auc: 0.9381, val accuracy: 0.9592, val f1: 0.6581, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0323, val loss: 0.0321, val auc: 0.9405, val accuracy: 0.9598, val f1: 0.5677, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0322, val loss: 0.0300, val auc: 0.9405, val accuracy: 0.9628, val f1: 0.6513, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0330, val loss: 0.0340, val auc: 0.9419, val accuracy: 0.9542, val f1: 0.6444, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0337, val loss: 0.0310, val auc: 0.9447, val accuracy: 0.9653, val f1: 0.6799, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0319, val loss: 0.0354, val auc: 0.9406, val accuracy: 0.9506, val f1: 0.3878, LR: 0.001\n",
      "Epoch 13/50, train loss: 0.0325, val loss: 0.0314, val auc: 0.9384, val accuracy: 0.9601, val f1: 0.6649, LR: 0.001\n",
      "Epoch 14/50, train loss: 0.0321, val loss: 0.0317, val auc: 0.9468, val accuracy: 0.9592, val f1: 0.6453, LR: 0.001\n",
      "Epoch 15/50, train loss: 0.0327, val loss: 0.0293, val auc: 0.9479, val accuracy: 0.9625, val f1: 0.6433, LR: 0.001\n",
      "Epoch 16/50, train loss: 0.0293, val loss: 0.0285, val auc: 0.9494, val accuracy: 0.9616, val f1: 0.6702, LR: 0.001\n",
      "Epoch 17/50, train loss: 0.0295, val loss: 0.0385, val auc: 0.9492, val accuracy: 0.9567, val f1: 0.5316, LR: 0.001\n",
      "Epoch 18/50, train loss: 0.0308, val loss: 0.0286, val auc: 0.9505, val accuracy: 0.9625, val f1: 0.6534, LR: 0.001\n",
      "Epoch 19/50, train loss: 0.0287, val loss: 0.0377, val auc: 0.9493, val accuracy: 0.9592, val f1: 0.5552, LR: 0.001\n",
      "Epoch 20/50, train loss: 0.0285, val loss: 0.0281, val auc: 0.9487, val accuracy: 0.9625, val f1: 0.6703, LR: 0.001\n",
      "Epoch 21/50, train loss: 0.0289, val loss: 0.0391, val auc: 0.9508, val accuracy: 0.9558, val f1: 0.4894, LR: 0.001\n",
      "Epoch 22/50, train loss: 0.0293, val loss: 0.0284, val auc: 0.9504, val accuracy: 0.9619, val f1: 0.6374, LR: 0.001\n",
      "Epoch 23/50, train loss: 0.0286, val loss: 0.0288, val auc: 0.9532, val accuracy: 0.9625, val f1: 0.6573, LR: 0.001\n",
      "Epoch 24/50, train loss: 0.0286, val loss: 0.0278, val auc: 0.9536, val accuracy: 0.9641, val f1: 0.6465, LR: 0.001\n",
      "Epoch 25/50, train loss: 0.0289, val loss: 0.0284, val auc: 0.9516, val accuracy: 0.9601, val f1: 0.6615, LR: 0.001\n",
      "Epoch 26/50, train loss: 0.0284, val loss: 0.0326, val auc: 0.9489, val accuracy: 0.9616, val f1: 0.6499, LR: 0.001\n",
      "Epoch 27/50, train loss: 0.0287, val loss: 0.0286, val auc: 0.9523, val accuracy: 0.9598, val f1: 0.6765, LR: 0.001\n",
      "Epoch 28/50, train loss: 0.0285, val loss: 0.0272, val auc: 0.9556, val accuracy: 0.9625, val f1: 0.6806, LR: 0.001\n",
      "Epoch 29/50, train loss: 0.0272, val loss: 0.0292, val auc: 0.9483, val accuracy: 0.9598, val f1: 0.6684, LR: 0.001\n",
      "Epoch 30/50, train loss: 0.0294, val loss: 0.0321, val auc: 0.9527, val accuracy: 0.9592, val f1: 0.5581, LR: 0.001\n",
      "Epoch 31/50, train loss: 0.0272, val loss: 0.0295, val auc: 0.9523, val accuracy: 0.9585, val f1: 0.6809, LR: 0.001\n",
      "Epoch 32/50, train loss: 0.0281, val loss: 0.0297, val auc: 0.9529, val accuracy: 0.9582, val f1: 0.6808, LR: 0.001\n",
      "Epoch 33/50, train loss: 0.0273, val loss: 0.0287, val auc: 0.9556, val accuracy: 0.9638, val f1: 0.6313, LR: 0.001\n",
      "Epoch 34/50, train loss: 0.0275, val loss: 0.0293, val auc: 0.9549, val accuracy: 0.9579, val f1: 0.5292, LR: 0.0001\n",
      "Epoch 35/50, train loss: 0.0243, val loss: 0.0275, val auc: 0.9550, val accuracy: 0.9595, val f1: 0.6508, LR: 0.0001\n",
      "Epoch 36/50, train loss: 0.0230, val loss: 0.0283, val auc: 0.9550, val accuracy: 0.9613, val f1: 0.6702, LR: 0.0001\n",
      "Epoch 37/50, train loss: 0.0230, val loss: 0.0272, val auc: 0.9553, val accuracy: 0.9613, val f1: 0.6631, LR: 0.0001\n",
      "Epoch 38/50, train loss: 0.0235, val loss: 0.0275, val auc: 0.9554, val accuracy: 0.9616, val f1: 0.6684, LR: 0.0001\n",
      "Epoch 39/50, train loss: 0.0231, val loss: 0.0273, val auc: 0.9558, val accuracy: 0.9619, val f1: 0.6649, LR: 0.0001\n",
      "Epoch 40/50, train loss: 0.0228, val loss: 0.0278, val auc: 0.9557, val accuracy: 0.9631, val f1: 0.7000, LR: 1e-05\n",
      "Epoch 41/50, train loss: 0.0221, val loss: 0.0274, val auc: 0.9559, val accuracy: 0.9607, val f1: 0.6684, LR: 1e-05\n",
      "Epoch 42/50, train loss: 0.0224, val loss: 0.0275, val auc: 0.9560, val accuracy: 0.9616, val f1: 0.6719, LR: 1e-05\n",
      "Epoch 43/50, train loss: 0.0225, val loss: 0.0273, val auc: 0.9559, val accuracy: 0.9613, val f1: 0.6684, LR: 1e-05\n",
      "Epoch 44/50, train loss: 0.0223, val loss: 0.0273, val auc: 0.9559, val accuracy: 0.9625, val f1: 0.6755, LR: 1e-05\n",
      "Epoch 45/50, train loss: 0.0223, val loss: 0.0276, val auc: 0.9560, val accuracy: 0.9628, val f1: 0.6756, LR: 1e-05\n",
      "Epoch 46/50, train loss: 0.0219, val loss: 0.0275, val auc: 0.9560, val accuracy: 0.9622, val f1: 0.6720, LR: 1.0000000000000002e-06\n",
      "Epoch 47/50, train loss: 0.0223, val loss: 0.0275, val auc: 0.9560, val accuracy: 0.9625, val f1: 0.6755, LR: 1.0000000000000002e-06\n",
      "Epoch 48/50, train loss: 0.0225, val loss: 0.0274, val auc: 0.9560, val accuracy: 0.9625, val f1: 0.6755, LR: 1.0000000000000002e-06\n",
      "Epoch 49/50, train loss: 0.0223, val loss: 0.0274, val auc: 0.9560, val accuracy: 0.9622, val f1: 0.6737, LR: 1.0000000000000002e-06\n",
      "Epoch 50/50, train loss: 0.0220, val loss: 0.0274, val auc: 0.9560, val accuracy: 0.9619, val f1: 0.6720, LR: 1.0000000000000002e-06\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(image_only_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(image_only_model, image_train_loader, image_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Only ROC: 0.9571335873519634, Accuracy: 0.9612665232093452, F1: 0.6012658227848101\n",
      "Image Only Accuracy: 0.9631109744850906, F1: 0.7196261682242989\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(image_only_model, image_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "image_only_roc = roc_auc_score(y[test_idx].numpy(), y_probs)\n",
    "image_only_accuracy = accuracy_score(y[test_idx].numpy(), y_preds)\n",
    "image_only_f1 = f1_score(y[test_idx].numpy(), y_preds)\n",
    "print(f'Image Only ROC: {image_only_roc}, Accuracy: {image_only_accuracy}, F1: {image_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y[test_idx].numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "image_only_accuracy = accuracy_score(y[test_idx].numpy(), y_preds)\n",
    "image_only_f1 = f1_score(y[test_idx].numpy(), y_preds)\n",
    "print(f'Image Only Accuracy: {image_only_accuracy}, F1: {image_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text_embed into train and test based on brset_embed['split']\n",
    "text_train = text_embed[train_idx]\n",
    "text_val = text_embed[val_idx]\n",
    "text_test = text_embed[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_dataset = SimpleDataset(text_train, y_train)\n",
    "text_val_dataset = SimpleDataset(text_val, y_val)\n",
    "text_test_dataset = SimpleDataset(text_test, y_test)\n",
    "\n",
    "text_train_loader = DataLoader(text_train_dataset, batch_size=32, shuffle=True)\n",
    "text_val_loader = DataLoader(text_val_dataset, batch_size=32, shuffle=False)\n",
    "text_test_loader = DataLoader(text_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_model = nn.Sequential(\n",
    "    nn.Linear(4096, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    # nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, 1),\n",
    "    # nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0736, val loss: 0.0320, val auc: 0.9431, val accuracy: 0.9527, val f1: 0.4380, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0348, val loss: 0.0323, val auc: 0.9517, val accuracy: 0.9619, val f1: 0.7328, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0305, val loss: 0.0266, val auc: 0.9576, val accuracy: 0.9699, val f1: 0.7216, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0269, val loss: 0.0243, val auc: 0.9544, val accuracy: 0.9773, val f1: 0.8093, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0332, val loss: 0.0288, val auc: 0.9563, val accuracy: 0.9668, val f1: 0.6805, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0318, val loss: 0.0358, val auc: 0.9591, val accuracy: 0.9647, val f1: 0.6326, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0316, val loss: 0.0291, val auc: 0.9585, val accuracy: 0.9659, val f1: 0.6520, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0326, val loss: 0.0331, val auc: 0.9596, val accuracy: 0.9628, val f1: 0.6134, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0338, val loss: 0.0274, val auc: 0.9602, val accuracy: 0.9705, val f1: 0.7318, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0341, val loss: 0.0317, val auc: 0.9591, val accuracy: 0.9567, val f1: 0.5253, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0283, val loss: 0.0294, val auc: 0.9589, val accuracy: 0.9610, val f1: 0.6044, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0280, val loss: 0.0282, val auc: 0.9595, val accuracy: 0.9742, val f1: 0.7801, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0280, val loss: 0.0285, val auc: 0.9602, val accuracy: 0.9748, val f1: 0.7897, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0272, val loss: 0.0280, val auc: 0.9602, val accuracy: 0.9757, val f1: 0.7916, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0270, val loss: 0.0285, val auc: 0.9604, val accuracy: 0.9757, val f1: 0.7882, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0271, val loss: 0.0283, val auc: 0.9601, val accuracy: 0.9671, val f1: 0.6899, LR: 1e-05\n",
      "Epoch 17/50, train loss: 0.0261, val loss: 0.0280, val auc: 0.9604, val accuracy: 0.9754, val f1: 0.7861, LR: 1e-05\n",
      "Epoch 18/50, train loss: 0.0273, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1e-05\n",
      "Epoch 19/50, train loss: 0.0271, val loss: 0.0278, val auc: 0.9603, val accuracy: 0.9736, val f1: 0.7749, LR: 1e-05\n",
      "Epoch 20/50, train loss: 0.0263, val loss: 0.0278, val auc: 0.9600, val accuracy: 0.9736, val f1: 0.7749, LR: 1e-05\n",
      "Epoch 21/50, train loss: 0.0269, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9754, val f1: 0.7872, LR: 1e-05\n",
      "Epoch 22/50, train loss: 0.0276, val loss: 0.0281, val auc: 0.9603, val accuracy: 0.9736, val f1: 0.7676, LR: 1.0000000000000002e-06\n",
      "Epoch 23/50, train loss: 0.0261, val loss: 0.0280, val auc: 0.9604, val accuracy: 0.9754, val f1: 0.7872, LR: 1.0000000000000002e-06\n",
      "Epoch 24/50, train loss: 0.0271, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9754, val f1: 0.7872, LR: 1.0000000000000002e-06\n",
      "Epoch 25/50, train loss: 0.0266, val loss: 0.0279, val auc: 0.9606, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-06\n",
      "Epoch 26/50, train loss: 0.0274, val loss: 0.0279, val auc: 0.9604, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-06\n",
      "Epoch 27/50, train loss: 0.0268, val loss: 0.0279, val auc: 0.9606, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-06\n",
      "Epoch 28/50, train loss: 0.0264, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-07\n",
      "Epoch 29/50, train loss: 0.0262, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-07\n",
      "Epoch 30/50, train loss: 0.0266, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-07\n",
      "Epoch 31/50, train loss: 0.0261, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-07\n",
      "Epoch 32/50, train loss: 0.0272, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-07\n",
      "Epoch 33/50, train loss: 0.0263, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000002e-07\n",
      "Epoch 34/50, train loss: 0.0264, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 35/50, train loss: 0.0268, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 36/50, train loss: 0.0265, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 37/50, train loss: 0.0266, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 38/50, train loss: 0.0268, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 39/50, train loss: 0.0266, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 40/50, train loss: 0.0270, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 41/50, train loss: 0.0273, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 42/50, train loss: 0.0259, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 43/50, train loss: 0.0270, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 44/50, train loss: 0.0262, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 45/50, train loss: 0.0263, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 46/50, train loss: 0.0271, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 47/50, train loss: 0.0260, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 48/50, train loss: 0.0266, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 49/50, train loss: 0.0266, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n",
      "Epoch 50/50, train loss: 0.0267, val loss: 0.0279, val auc: 0.9605, val accuracy: 0.9745, val f1: 0.7810, LR: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(text_only_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(text_only_model, text_train_loader, text_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Only ROC: 0.9761734522853989, Accuracy: 0.9342145711650784, F1: 0.0\n",
      "Text Only Accuracy: 0.9787888103289272, F1: 0.8345323741007193\n"
     ]
    }
   ],
   "source": [
    "# Evaluate text only model on test set\n",
    "y_probs = get_probs(text_only_model, text_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "text_only_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "text_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "text_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Text Only ROC: {text_only_roc}, Accuracy: {text_only_accuracy}, F1: {text_only_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "text_only_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "text_only_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Text Only Accuracy: {text_only_accuracy}, F1: {text_only_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Early Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_early_fusion_model = nn.Sequential(\n",
    "    nn.Linear(4096+1536, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 1),\n",
    "    # nn.Sigmoid()\n",
    ")\n",
    "\n",
    "combined_train = torch.cat((text_train, image_train), dim=1)\n",
    "combined_val = torch.cat((text_val, image_val), dim=1)\n",
    "combined_test = torch.cat((text_test, image_test), dim=1)\n",
    "\n",
    "combined_train_dataset = SimpleDataset(combined_train, y_train)\n",
    "combined_val_dataset = SimpleDataset(combined_val, y_val)\n",
    "combined_test_dataset = SimpleDataset(combined_test, y_test)\n",
    "\n",
    "combined_train_loader = DataLoader(combined_train_dataset, batch_size=32, shuffle=True)\n",
    "combined_val_loader = DataLoader(combined_val_dataset, batch_size=32, shuffle=False)\n",
    "combined_test_loader = DataLoader(combined_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.1764, val loss: 0.0254, val auc: 0.9623, val accuracy: 0.9662, val f1: 0.6584, LR: 0.001\n",
      "Epoch 2/50, train loss: 0.0275, val loss: 0.0268, val auc: 0.9644, val accuracy: 0.9717, val f1: 0.7745, LR: 0.001\n",
      "Epoch 3/50, train loss: 0.0257, val loss: 0.0259, val auc: 0.9679, val accuracy: 0.9616, val f1: 0.5847, LR: 0.001\n",
      "Epoch 4/50, train loss: 0.0270, val loss: 0.0237, val auc: 0.9671, val accuracy: 0.9681, val f1: 0.6848, LR: 0.001\n",
      "Epoch 5/50, train loss: 0.0284, val loss: 0.0298, val auc: 0.9673, val accuracy: 0.9647, val f1: 0.6302, LR: 0.001\n",
      "Epoch 6/50, train loss: 0.0250, val loss: 0.0258, val auc: 0.9688, val accuracy: 0.9687, val f1: 0.6871, LR: 0.001\n",
      "Epoch 7/50, train loss: 0.0244, val loss: 0.0251, val auc: 0.9648, val accuracy: 0.9671, val f1: 0.6667, LR: 0.001\n",
      "Epoch 8/50, train loss: 0.0221, val loss: 0.0271, val auc: 0.9683, val accuracy: 0.9622, val f1: 0.7545, LR: 0.001\n",
      "Epoch 9/50, train loss: 0.0260, val loss: 0.0191, val auc: 0.9705, val accuracy: 0.9773, val f1: 0.8177, LR: 0.001\n",
      "Epoch 10/50, train loss: 0.0248, val loss: 0.0202, val auc: 0.9697, val accuracy: 0.9782, val f1: 0.8076, LR: 0.001\n",
      "Epoch 11/50, train loss: 0.0224, val loss: 0.0200, val auc: 0.9703, val accuracy: 0.9800, val f1: 0.8346, LR: 0.001\n",
      "Epoch 12/50, train loss: 0.0208, val loss: 0.0213, val auc: 0.9713, val accuracy: 0.9788, val f1: 0.8099, LR: 0.001\n",
      "Epoch 13/50, train loss: 0.0255, val loss: 0.0253, val auc: 0.9685, val accuracy: 0.9767, val f1: 0.7889, LR: 0.001\n",
      "Epoch 14/50, train loss: 0.0311, val loss: 0.0265, val auc: 0.9694, val accuracy: 0.9656, val f1: 0.6433, LR: 0.001\n",
      "Epoch 15/50, train loss: 0.0284, val loss: 0.0298, val auc: 0.9693, val accuracy: 0.9739, val f1: 0.7606, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0236, val loss: 0.0251, val auc: 0.9690, val accuracy: 0.9810, val f1: 0.8434, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0225, val loss: 0.0265, val auc: 0.9691, val accuracy: 0.9776, val f1: 0.8043, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0225, val loss: 0.0272, val auc: 0.9697, val accuracy: 0.9770, val f1: 0.7967, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0222, val loss: 0.0246, val auc: 0.9694, val accuracy: 0.9797, val f1: 0.8325, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0232, val loss: 0.0242, val auc: 0.9697, val accuracy: 0.9810, val f1: 0.8426, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0229, val loss: 0.0243, val auc: 0.9695, val accuracy: 0.9791, val f1: 0.8238, LR: 1e-05\n",
      "Epoch 22/50, train loss: 0.0218, val loss: 0.0244, val auc: 0.9697, val accuracy: 0.9794, val f1: 0.8260, LR: 1e-05\n",
      "Epoch 23/50, train loss: 0.0214, val loss: 0.0245, val auc: 0.9697, val accuracy: 0.9794, val f1: 0.8260, LR: 1e-05\n",
      "Epoch 24/50, train loss: 0.0222, val loss: 0.0244, val auc: 0.9696, val accuracy: 0.9807, val f1: 0.8372, LR: 1e-05\n",
      "Epoch 25/50, train loss: 0.0220, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9807, val f1: 0.8372, LR: 1e-05\n",
      "Epoch 26/50, train loss: 0.0224, val loss: 0.0247, val auc: 0.9696, val accuracy: 0.9794, val f1: 0.8251, LR: 1e-05\n",
      "Epoch 27/50, train loss: 0.0217, val loss: 0.0247, val auc: 0.9696, val accuracy: 0.9797, val f1: 0.8272, LR: 1.0000000000000002e-06\n",
      "Epoch 28/50, train loss: 0.0221, val loss: 0.0246, val auc: 0.9696, val accuracy: 0.9800, val f1: 0.8312, LR: 1.0000000000000002e-06\n",
      "Epoch 29/50, train loss: 0.0214, val loss: 0.0246, val auc: 0.9696, val accuracy: 0.9800, val f1: 0.8312, LR: 1.0000000000000002e-06\n",
      "Epoch 30/50, train loss: 0.0216, val loss: 0.0246, val auc: 0.9696, val accuracy: 0.9800, val f1: 0.8312, LR: 1.0000000000000002e-06\n",
      "Epoch 31/50, train loss: 0.0221, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9800, val f1: 0.8312, LR: 1.0000000000000002e-06\n",
      "Epoch 32/50, train loss: 0.0219, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9800, val f1: 0.8312, LR: 1.0000000000000002e-06\n",
      "Epoch 33/50, train loss: 0.0214, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000002e-07\n",
      "Epoch 34/50, train loss: 0.0219, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000002e-07\n",
      "Epoch 35/50, train loss: 0.0216, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000002e-07\n",
      "Epoch 36/50, train loss: 0.0215, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000002e-07\n",
      "Epoch 37/50, train loss: 0.0220, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000002e-07\n",
      "Epoch 38/50, train loss: 0.0225, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000002e-07\n",
      "Epoch 39/50, train loss: 0.0219, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 40/50, train loss: 0.0220, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 41/50, train loss: 0.0219, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 42/50, train loss: 0.0220, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 43/50, train loss: 0.0215, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 44/50, train loss: 0.0222, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 45/50, train loss: 0.0227, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 46/50, train loss: 0.0216, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 47/50, train loss: 0.0221, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 48/50, train loss: 0.0216, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 49/50, train loss: 0.0216, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n",
      "Epoch 50/50, train loss: 0.0221, val loss: 0.0245, val auc: 0.9696, val accuracy: 0.9803, val f1: 0.8342, LR: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(simple_early_fusion_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(simple_early_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Fusion ROC: 0.9857199090945434, Accuracy: 0.9342145711650784, F1: 0.0\n",
      "Early Fusion Accuracy: 0.9797110359667999, F1: 0.8382352941176471\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(simple_early_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "early_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "early_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "early_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Early Fusion ROC: {early_fusion_roc}, Accuracy: {early_fusion_accuracy}, F1: {early_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "early_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "early_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Early Fusion Accuracy: {early_fusion_accuracy}, F1: {early_fusion_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Late Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separate modules for text and image processing\n",
    "class TextModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class ImageModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class SimpleLateFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLateFusionModel, self).__init__()\n",
    "        self.text_module = TextModule()\n",
    "        self.image_module = ImageModule()\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_features = self.text_module(text_data)\n",
    "        image_features = self.image_module(image_data)\n",
    "        combined_features = torch.cat((text_features, image_features), dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.output(x)\n",
    "        return x\n",
    "\n",
    "late_fusion_model = SimpleLateFusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0402, val loss: 0.0275, val auc: 0.9575, val accuracy: 0.9631, val f1: 0.6296, LR: 0.0001\n",
      "Epoch 2/50, train loss: 0.0258, val loss: 0.0225, val auc: 0.9648, val accuracy: 0.9717, val f1: 0.7444, LR: 0.0001\n",
      "Epoch 3/50, train loss: 0.0215, val loss: 0.0358, val auc: 0.9677, val accuracy: 0.9601, val f1: 0.5578, LR: 0.0001\n",
      "Epoch 4/50, train loss: 0.0204, val loss: 0.0192, val auc: 0.9704, val accuracy: 0.9773, val f1: 0.8032, LR: 0.0001\n",
      "Epoch 5/50, train loss: 0.0182, val loss: 0.0191, val auc: 0.9705, val accuracy: 0.9782, val f1: 0.8076, LR: 0.0001\n",
      "Epoch 6/50, train loss: 0.0163, val loss: 0.0184, val auc: 0.9709, val accuracy: 0.9794, val f1: 0.8184, LR: 0.0001\n",
      "Epoch 7/50, train loss: 0.0181, val loss: 0.0173, val auc: 0.9722, val accuracy: 0.9807, val f1: 0.8372, LR: 0.0001\n",
      "Epoch 8/50, train loss: 0.0157, val loss: 0.0196, val auc: 0.9708, val accuracy: 0.9782, val f1: 0.8337, LR: 0.0001\n",
      "Epoch 9/50, train loss: 0.0159, val loss: 0.0218, val auc: 0.9723, val accuracy: 0.9773, val f1: 0.7933, LR: 0.0001\n",
      "Epoch 10/50, train loss: 0.0154, val loss: 0.0179, val auc: 0.9732, val accuracy: 0.9794, val f1: 0.8164, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0150, val loss: 0.0166, val auc: 0.9726, val accuracy: 0.9834, val f1: 0.8663, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0147, val loss: 0.0173, val auc: 0.9731, val accuracy: 0.9813, val f1: 0.8399, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0145, val loss: 0.0165, val auc: 0.9735, val accuracy: 0.9831, val f1: 0.8642, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0137, val loss: 0.0186, val auc: 0.9750, val accuracy: 0.9803, val f1: 0.8261, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0144, val loss: 0.0241, val auc: 0.9749, val accuracy: 0.9745, val f1: 0.8176, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0135, val loss: 0.0197, val auc: 0.9759, val accuracy: 0.9782, val f1: 0.8011, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0128, val loss: 0.0223, val auc: 0.9750, val accuracy: 0.9770, val f1: 0.7875, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0119, val loss: 0.0165, val auc: 0.9756, val accuracy: 0.9828, val f1: 0.8607, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0129, val loss: 0.0157, val auc: 0.9771, val accuracy: 0.9831, val f1: 0.8579, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0124, val loss: 0.0195, val auc: 0.9758, val accuracy: 0.9797, val f1: 0.8187, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0126, val loss: 0.0270, val auc: 0.9749, val accuracy: 0.9671, val f1: 0.7838, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0131, val loss: 0.0176, val auc: 0.9768, val accuracy: 0.9810, val f1: 0.8351, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0118, val loss: 0.0206, val auc: 0.9770, val accuracy: 0.9782, val f1: 0.8022, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0119, val loss: 0.0281, val auc: 0.9767, val accuracy: 0.9714, val f1: 0.7207, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0113, val loss: 0.0153, val auc: 0.9787, val accuracy: 0.9840, val f1: 0.8667, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0112, val loss: 0.0167, val auc: 0.9772, val accuracy: 0.9822, val f1: 0.8638, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0118, val loss: 0.0152, val auc: 0.9778, val accuracy: 0.9843, val f1: 0.8689, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0107, val loss: 0.0172, val auc: 0.9784, val accuracy: 0.9831, val f1: 0.8662, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0112, val loss: 0.0168, val auc: 0.9796, val accuracy: 0.9843, val f1: 0.8734, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0104, val loss: 0.0184, val auc: 0.9788, val accuracy: 0.9797, val f1: 0.8514, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0116, val loss: 0.0165, val auc: 0.9793, val accuracy: 0.9828, val f1: 0.8621, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0098, val loss: 0.0300, val auc: 0.9733, val accuracy: 0.9638, val f1: 0.7649, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0107, val loss: 0.0263, val auc: 0.9789, val accuracy: 0.9671, val f1: 0.7821, LR: 1e-05\n",
      "Epoch 34/50, train loss: 0.0078, val loss: 0.0157, val auc: 0.9810, val accuracy: 0.9850, val f1: 0.8772, LR: 1e-05\n",
      "Epoch 35/50, train loss: 0.0073, val loss: 0.0161, val auc: 0.9809, val accuracy: 0.9843, val f1: 0.8689, LR: 1e-05\n",
      "Epoch 36/50, train loss: 0.0072, val loss: 0.0176, val auc: 0.9805, val accuracy: 0.9831, val f1: 0.8736, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0072, val loss: 0.0159, val auc: 0.9808, val accuracy: 0.9856, val f1: 0.8845, LR: 1e-05\n",
      "Epoch 38/50, train loss: 0.0072, val loss: 0.0159, val auc: 0.9810, val accuracy: 0.9846, val f1: 0.8718, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0071, val loss: 0.0157, val auc: 0.9810, val accuracy: 0.9850, val f1: 0.8759, LR: 1.0000000000000002e-06\n",
      "Epoch 40/50, train loss: 0.0068, val loss: 0.0157, val auc: 0.9810, val accuracy: 0.9850, val f1: 0.8759, LR: 1.0000000000000002e-06\n",
      "Epoch 41/50, train loss: 0.0068, val loss: 0.0157, val auc: 0.9810, val accuracy: 0.9850, val f1: 0.8759, LR: 1.0000000000000002e-06\n",
      "Epoch 42/50, train loss: 0.0067, val loss: 0.0158, val auc: 0.9810, val accuracy: 0.9850, val f1: 0.8759, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0067, val loss: 0.0158, val auc: 0.9810, val accuracy: 0.9850, val f1: 0.8759, LR: 1.0000000000000002e-06\n",
      "Epoch 44/50, train loss: 0.0067, val loss: 0.0157, val auc: 0.9809, val accuracy: 0.9853, val f1: 0.8794, LR: 1.0000000000000002e-06\n",
      "Epoch 45/50, train loss: 0.0067, val loss: 0.0157, val auc: 0.9809, val accuracy: 0.9850, val f1: 0.8772, LR: 1.0000000000000002e-07\n",
      "Epoch 46/50, train loss: 0.0067, val loss: 0.0157, val auc: 0.9809, val accuracy: 0.9853, val f1: 0.8794, LR: 1.0000000000000002e-07\n",
      "Epoch 47/50, train loss: 0.0067, val loss: 0.0157, val auc: 0.9809, val accuracy: 0.9853, val f1: 0.8788, LR: 1.0000000000000002e-07\n",
      "Epoch 48/50, train loss: 0.0067, val loss: 0.0157, val auc: 0.9809, val accuracy: 0.9853, val f1: 0.8788, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0067, val loss: 0.0157, val auc: 0.9809, val accuracy: 0.9853, val f1: 0.8788, LR: 1.0000000000000002e-07\n",
      "Epoch 50/50, train loss: 0.0067, val loss: 0.0157, val auc: 0.9809, val accuracy: 0.9853, val f1: 0.8788, LR: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(late_fusion_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(late_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion ROC: 0.9867116888548557, Accuracy: 0.984014755610206, F1: 0.8645833333333333\n",
      "Late Fusion Accuracy: 0.9864740239778665, F1: 0.8916256157635468\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(late_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "late_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "late_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "late_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Late Fusion ROC: {late_fusion_roc}, Accuracy: {late_fusion_accuracy}, F1: {late_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "late_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "late_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Late Fusion Accuracy: {late_fusion_accuracy}, F1: {late_fusion_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(1536, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Reshape x from [batch_size, 256] to [batch_size, 16, 16] for attention\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class TextAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextAttentionModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=16, num_heads=4, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(-1, 16, 16)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Flatten the output for the final fully connected layer\n",
    "        x = attn_output.reshape(-1, 256)  # Reshape back to original shape after attention\n",
    "        return x\n",
    "\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionFusionModel, self).__init__()\n",
    "        self.text_attention = TextAttentionModule()\n",
    "        self.image_attention = ImageAttentionModule()\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=256, num_heads=4, batch_first=True)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, combined_data):\n",
    "        text_data = combined_data[:, :4096]\n",
    "        image_data = combined_data[:, 4096:]\n",
    "        text_output = self.text_attention(text_data)\n",
    "        image_output = self.image_attention(image_data)\n",
    "        # combined_features = torch.cat((text_output, image_output), dim=1)\n",
    "        combined_features, _ = self.cross_attention(text_output.unsqueeze(1), image_output.unsqueeze(1), image_output.unsqueeze(1))\n",
    "        combined_features = combined_features.squeeze(1)\n",
    "        x = self.fc1(combined_features)\n",
    "\n",
    "        x = torch.relu(x)\n",
    " \n",
    "        x = self.fc2(x)\n",
    "        # x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "attention_fusion_model = AttentionFusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, train loss: 0.0604, val loss: 0.0451, val auc: 0.8778, val accuracy: 0.9404, val f1: 0.1849, LR: 0.0001\n",
      "Epoch 2/50, train loss: 0.0431, val loss: 0.0388, val auc: 0.9155, val accuracy: 0.9496, val f1: 0.4533, LR: 0.0001\n",
      "Epoch 3/50, train loss: 0.0383, val loss: 0.0354, val auc: 0.9235, val accuracy: 0.9561, val f1: 0.5600, LR: 0.0001\n",
      "Epoch 4/50, train loss: 0.0352, val loss: 0.0363, val auc: 0.9283, val accuracy: 0.9515, val f1: 0.4397, LR: 0.0001\n",
      "Epoch 5/50, train loss: 0.0352, val loss: 0.0410, val auc: 0.9310, val accuracy: 0.9518, val f1: 0.4291, LR: 0.0001\n",
      "Epoch 6/50, train loss: 0.0344, val loss: 0.0348, val auc: 0.9347, val accuracy: 0.9561, val f1: 0.6416, LR: 0.0001\n",
      "Epoch 7/50, train loss: 0.0321, val loss: 0.0337, val auc: 0.9394, val accuracy: 0.9570, val f1: 0.5238, LR: 0.0001\n",
      "Epoch 8/50, train loss: 0.0319, val loss: 0.0306, val auc: 0.9391, val accuracy: 0.9628, val f1: 0.6721, LR: 0.0001\n",
      "Epoch 9/50, train loss: 0.0310, val loss: 0.0306, val auc: 0.9420, val accuracy: 0.9638, val f1: 0.6380, LR: 0.0001\n",
      "Epoch 10/50, train loss: 0.0311, val loss: 0.0309, val auc: 0.9431, val accuracy: 0.9607, val f1: 0.6503, LR: 0.0001\n",
      "Epoch 11/50, train loss: 0.0304, val loss: 0.0300, val auc: 0.9439, val accuracy: 0.9601, val f1: 0.6429, LR: 0.0001\n",
      "Epoch 12/50, train loss: 0.0294, val loss: 0.0315, val auc: 0.9454, val accuracy: 0.9635, val f1: 0.6792, LR: 0.0001\n",
      "Epoch 13/50, train loss: 0.0287, val loss: 0.0286, val auc: 0.9444, val accuracy: 0.9656, val f1: 0.6667, LR: 0.0001\n",
      "Epoch 14/50, train loss: 0.0282, val loss: 0.0310, val auc: 0.9475, val accuracy: 0.9619, val f1: 0.6000, LR: 0.0001\n",
      "Epoch 15/50, train loss: 0.0281, val loss: 0.0389, val auc: 0.9488, val accuracy: 0.9496, val f1: 0.6481, LR: 0.0001\n",
      "Epoch 16/50, train loss: 0.0271, val loss: 0.0279, val auc: 0.9494, val accuracy: 0.9656, val f1: 0.6782, LR: 0.0001\n",
      "Epoch 17/50, train loss: 0.0278, val loss: 0.0279, val auc: 0.9490, val accuracy: 0.9665, val f1: 0.6804, LR: 0.0001\n",
      "Epoch 18/50, train loss: 0.0277, val loss: 0.0290, val auc: 0.9481, val accuracy: 0.9656, val f1: 0.6543, LR: 0.0001\n",
      "Epoch 19/50, train loss: 0.0261, val loss: 0.0295, val auc: 0.9501, val accuracy: 0.9607, val f1: 0.6784, LR: 0.0001\n",
      "Epoch 20/50, train loss: 0.0268, val loss: 0.0333, val auc: 0.9502, val accuracy: 0.9573, val f1: 0.5190, LR: 0.0001\n",
      "Epoch 21/50, train loss: 0.0263, val loss: 0.0275, val auc: 0.9506, val accuracy: 0.9662, val f1: 0.6746, LR: 0.0001\n",
      "Epoch 22/50, train loss: 0.0256, val loss: 0.0281, val auc: 0.9542, val accuracy: 0.9638, val f1: 0.6990, LR: 0.0001\n",
      "Epoch 23/50, train loss: 0.0257, val loss: 0.0288, val auc: 0.9522, val accuracy: 0.9638, val f1: 0.6313, LR: 0.0001\n",
      "Epoch 24/50, train loss: 0.0255, val loss: 0.0278, val auc: 0.9533, val accuracy: 0.9647, val f1: 0.6917, LR: 0.0001\n",
      "Epoch 25/50, train loss: 0.0257, val loss: 0.0282, val auc: 0.9542, val accuracy: 0.9635, val f1: 0.6925, LR: 0.0001\n",
      "Epoch 26/50, train loss: 0.0250, val loss: 0.0272, val auc: 0.9547, val accuracy: 0.9653, val f1: 0.6565, LR: 0.0001\n",
      "Epoch 27/50, train loss: 0.0240, val loss: 0.0377, val auc: 0.9523, val accuracy: 0.9598, val f1: 0.5619, LR: 0.0001\n",
      "Epoch 28/50, train loss: 0.0244, val loss: 0.0261, val auc: 0.9549, val accuracy: 0.9653, val f1: 0.6781, LR: 0.0001\n",
      "Epoch 29/50, train loss: 0.0235, val loss: 0.0265, val auc: 0.9534, val accuracy: 0.9638, val f1: 0.6811, LR: 0.0001\n",
      "Epoch 30/50, train loss: 0.0239, val loss: 0.0260, val auc: 0.9564, val accuracy: 0.9665, val f1: 0.6947, LR: 0.0001\n",
      "Epoch 31/50, train loss: 0.0235, val loss: 0.0265, val auc: 0.9572, val accuracy: 0.9662, val f1: 0.6875, LR: 0.0001\n",
      "Epoch 32/50, train loss: 0.0229, val loss: 0.0294, val auc: 0.9534, val accuracy: 0.9635, val f1: 0.7119, LR: 0.0001\n",
      "Epoch 33/50, train loss: 0.0230, val loss: 0.0285, val auc: 0.9553, val accuracy: 0.9644, val f1: 0.7114, LR: 0.0001\n",
      "Epoch 34/50, train loss: 0.0226, val loss: 0.0285, val auc: 0.9562, val accuracy: 0.9659, val f1: 0.6783, LR: 0.0001\n",
      "Epoch 35/50, train loss: 0.0228, val loss: 0.0285, val auc: 0.9562, val accuracy: 0.9650, val f1: 0.6566, LR: 0.0001\n",
      "Epoch 36/50, train loss: 0.0235, val loss: 0.0330, val auc: 0.9553, val accuracy: 0.9622, val f1: 0.6019, LR: 1e-05\n",
      "Epoch 37/50, train loss: 0.0202, val loss: 0.0268, val auc: 0.9573, val accuracy: 0.9653, val f1: 0.6817, LR: 1e-05\n",
      "Epoch 38/50, train loss: 0.0195, val loss: 0.0262, val auc: 0.9579, val accuracy: 0.9653, val f1: 0.6938, LR: 1e-05\n",
      "Epoch 39/50, train loss: 0.0185, val loss: 0.0263, val auc: 0.9578, val accuracy: 0.9659, val f1: 0.7008, LR: 1e-05\n",
      "Epoch 40/50, train loss: 0.0186, val loss: 0.0274, val auc: 0.9577, val accuracy: 0.9644, val f1: 0.6723, LR: 1e-05\n",
      "Epoch 41/50, train loss: 0.0183, val loss: 0.0271, val auc: 0.9576, val accuracy: 0.9662, val f1: 0.7090, LR: 1e-05\n",
      "Epoch 42/50, train loss: 0.0185, val loss: 0.0272, val auc: 0.9571, val accuracy: 0.9650, val f1: 0.6868, LR: 1.0000000000000002e-06\n",
      "Epoch 43/50, train loss: 0.0175, val loss: 0.0271, val auc: 0.9572, val accuracy: 0.9644, val f1: 0.6848, LR: 1.0000000000000002e-06\n",
      "Epoch 44/50, train loss: 0.0174, val loss: 0.0271, val auc: 0.9574, val accuracy: 0.9644, val f1: 0.6831, LR: 1.0000000000000002e-06\n",
      "Epoch 45/50, train loss: 0.0177, val loss: 0.0271, val auc: 0.9574, val accuracy: 0.9647, val f1: 0.6849, LR: 1.0000000000000002e-06\n",
      "Epoch 46/50, train loss: 0.0175, val loss: 0.0271, val auc: 0.9575, val accuracy: 0.9650, val f1: 0.6868, LR: 1.0000000000000002e-06\n",
      "Epoch 47/50, train loss: 0.0176, val loss: 0.0271, val auc: 0.9576, val accuracy: 0.9647, val f1: 0.6849, LR: 1.0000000000000002e-06\n",
      "Epoch 48/50, train loss: 0.0174, val loss: 0.0271, val auc: 0.9575, val accuracy: 0.9644, val f1: 0.6831, LR: 1.0000000000000002e-07\n",
      "Epoch 49/50, train loss: 0.0176, val loss: 0.0271, val auc: 0.9575, val accuracy: 0.9644, val f1: 0.6831, LR: 1.0000000000000002e-07\n",
      "Epoch 50/50, train loss: 0.0177, val loss: 0.0271, val auc: 0.9575, val accuracy: 0.9644, val f1: 0.6831, LR: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "criterion = BinaryFocalLoss(alpha=1-p1, gamma=2)\n",
    "optimizer = optim.Adam(attention_fusion_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "history = train(attention_fusion_model, combined_train_loader, combined_val_loader, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Fusion ROC: 0.9535139756375838, Accuracy: 0.9624961573931755, F1: 0.6369047619047619\n",
      "Attention Fusion Accuracy: 0.9674146941284968, F1: 0.7282051282051282\n"
     ]
    }
   ],
   "source": [
    "y_probs = get_probs(attention_fusion_model, combined_test_loader)\n",
    "y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "attention_fusion_roc = roc_auc_score(y_test.numpy(), y_probs)\n",
    "attention_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "attention_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Attention Fusion ROC: {attention_fusion_roc}, Accuracy: {attention_fusion_accuracy}, F1: {attention_fusion_f1}')\n",
    "\n",
    "threshold = get_optimal_f1_threshold(y_test.numpy(), y_probs)\n",
    "y_preds = (np.array(y_probs) > threshold).astype(int)\n",
    "attention_fusion_accuracy = accuracy_score(y_test.numpy(), y_preds)\n",
    "attention_fusion_f1 = f1_score(y_test.numpy(), y_preds)\n",
    "print(f'Attention Fusion Accuracy: {attention_fusion_accuracy}, F1: {attention_fusion_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
