{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doug/miniconda3/envs/mit-ml/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/doug/miniconda3/envs/mit-ml/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/doug/miniconda3/envs/mit-ml/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import ConvNextV2ForImageClassification\n",
    "from sklearn.metrics import precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Weights obtained from David Restrepo: https://drive.google.com/file/d/1ExReZmG3yKUbNWgrovIKNSdRJq6ZWV3O/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torch.load('fine_tuned_convnextv2_binary_DR_ICDR_byol_best.pth')\n",
    "corrected_weights = {}\n",
    "for k, v in model_weights.items():\n",
    "    corrected_weights[k.replace('module.', '')] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied and adapted from https://github.com/luisnakayama/BRSET/blob/main/src/model.py\n",
    "class FoundationalCVModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FoundationalCVModel, self).__init__()\n",
    "        self.backbone = ConvNextV2ForImageClassification.from_pretrained('facebook/convnextv2-base-22k-224')\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = features['pooler_output']\n",
    "        return features\n",
    "\n",
    "class FoundationalCVModelWithClassifier(torch.nn.Module):\n",
    "    def __init__(self, backbone, hidden, num_classes, mode='eval', backbone_mode='eval'):\n",
    "        super(FoundationalCVModelWithClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.hidden = hidden\n",
    "        output_dim = self.calculate_backbone_out()\n",
    "        layers = []\n",
    "        \n",
    "        # Add the linear layer and ReLU activation if 'hidden' is an integer\n",
    "        if isinstance(hidden, int):\n",
    "            layers.append(nn.Linear(output_dim, hidden))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(p=0.2))\n",
    "            layers.append(nn.BatchNorm1d(hidden))\n",
    "            output_dim = hidden\n",
    "            \n",
    "        # Add the linear layer and ReLU activation for each element in 'hidden' if it's a list\n",
    "        elif isinstance(hidden, list):\n",
    "            for h in hidden:\n",
    "                layers.append(nn.Linear(output_dim, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(p=0.2))\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "                output_dim = h\n",
    "        \n",
    "        if hidden:\n",
    "            self.hidden_layers = nn.Sequential(*layers)\n",
    "        else:\n",
    "            self.norm = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "        self.classifier = nn.Linear(output_dim, num_classes)\n",
    "            \n",
    "        # Set the mode\n",
    "        self.mode = mode\n",
    "        self.backbone_mode = backbone_mode\n",
    "        \n",
    "        if backbone_mode == 'eval':\n",
    "            self.backbone.eval()\n",
    "        elif backbone_mode == 'fine_tune':\n",
    "            self.backbone.train()\n",
    "            \n",
    "        if mode == 'eval':\n",
    "            self.eval()\n",
    "        elif mode == 'fine_tune':\n",
    "            self.train()    \n",
    "\n",
    "    def calculate_backbone_out(self):\n",
    "        sample_input = torch.randn(1, 3, 224, 224)\n",
    "        \n",
    "        self.backbone.eval()\n",
    "        # Forward pass the sample input through the model\n",
    "        with torch.no_grad():\n",
    "            output = self.backbone(sample_input)\n",
    "        return output.shape[1]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass to obtain class predictions from input data.\n",
    "\n",
    "        Args:\n",
    "        - x (torch.Tensor): Input data to obtain class predictions for.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Class predictions generated by the model for the input data.\n",
    "        \"\"\"\n",
    "        # Pass the input through the backbone\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if self.hidden:\n",
    "            features = self.hidden_layers(features)\n",
    "        else:\n",
    "            features = self.norm(features)\n",
    "\n",
    "        # Apply the classifier to obtain class predictions\n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        # Get the probabilities\n",
    "        # probabilities = self.activation_f(logits)\n",
    "\n",
    "        return logits    \n",
    "\n",
    "HIDDEN = [128]\n",
    "num_classes = 2\n",
    "MODE = 'eval'\n",
    "backbone_mode = 'eval'\n",
    "\n",
    "backbone_model = FoundationalCVModel()\n",
    "model = FoundationalCVModelWithClassifier(backbone_model, hidden=HIDDEN, num_classes=num_classes, mode=MODE, backbone_mode=backbone_mode)\n",
    "model.load_state_dict(corrected_weights)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "_ = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_labels = pd.read_csv('labels.csv') # From Original BRSET Dataset\n",
    "brset_embed = pd.read_csv('embeddings.csv') # From Embeddings archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brset_labels['split'] = brset_embed['split']\n",
    "brset_labels['DR_2'] = brset_embed['DR_2']\n",
    "image_dir = '/home/doug/data/brset/images/'\n",
    "image_list = brset_labels['image_id'] + \".jpg\"\n",
    "test_list = image_list[brset_labels['split'] == 'test']\n",
    "test_labels = brset_labels[brset_labels['split'] == 'test']['DR_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "load_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, image_dir, transform):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = image_list\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "        self.images = []\n",
    "        for img_name in image_paths:\n",
    "            img_path = os.path.join(image_dir, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            img = self.transform(img)\n",
    "            self.images.append(img)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "    \n",
    "test_dataset = ImageDataset(test_list, test_labels, image_dir, load_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_probs(model, loader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    all_logits = []\n",
    "    with torch.no_grad():\n",
    "        for X,_ in loader:\n",
    "            X = X.to(device)\n",
    "            model_output = model(X).cpu()\n",
    "            all_logits.append(model_output[:,0].numpy())\n",
    "            # y_hat = torch.cat((y_hat, model(X)))\n",
    "    all_logits = np.concatenate(all_logits)\n",
    "    return nn.Sigmoid()(torch.tensor(all_logits)).numpy()\n",
    "\n",
    "def get_optimal_f1_threshold(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    return thresholds[np.argmax(f1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC: 0.9911692284210674\n",
      "Test Accuracy: 0.9849416103257529\n",
      "Test F1: 0.8778054862842892\n"
     ]
    }
   ],
   "source": [
    "test_probs = get_predicted_probs(model, test_loader)\n",
    "threshold = get_optimal_f1_threshold(test_labels, test_probs)\n",
    "test_preds = (test_probs > threshold).astype(int)\n",
    "\n",
    "test_roc = roc_auc_score(test_labels, test_probs)\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "test_f1 = f1_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Test ROC: {test_roc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test F1: {test_f1}\")\n",
    "np.save('probs/convnextv2-base_test_emsplit_probs.npy', test_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
